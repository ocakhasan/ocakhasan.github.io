[{"categories":null,"content":"Bu yÄ±lÄ±n baÅŸÄ±nda hedeflerimden birisi fazla yazÄ± yazmaktÄ±. Neden bÃ¶yle bir karar aldÄ±ÄŸÄ±mÄ± aÃ§Ä±klayayÄ±m. Blog yazmaktan ziyade, yazma sÃ¼recini sevmem. blog yazabilmek iÃ§in yazdÄ±ÄŸÄ±nÄ±z konuyu iyice Ã¶ÄŸrenmek gerekiyor. bir ÅŸeyleri Ã¶ÄŸrenmenin verdiÄŸi haz beni mutlu ediyor. YazÄ±larÄ±mÄ±n ne kadar az kiÅŸi tarafÄ±ndan olsa da okunduÄŸunu gÃ¶rmek gerÃ§ekten keyif veriyor. Ã‡evremdeki bazÄ± insanlarÄ±n blogum hakkÄ±ndaki pozitif yorumlarÄ±. YÄ±lÄ±n ilk yarÄ±sÄ±nda ne kadar fazla blog yazmak gibi bir hedefim olsa da bunu tutturamadÄ±m. Ancak yÄ±lÄ±n ikinci yarÄ±sÄ±nda, Ã¶zellikle AÄŸustos ayÄ±ndan itibaren iÃ§imde gerÃ§ekten mÃ¼thiÅŸ bir yazÄ± yazma isteÄŸi var, umarÄ±m kaybolmaz. Bundan sonra yazmak istediÄŸim konular Matematik Ekonomi OkuduÄŸum bazÄ± kitaplarÄ±n deÄŸerlendirmeleri Bir konuyu Ã¶ÄŸrenmenin en iyi yolunun o konuyu Ã¶ÄŸretmek olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum, bunu Ã¼niversite zamanÄ±nda asistanlÄ±k yaparken daha iyi anladÄ±m. Richard Feynman on Lecture Ä°ÅŸin kÃ¶tÃ¼ yanÄ± bu kadar hevesli olup bazÄ± kiÅŸisel sebeplerden dolayÄ± 1 ay gibi bir sÃ¼re ara vermek zorunda olmam. Bu sÃ¼reyi de genel olarak Ã¶ÄŸrendiklerim hakkÄ±nda dÃ¼ÅŸÃ¼nerek geÃ§irmeyi planlÄ±yorum. Buradan blogum hakkÄ±nda iyi veya kÃ¶tÃ¼ yorumlarÄ± olan herkese sevgilerle, takipte kalÄ±nÄ±z. REFERENCES https://en.wikipedia.org/wiki/Richard_Feynman ","date":"2023-09-08","objectID":"/bundan-sonra-ne-yazacagim/:0:0","tags":["life"],"title":"(TR) Bundan Sonra Ne YazacaÄŸÄ±m","uri":"/bundan-sonra-ne-yazacagim/"},{"categories":null,"content":"Introduction In the ever-evolving landscape of web development, GraphQL has emerged as a powerful alternative to traditional RESTful APIs. Its flexibility and efficiency have led many developers to consider migrating their REST endpoints to GraphQL. In this blog post, we will explore the process of converting a RESTful endpoint to GraphQL, unlocking the benefits of a more customizable and efficient data-fetching experience. Join us on this journey as we delve into the world of GraphQL and transform a RESTful API into a GraphQL powerhouse. ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:1:0","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"Rest API Implementation Letâ€™s say that we have a server with a REST Endpoint structured as below. curl http://localhost:8080/artists and it returns [ { \"name\": \"The Weeknd\", \"age\": 30, \"tracks\": [ { \"name\": \"Creepin\", \"duration\": 222 } ] }, { \"name\": \"Tame Impala\", \"age\": 30, \"tracks\": [ { \"name\": \"Let It Happen\", \"duration\": 467 } ] } ] This endpoint simply can be handled by this below code. package main import ( \"encoding/json\" \"log\" \"net/http\" ) type Track struct { Name string `json:\"name\"` Duration int `json:\"duration\"` // in seconds } type Artist struct { Name string `json:\"name\"` Age int `json:\"age\"` Tracks []Track `json:\"tracks\"` } var data = []Artist{ { Name: \"The Weeknd\", Age: 30, Tracks: []Track{ {Name: \"Creepin\", Duration: 222}, }, }, { Name: \"Tame Impala\", Age: 35, Tracks: []Track{ {Name: \"Let It Happen\", Duration: 467}, }, }, } func main() { mux := http.NewServeMux() mux.HandleFunc(\"/artists\", func(w http.ResponseWriter, r *http.Request) { if err := json.NewEncoder(w).Encode(\u0026data); err != nil { return } }) log.Fatal(http.ListenAndServe(\":8080\", mux)) } ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:2:0","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"Structure Change But you only want some of the fields maybe like [ { \"name\": \"The Weeknd\", \"tracks\": [ { \"name\": \"Creepin\", } ] }, { \"name\": \"Tame Impala\", \"tracks\": [ { \"name\": \"Let It Happen\", } ] } ] You want to make it as a GraphQL query maybe something like query { getArtists { name tracks { name } } } Question is how to change this really simple API to a graphQL endpoint. ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:2:1","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"GraphQL Implementation For this we will use the package of https://github.com/99designs/gqlgen, you can have a look. To start the project, we will follow the quick quide. First create the project mkdir example cd example go mod init example Add 99designs/gqlgen to your projectâ€™s tools.go printf '// +build tools\\npackage tools\\nimport (_ \"github.com/99designs/gqlgen\"\\n _ \"github.com/99designs/gqlgen/graphql/introspection\")' | gofmt \u003e tools.go go mod tidy Initialise gqlgen config and generate models go run github.com/99designs/gqlgen init go mod tidy Start the graphql server go run server.go ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:3:0","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"Project structure Your folder structure should look like this â”œâ”€â”€ go.mod â”œâ”€â”€ go.sum â”œâ”€â”€ gqlgen.yml â”œâ”€â”€ graph â”‚Â â”œâ”€â”€ generated.go â”‚Â â”œâ”€â”€ model â”‚Â â”‚Â â””â”€â”€ models_gen.go â”‚Â â”œâ”€â”€ resolver.go â”‚Â â”œâ”€â”€ schema.graphqls â”‚Â â””â”€â”€ schema.resolvers.go â”œâ”€â”€ server.go â””â”€â”€ tools.go ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:3:1","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"Generated Code and GraphiQL Playground Your server.go will look like this package main import ( \"log\" \"net/http\" \"os\" \"github.com/99designs/gqlgen/graphql/handler\" \"github.com/99designs/gqlgen/graphql/playground\" \"github.com/ocakhasan/graph/graph\" ) const defaultPort = \"8080\" func main() { port := os.Getenv(\"PORT\") if port == \"\" { port = defaultPort } srv := handler.NewDefaultServer(graph.NewExecutableSchema(graph.Config{Resolvers: \u0026graph.Resolver{}})) http.Handle(\"/\", playground.Handler(\"GraphQL playground\", \"/query\")) http.Handle(\"/query\", srv) log.Printf(\"connect to http://localhost:%s/ for GraphQL playground\", port) log.Fatal(http.ListenAndServe(\":\"+port, nil)) } When you run all of the commands above and run the project you should see something like this on your project We will be testing our query from the UI to easily see the results. ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:3:2","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"GraphQL File There is an autogenerated file schema.graphqls, we will be setting our Artist and Track models here. type Artist { name: String! age: Int! tracks: [Track!]! } type Track { name: String! duration: Int! } type Query { artists: [Artist!]! } Then run below command to auto-generate models resolver etc, we will just fill the logic. go run github.com/99designs/gqlgen generate Then the schema.resolvers.go file will be like this package graph // This file will be automatically regenerated based on the schema, any resolver implementations // will be copied through when generating and any unknown code will be moved to the end. // Code generated by github.com/99designs/gqlgen version v0.17.36 import ( \"context\" \"fmt\" \"github.com/ocakhasan/graph/graph/model\" ) // Artists is the resolver for the artists field. func (r *queryResolver) Artists(ctx context.Context) ([]*model.Artist, error) { panic(fmt.Errorf(\"not implemented: Artists - artists\")) } // Query returns QueryResolver implementation. func (r *Resolver) Query() QueryResolver { return \u0026queryResolver{r} } type queryResolver struct{ *Resolver } We will fill the Artists method, it will be a simple returning array of model.Artist which is in the model/models_gen.go (auto-generated file) // Code generated by github.com/99designs/gqlgen, DO NOT EDIT. package model type Artist struct { Name string `json:\"name\"` Age int `json:\"age\"` Tracks []*Track `json:\"tracks\"` } type Track struct { Name string `json:\"name\"` Duration int `json:\"duration\"` } ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:3:3","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"Implementation of the Resolver To implement the resolver we will return a hardcoded array of model.Artist struct. package graph // This file will be automatically regenerated based on the schema, any resolver implementations // will be copied through when generating and any unknown code will be moved to the end. // Code generated by github.com/99designs/gqlgen version v0.17.36 import ( \"context\" \"github.com/ocakhasan/graph/graph/model\" ) var data = []*model.Artist{ { Name: \"The Weeknd\", Age: 30, Tracks: []*model.Track{ {Name: \"Creepin\", Duration: 222}, }, }, { Name: \"Tame Impala\", Age: 60, Tracks: []*model.Track{ {Name: \"Let It Happen\", Duration: 467}, }, }, } // Artists is the resolver for the artists field. func (r *queryResolver) Artists(ctx context.Context) ([]*model.Artist, error) { return data, nil } // Query returns QueryResolver implementation. func (r *Resolver) Query() QueryResolver { return \u0026queryResolver{r} } type queryResolver struct{ *Resolver } Letâ€™s run the server again and go to GraphiQL playground (http://localhost:8080/). go run server.go Then go to http://localhost:8080 and paste the query query { artists { name } } it will return { \"data\": { \"artists\": [ { \"name\": \"The Weeknd\" }, { \"name\": \"Tame Impala\" } ] } } You can play with the editor and convert your rest endpoints to GraphQL easily. ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:3:4","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"REFERENCES In summary, transitioning from REST to GraphQL offers numerous benefits for your API. Itâ€™s a journey worth taking, promising improved efficiency and flexibility. So, take that step, and may your GraphQL journey be both rewarding and transformative. Happy coding! https://github.com/99designs/gqlgen ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:4:0","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"MOTIVATION I work as a Backend engineer almost 2 years now as of August 2023. My work mostly relies on database systems such as MySQL, Redis, Mongo etc. So it would be great to learn the internals or system designs related to those database systems. Also it is stated in the book that, aynone working on backend side who processes data and the applications they developed uses internet should read this book, so I am quite a fit for the people who should read this book. I will make a blog post on each of the chapter I read, mostly I will read after my working hours so it will probably take months for me to really finish this book. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:0:0","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"CHAPTER 1 - Reliable, Scalable and Maintainable Applications Most applications are data-intensive nowadays, the problems mostly related to amount of data etc. Most of the tools developed are highly advanced nowadays but none of them can meet all of the needs of different data processing and storing requirements. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:1:0","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"Definitions Reliability The system should continue to work correctly even though a system error occurs. tolerate human errors prevents unauthorized access there could be some hardware problems such as hard disk crashs, ram becomes faulty etc. design systems in a way that human errors opportunity are minimized. test your system, froom unit to integration tests. setup monitoring tools, perfomance metrics and error rates. Scalability The system should handle the load gracefully if the volume (data, network etc) grows. what happens to system resources when you increase the load to your system how much resource you need to increase when you increase the load. response time is what client sees, request sent and response is received from the client latency is the duration that a request is waiting to be handled in response times it is better to use percentile, not the average. because it does not tell you how many users are affected by a specific number of delay. Maintainability Project should be easily developed by many other engineers who work on the project. cost of software are mostly based on the ongoing mainteiance, not the initial software development. projects should be evolvable: meaning making changes should be easy. simple: a project should not be complex, should be easy to work with. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:1:1","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"CHAPTER 2 - Data Models and Query Languages ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:2:0","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"Relational Vs Document Model Most famous data format is SQL. Goal of relational model was to hide the implementation detail behind a cleaner interface rather than forcing developers to think the internal representation of the data. The driving forces for NoSQL (Document) Databases need for greater scalability specialized query operations not supported by SQL more dynamic and expressive data models. Chapter 2 will be continued. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:2:1","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"CHAPTER 3 - STORAGE AND RETRIEVAL On the most basic model, a database needs to do 2 operations. it should store the given data when ask it again later, it should give the data back. The questions needs to be asked as an application developer probably would not be how the database handles storage and retrieval internally? But if you have to tune the program you use, it is better to know the internals of the tool. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:3:0","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"WORLD SIMPLEST DATABASE Would be a key value store written into a file. db_set () { echo \"$1,$2\" \u003e\u003e database } db_get () { grep \"^$1,\" database | sed -e \"s/^$1,//\" | tail -n 1 } Similarly to what db_set function does, the databasess also uses a log internally, append-only data file. db_get function performance is terrible on large scale of data since it traverse the all of the file O(N). ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:3:1","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"Index To retrieve the data efficiently, you need an index. Index is an additional data which can be derived from the original set of data. Creating indexes may create an overhead to write operations, since it cannot be more efficient than writing to end of file. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:3:2","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"HASH INDEXES ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:3:3","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"Introduction Before going any further all of the code can be found in the local-go-sqs-setup. Welcome to our blog post on using local Amazon Simple Queue Service (SQS) with Golang! In this guide, weâ€™ll explore how to harness the power of local SQS within your Golang applications. By setting up and running SQS on your local environment, you can achieve seamless development and testing, reducing cloud dependencies and potential costs. Letâ€™s dive in and discover how to supercharge your Golang projects with this efficient, on-premises queuing solution! ","date":"2023-07-22","objectID":"/use-sqs-locally-with-golang/:0:0","tags":["sqs","go","consumer"],"title":"Local SQS Setup With Golang","uri":"/use-sqs-locally-with-golang/"},{"categories":null,"content":"Technologies we use Docker We will use the docker image of the softwaremill/elasticmq for the local SQS Golang softwaremill/elasticmq is a tool which runs a SQS compatible server on your local environment. ","date":"2023-07-22","objectID":"/use-sqs-locally-with-golang/:1:0","tags":["sqs","go","consumer"],"title":"Local SQS Setup With Golang","uri":"/use-sqs-locally-with-golang/"},{"categories":null,"content":"Setup the Local SQS To be able to run an sqs server locally, simply run the command docker run -p 9324:9324 -p 9325:9325 softwaremill/elasticmq Then, go to your browser and enter the url of http://localhost:9325. You will see something like this. ","date":"2023-07-22","objectID":"/use-sqs-locally-with-golang/:2:0","tags":["sqs","go","consumer"],"title":"Local SQS Setup With Golang","uri":"/use-sqs-locally-with-golang/"},{"categories":null,"content":"Create A Queue To create a queue, run the command aws sqs create-queue --endpoint-url http://localhost:9324 --queue-name test_queue --region eu-west-1 the response will be something like this. { \"QueueUrl\": \"http://localhost:9324/000000000000/test_queue\" } And the browser will be ","date":"2023-07-22","objectID":"/use-sqs-locally-with-golang/:3:0","tags":["sqs","go","consumer"],"title":"Local SQS Setup With Golang","uri":"/use-sqs-locally-with-golang/"},{"categories":null,"content":"How To Integrate With Go Normally thatâ€™s how you create a sqs client in go to list the queue urls. package main import ( \"context\" \"log\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) func main() { cfg, err := config.LoadDefaultConfig(context.Background()) if err != nil { log.Fatal(err) } sqsClient := sqs.NewFromConfig(cfg) res, err := sqsClient.ListQueues(context.Background(), \u0026sqs.ListQueuesInput{ MaxResults: aws.Int32(10), NextToken: nil, QueueNamePrefix: nil, }) if err != nil { log.Printf(\"error while listing the queues\") } for _, queue := range res.QueueUrls { log.Println(queue) } } However, to be able to connect to local queue we need an EndpointResolverWithOptions which will redirect the requests to http://localhost:9324 type EndpointResolverWithOptions interface { ResolveEndpoint(service, region string, options ...interface{}) (Endpoint, error) } To be able to do it, we can create a simple struct which implements the EndpointResolverWithOptions interface. type localResolver struct{} func (l localResolver) ResolveEndpoint(service, region string, options ...interface{}) (aws.Endpoint, error) { return aws.Endpoint{ URL: \"http://localhost:9324\", SigningRegion: \"eu-west-1\", }, nil } The all of the code is package main import ( \"context\" \"log\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) type localResolver struct{} func (l localResolver) ResolveEndpoint(service, region string, options ...interface{}) (aws.Endpoint, error) { return aws.Endpoint{ URL: \"http://localhost:9324\", SigningRegion: \"eu-west-1\", }, nil } func main() { cfg, err := config.LoadDefaultConfig(context.Background()) if err != nil { log.Fatal(err) } cfg.EndpointResolverWithOptions = localResolver{} sqsClient := sqs.NewFromConfig(cfg) res, err := sqsClient.ListQueues(context.Background(), \u0026sqs.ListQueuesInput{ MaxResults: aws.Int32(10), NextToken: nil, QueueNamePrefix: nil, }) if err != nil { log.Printf(\"error while listing the queues\") } for _, queue := range res.QueueUrls { log.Println(queue) } } When you run this code with the command go run main.go You will see something like 2023/07/22 20:27:20 http://localhost:9324/000000000000/test_queue In conclusion, leveraging local Amazon SQS with Golang empowers you to create efficient message queuing systems in your development environment. By reducing cloud dependencies and streamlining development and testing, youâ€™ll save valuable time and resources. Embrace SQS for scalable, decoupled, and reliable systems, and keep exploring its possibilities for your specific use cases. Happy coding! If you have questions, please reach out to me. ","date":"2023-07-22","objectID":"/use-sqs-locally-with-golang/:4:0","tags":["sqs","go","consumer"],"title":"Local SQS Setup With Golang","uri":"/use-sqs-locally-with-golang/"},{"categories":null,"content":"REFERENCES https://github.com/softwaremill/elasticmq https://pkg.go.dev/github.com/aws/aws-sdk-go-v2/service/sqs Thanks for reading, please let me know if you have any questions. ","date":"2023-07-22","objectID":"/use-sqs-locally-with-golang/:5:0","tags":["sqs","go","consumer"],"title":"Local SQS Setup With Golang","uri":"/use-sqs-locally-with-golang/"},{"categories":null,"content":"Motivation The motivation for me to write this blog post is that I want to have a consumer which uses goroutines for the messages received from SQS but almost all of the posts I read was did not exactly implemented as a worker pool integration. The posts uses new goroutines for each of the messages received and it might be useful for their case but if you process millions of records, creating and deleting millions of records might be a burden to garbage collector. So in this post, 10 goroutines will listen for all of the messages received. Note This case only will work if you need to process and delete the messages from the queue in each of the ReceiveMessage call. Otherwise, it might not be useful for your case. ","date":"2023-07-07","objectID":"/golang-sqs-consumer-worker-pool/:1:0","tags":null,"title":"Golang Sqs Consumer Worker Pool","uri":"/golang-sqs-consumer-worker-pool/"},{"categories":null,"content":"Design ","date":"2023-07-07","objectID":"/golang-sqs-consumer-worker-pool/:1:1","tags":null,"title":"Golang Sqs Consumer Worker Pool","uri":"/golang-sqs-consumer-worker-pool/"},{"categories":null,"content":"Implementation There are some things to consider. For our case the consumer should do following steps Receive message from the queue it can receive at most 10 messages in one single call to sqs. Send these 10 messages to the channel for workers to listen. Wait for these 10 messages process to finish. Release the workers so they can process again. It might be useful for your case, so please use with care with your judgement. ","date":"2023-07-07","objectID":"/golang-sqs-consumer-worker-pool/:2:0","tags":null,"title":"Golang Sqs Consumer Worker Pool","uri":"/golang-sqs-consumer-worker-pool/"},{"categories":null,"content":"CODE To understand the functions and methods used here, please have a visit to aws-sdk-go-v2/sqs import ( \"context\" \"sync\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" \"github.com/aws/aws-sdk-go-v2/service/sqs/types\" ) type Consumer struct { client sqs.Client queueName string } func (consumer *Consumer) Start(ctx context.Context) { params := \u0026sqs.ReceiveMessageInput{ AttributeNames: []types.QueueAttributeName{types.QueueAttributeNameAll}, MaxNumberOfMessages: 10, // max it can receive MessageAttributeNames: []string{string(types.QueueAttributeNameAll)}, QueueUrl: aws.String(consumer.queueName), WaitTimeSeconds: 20, // wait for 20 seconds at max for at least 1 message to be received } msgCh := make(chan types.Message) var wg sync.WaitGroup startPool(ctx, msgCh, \u0026wg) for { select { case \u003c-ctx.Done(): close(msgCh) return default: resp, err := consumer.client.ReceiveMessage(ctx, params) if err != nil { log.Msg(\"cannot receive messages\") continue } // add number of messages received from the queue wg.Add(len(resp.Messages)) // send received messages to sqs, so they can be processed for _, message := range resp.Messages { msgCh \u003c- message } // wait for workers in the pool to be finished. wg.Wait() } } } // startPool starts 10 goroutines which listens to the msgCh which receives the // messages from the SQS. func startPool(ctx context.Context, msgCh chan types.Message, wg *sync.WaitGroup) { for i := 0; i \u003c 10; i++ { go func() { for { select { case \u003c-ctx.Done(): return case msg, channelClosed := \u003c-msgCh: // If the channel is closed if !channelClosed { return } // handle the message here, insert your logic. // release the waitgroup to inform that the message has been processed. wg.Done() } } }() } } ","date":"2023-07-07","objectID":"/golang-sqs-consumer-worker-pool/:2:1","tags":null,"title":"Golang Sqs Consumer Worker Pool","uri":"/golang-sqs-consumer-worker-pool/"},{"categories":null,"content":"Some Points Letâ€™s say you are receiving 1 million daily throughput from the SQS. For the 10 messages you received if you create 5 goroutines in each time in the end you will create 500_000 goroutines. if you create 5 goroutines which listens to a channel and process those messages, then you will only create 5 goroutines. Thanks for reading. Any feedback is appreciated. ","date":"2023-07-07","objectID":"/golang-sqs-consumer-worker-pool/:3:0","tags":null,"title":"Golang Sqs Consumer Worker Pool","uri":"/golang-sqs-consumer-worker-pool/"},{"categories":null,"content":"Introduction Go is an excellent programming language for building HTTP servers, thanks to its net/http package in the standard library, which makes it easy to attach HTTP handlers to any Go program. The standard library also includes packages that facilitate testing HTTP servers, making it just as effortless to test them as it is to build them. Nowadays, test coverage is widely accepted as an essential and valuable part of software development. Developers invest time in testing their code to get quick feedback when making changes, and a good test suite becomes an invaluable component of the software project when combined with continuous integration and delivery methodologies. Given the importance of a good test suite, what approach should developers using Go take when testing their HTTP servers? This article provides everything you need to know to test your Go HTTP servers thoroughly. ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:0:0","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"Http Server For Conversion of Roman Numerals We will have a web server which gives the roman numeral of the given number. We will only have 1 endpoint. Show the roman numeral of the number GET /roman ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:1:0","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"Example Request and Response Request curl --location --request GET 'http://localhost:8080/roman?query=1' Response { \"output\": \"I\" } ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:1:1","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"Code and Explanation package main import ( \"encoding/json\" \"log\" \"net/http\" \"strconv\" ) var ( nums = []int{1, 4, 5, 9, 10, 40, 50, 90, 100, 400, 500, 900, 1000} symbols = []string{\"I\", \"IV\", \"V\", \"IX\", \"X\", \"XL\", \"L\", \"XC\", \"C\", \"CD\", \"D\", \"CM\", \"M\"} ) func convertIntegerToRoman(input int) string { var ( i = len(nums) - 1 result string ) for input \u003e 0 { division := input / nums[i] input = input % nums[i] for division \u003e 0 { result += symbols[i] division = division - 1 } i = i - 1 } return result } type romanHandler struct{} func (h romanHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { w.Header().Set(\"Content-Type\", \"application/json\") if r.Method != http.MethodGet { http.Error(w, \"unsupported method\", http.StatusMethodNotAllowed) return } input := r.URL.Query().Get(\"query\") inputInt, err := strconv.Atoi(input) if err != nil { http.Error(w, \"invalid input\", http.StatusBadRequest) return } output := convertIntegerToRoman(inputInt) response := map[string]interface{}{ \"output\": output, } if err := json.NewEncoder(w).Encode(\u0026response); err != nil { return } } func main() { mux := http.NewServeMux() mux.Handle(\"/roman\", romanHandler{}) log.Fatal(http.ListenAndServe(\":8080\", mux)) } Points The function convertIntegerToRoman takes an integer and return the roman numeral conversion of the number. Please have a look on Convert Number Into Roman Numeral We accept a single query parameter named query in the URL which should have the number which will be converted. The struct implements the http.Handler interface by implementing the method of ServeHTTP(ResponseWriter, *Request) ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:1:2","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"Testing Of the Server The whole purpose of this blog was to learn how to test http servers in Go, so letâ€™s find out. As we mentioned in the beginning Go has all of the tools we need to both create net/http and test net/http/httptest. All of the tools are included in the net module. Letâ€™s create a file named main_test.go which has all of the tests for the HTTP Server. ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:2:0","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"Tests package main import ( \"fmt\" \"net/http\" \"net/http/httptest\" \"strings\" \"testing\" ) func TestRomanHandler(t *testing.T) { tt := []struct { name string httpMethod string query string responseBody string statusCode int }{ { name: \"unsupported httpMethod\", httpMethod: http.MethodPost, query: \"1\", responseBody: \"unsupported httpMethod\", statusCode: http.StatusMethodNotAllowed, }, { name: \"invalid input\", httpMethod: http.MethodGet, query: \"asd\", responseBody: `invalid input`, statusCode: http.StatusBadRequest, }, { name: \"correct query param\", httpMethod: http.MethodGet, query: \"1\", responseBody: `{\"output\":\"I\"}`, statusCode: http.StatusOK, }, } for _, tc := range tt { t.Run(tc.name, func(t *testing.T) { path := fmt.Sprintf(\"/roman?query=%s\", tc.query) request := httptest.NewRequest(tc.httpMethod, path, nil) responseRecorder := httptest.NewRecorder() romanHandler{}.ServeHTTP(responseRecorder, request) if responseRecorder.Code != tc.statusCode { t.Errorf(\"Want status '%d', got '%d'\", tc.statusCode, responseRecorder.Code) } if strings.TrimSpace(responseRecorder.Body.String()) != tc.responseBody { t.Errorf(\"Want '%s', got '%s'\", tc.responseBody, responseRecorder.Body) } }) } } To test the handler, we use the common table-driven approach and provide three cases: the http method is not correct http method is correct, but the query param is invalid both http method and query param is valid. For each case, we run a subtest that creates a new request and a response recorder. We use the httptest.NewRequest function to create an http.Request struct, which represents an incoming request to the handler. This allows us to simulate a real request without relying on an actual HTTP server. However, this function only handles the request half of the testing. To handle the response half, we use httptest.ResponseRecorder, which records the mutations of the http.ResponseWriter and enables us to make assertions on it later in the test. By using this duo of httptest.ResponseRecorder and http.Request, we can successfully test any HTTP handler in Go. Running the test will produce the following output. === RUN TestRomanHandler === RUN TestRomanHandler/unsupported_method === RUN TestRomanHandler/invalid_input === RUN TestRomanHandler/correct_query_param --- PASS: TestRomanHandler (0.00s) --- PASS: TestRomanHandler/unsupported_method (0.00s) --- PASS: TestRomanHandler/invalid_input (0.00s) --- PASS: TestRomanHandler/correct_query_param (0.00s) PASS ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:2:1","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"REFERENCES net/http Testing HTTP Servers By Ieftimov Converting Decimal To Roman ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:2:2","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"I have never written my long term goals into something and I just want to try it. Letâ€™s see if I will be able to achieve my goals. Here is the list Read More Books (at least 25) Do more exercise 10000 pushups start to run regularly Write more blog posts at least 1 post per month write non-techincal stuff also (maybe some reviews on books) Go outside more ðŸ˜„ Start to learn investing Get a promotion hopefully These are the things that comes to my mind. If anything comes up, I will add it to the list. Wish me luck! ","date":"2022-12-31","objectID":"/my-goals-for-2023/:0:0","tags":["goals","life"],"title":"My Goals For 2023","uri":"/my-goals-for-2023/"},{"categories":null,"content":"MongoDB \u0026 Golang Query Examples - Cheat Sheet This cheat sheet should help you about the MongoDB queries with Golang. We will start with some basic examples to more complex queries with Go Programming Language. The examples are written with Go 1.19 and go.mongodb.org/mongo-driver/mongo. ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:0:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Table Of Contents Connecting to MongoDB Inserting A Document to MongoDB Writing Multiple Documents To MongoDB Finding Single Document From MongoDB Finding All Documents From MongoDB Updating Document(s) From MongoDB Deleting Document(s) From MongoDB ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:1:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"How to Connect to MongoDB with Golang Connecting to MongoDB is fairly simple, you just connect the uri generated by the MongoDB. Then we can use the client.Database() function to make sure that we are connecting to the correct database. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") // disconnect the mongo client when main is completed defer func() { if err = client.Disconnect(ctx); err != nil { panic(err) } }() } To really make sure that we are connected to the correct database, we can use the Ping method. ctx, cancel = context.WithTimeout(context.Background(), 2*time.Second) defer cancel() err = client.Ping(ctx, readpref.Primary()) ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:2:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Inserting A Document to MongoDB with Golang To insert a document to MongoDB, we can use the bson.D provided by the MongoDB. But to make the operations more simple and more realistic to real world applications, we will use structs with bson tags. The model we are using is type Car struct { Id primitive.ObjectID `bson:\"_id\"` Brand string `bson:\"brand\"` Model string `bson:\"model\"` Year int `bson:\"year\"` } Then we can simply use the InsertOne() method to insert a document to MongoDB. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson/primitive\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) type Car struct { Id primitive.ObjectID `bson:\"_id\"` CreatedAt time.Time `bson:\"createdAt\"` Brand string `bson:\"brand\"` Model string `bson:\"model\"` Year int `bson:\"year\"` } func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") exampleData := Car{ Id: primitive.NewObjectID(), CreatedAt: time.Now().UTC(), Brand: \"Mercedes\", Model: \"G-360\", Year: 2002, } res, err := db.Collection(\"cars\").InsertOne(context.Background(), exampleData) if err != nil { log.Fatal(err) } // inserted id is ObjectID(\"639b62ae2518fbd9315e405d\") log.Printf(\"inserted id is %v\", res.InsertedID) } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:3:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Writing Multiple Documents To MongoDB with Golang We can use the InsertMany() method of the Collection object. However, the InsertMany() requires an []interface{} to work on. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson/primitive\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) type Car struct { Id primitive.ObjectID `bson:\"_id\"` CreatedAt time.Time `bson:\"createdAt\"` Brand string `bson:\"brand\"` Model string `bson:\"model\"` Year int `bson:\"year\"` } func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") var data []interface{} data = append(data, Car{ Id: primitive.NewObjectID(), CreatedAt: time.Now().UTC(), Brand: \"Toyota\", Model: \"Corolla\", Year: 2008, }) data = append(data, Car{ Id: primitive.NewObjectID(), CreatedAt: time.Now().UTC(), Brand: \"Ford\", Model: \"Focus\", Year: 2021, }) res, err := db.Collection(\"cars\").InsertMany(context.Background(), data) if err != nil { log.Fatal(err) } // 2 documents inserted log.Printf(\"%v documents inserted\", len(res.InsertedIDs)) } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:4:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Finding Single Document From MongoDB with Golang To find a single document with a condition, we can use the FindOne() method of *Collection object. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson/primitive\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) type Car struct { Id primitive.ObjectID `bson:\"_id\"` CreatedAt time.Time `bson:\"createdAt\"` Brand string `bson:\"brand\"` Model string `bson:\"model\"` Year int `bson:\"year\"` } func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") condition := bson.M{} cur, err := db.Collection(\"cars\").FindOne(context.Background(), condition) if err != nil { log.Fatal(err) } var data []Car if err := cur.All(context.Background(), \u0026data); err != nil { log.Fatal(err) } // now we can use the data array, which contains all of the documents for _, car := range data { log.Printf(\"the brand is %v\\n\", car.Brand) } } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:5:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Fetch the Lastly Created Document We can also pass mongo.Options to the Find() operation. Letâ€™s say we want to fetch the lastly inserted document. we need to sort by the createdAt field it should be descending, thatâ€™s why we made the sort value as -1. var opts = options.FindOne().SetSort(bson.M{ \"createdAt\": -1, }) res := db.Collection(\"cars\").FindOne(context.Background(), bson.M{}, opts) if res.Err() != nil { log.Fatal(err) } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:5:1","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Finding All Documents From MongoDB with Golang To find the all documents in a collection, we can use the Find() method of *Collection object. In the below example, we did not specify any condition, which means that return all of the documents in the database. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson/primitive\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) type Car struct { Id primitive.ObjectID `bson:\"_id\"` CreatedAt time.Time `bson:\"createdAt\"` Brand string `bson:\"brand\"` Model string `bson:\"model\"` Year int `bson:\"year\"` } func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") condition := bson.M{} cur, err := db.Collection(\"cars\").Find(context.Background(), condition) if err != nil { log.Fatal(err) } var data []Car if err := cur.All(context.Background(), \u0026data); err != nil { log.Fatal(err) } // now we can use the data array, which contains all of the documents for _, car := range data { log.Printf(\"the brand is %v\\n\", car.Brand) } } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:6:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Finding Many Documents With Condition If we would like to return the cars where the brand is Toyota, then we can change the condition variable as condition := bson.M{ \"brand\": \"Toyota\" } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:6:1","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Use Projection in Find Operations If you want to use projection in Find() operation, we can use the mongo.Options for that. Letâ€™s say we would like to return 2 fields return the brand of the car. return a boolean field to check if the car is new if the production year of the car is 2022, it is new else, it is old. SetProjection() sets the value for the projection field. var opts = options.Find().SetProjection( bson.M{ \"brand\": 1, \"isNew\": bson.M{ \"$cond\": bson.M{ \"if\": bson.M{\"$gte\": bson.A{\"$year\", 2022}}, \"then\": true, \"else\": false}, }, }) cur, err := db.Collection(\"cars\").Find(context.Background(), bson.M{}, opts) More will come, so please stay tuned! ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:6:2","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Update Single Document in MongoDB With Golang To update a single document, we should use the FindOneAndUpdate() or UpdateOne() operations. For this blog, we will use the FindOneAndUpdate() operation. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") filter := bson.M{ \"brand\": \"Toyota\", \"model\": \"Corolla\", } update := bson.M{ \"year\": 2022, } res := db.Collection(\"cars\").FindOneAndUpdate(context.Background(), filter, update) if res.Err() != nil { log.Fatal(err) } // operation successful } How to return the updated document in MongoDB? We can use mongo.Options package to do that. We should set the return document option to after. opts := options.FindOneAndUpdate().SetReturnDocument(options.After) res := db.Collection(\"cars\").FindOneAndUpdate(context.Background(), filter, update, opts) // we can use the updated car document var updatedData Car if err := res.Decode(\u0026updatedData); err != nil { log.Fatal(err) } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:6:3","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Delete Document(s) from MongoDB with Golang To delete a document we can use DeleteOne() method of the *Collection object. To delete many documents, we can use the DeleteMany() method of the *Collection package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") filter := bson.M{ \"brand\": \"Toyota\", \"model\": \"Corolla\", } // for single document res, err := db.Collection(\"cars\").DeleteMany(context.Background(), filter) if err != nil { log.Fatal(err) } // 1 document is deleted. log.Printf(\"%v document is deleted\", res.DeletedCount) } More will come, so please stay tuned! ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:6:4","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Ã–zet Bu yazÄ±da basit bir kod parÃ§asÄ±ndaki bÃ¼tÃ¼n hatalarÄ± bulup refactor edeceÄŸim. Bunu yaparken de Go dilindeki temel unsurlarÄ± aÃ§Ä±klayarak yapacaÄŸÄ±m. Bu yazÄ± Concurrency Made Easy videosundan aÄŸÄ±r ÅŸekilde esinlenmiÅŸtir. Go dilinde concurreny baya Ã¶ne Ã§Ä±kan bir unsur ancak doÄŸru kullanmayÄ± bilmek daha da Ã¶nemli. Kendim de bu konuda mÃ¼kemmel sayÄ±lmam ancak hala Ã¶ÄŸreniyorum. ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:0:0","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Ãœzerinde Ã‡alÄ±ÅŸma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Elimizdeki Fonksiyon Elimizdeki fonksiyon sadece bir parametre websites alÄ±yor. Bu websiteler Ã¼zerinde gezinirken handle diye error dÃ¶ndÃ¼ren bir fonksiyon alÄ±yor ve handle fonksiyonu herhangi bir error dÃ¶ndÃ¼rdÃ¼ÄŸÃ¼ anda ise bu erroru dÃ¶ndÃ¼rmek istiyor. func handleWebsites(websites []string) error { errChan := make(chan error, 1) semaphores := make(chan struct{}, 5) // aynÄ± anda 5 iÅŸ Ã§alÄ±ÅŸtÄ±r var wg sync.WaitGroup wg.Add(len(websites)) for _, website := range websites { semaphores \u003c- struct{}{} // semaphore acquire et go func() { defer func() { wg.Done() \u003c-semaphores }() if err := handle(website); err != nil { errChan \u003c- err } }() } wg.Wait() close(semaphores) close(errChan) return \u003c-errChan } ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:1:0","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Ãœzerinde Ã‡alÄ±ÅŸma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Sorunlar ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:0","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Ãœzerinde Ã‡alÄ±ÅŸma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Semaphore ve WaitGroup KÄ±smÄ± func handleWebsites(websites []string) error { errChan := make(chan error, 1) semaphores := make(chan struct{}, 5) // aynÄ± anda 5 iÅŸ Ã§alÄ±ÅŸtÄ±r var wg sync.WaitGroup wg.Add(len(websites)) for _, website := range websites { semaphores \u003c- struct{}{} // semaphore acquire et go func() { defer func() { wg.Done() \u003c-semaphores }() if err := handle(website); err != nil { errChan \u003c- err } }() } wg.Wait() close(semaphores) close(errChan) return \u003c-errChan } Bu kÄ±sÄ±mlar kodumuzda bir panic oluÅŸturmuyor, ancak aÅŸaÄŸÄ±daki 2 durumdan birisi oluÅŸuyor. \u003c-semaphores iÅŸlemi close(semaphores) iÅŸleminden Ã¶nce oluÅŸabilir ve bu durumda zaten kanaldan bir deÄŸer okur. close(semaphores) iÅŸlemi daha Ã¶nce gerÃ§ekleÅŸir ve \u003c-semaphores ise zero value alÄ±r. Ã–nce wg.Done() operasyonu wg.Wait() fonksiyonun bitmesine ve close(semaphores) satÄ±rÄ±nÄ±n Ã§alÄ±ÅŸmasÄ±na yol aÃ§abilir. Her iki durumda da bir sÄ±kÄ±ntÄ± yok ancak bu kod fonksiyonun takibini daha zor yapÄ±yor. Bunu go dilindeki ÅŸu tavsiyeyle Ã§Ã¶zebiliriz. Release locks and semaphores in the reverse order you acquired them. AnlamÄ± ise locklar ve semaphorelarÄ± onlarÄ± aldÄ±ÄŸÄ±nÄ±z sÄ±ranÄ±n tersinde bÄ±rakÄ±n. Bu durumda kodumuz ÅŸu hale geliyor ve daha basit bir duruma dÃ¶nÃ¼ÅŸÃ¼yor. func handleWebsites(websites []string) error { errChan := make(chan error, 1) semaphores := make(chan struct{}, 5) // aynÄ± anda 5 iÅŸ Ã§alÄ±ÅŸtÄ±r var wg sync.WaitGroup wg.Add(len(websites)) for _, website := range websites { semaphores \u003c- struct{}{} // semaphore acquire et go func() { defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }() } wg.Wait() close(semaphores) close(errChan) return \u003c-errChan } Åžimdi ise sadece tek bir durum gerÃ§ekleÅŸebilir o da \u003c-semaphores iÅŸlemi channel kapanmadan okuma iÅŸlemlerini yapabilir Ã§Ã¼nkÃ¼ wg.Wait() iÅŸlemi ancak ve ancak bÃ¼tÃ¼n semaphores kanalÄ±ndan okuma iÅŸlemleri gerÃ§ekleÅŸtikten sonra gerÃ§ekleÅŸebilir. ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:1","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Ãœzerinde Ã‡alÄ±ÅŸma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"SemaphorelarÄ±n KullanÄ±mÄ± SemaphorelarÄ±n kullanÄ±ldÄ±ÄŸÄ± kÄ±sÄ±ma biraz daha yakÄ±ndan bakalÄ±m. for _, website := range websites { semaphores \u003c- struct{}{} // semaphore acquire et go func() { defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }() } semaphores channelÄ± 5 uzunluklu bir channel olduÄŸundan dolayÄ± 5 goroutine Ã§alÄ±ÅŸtÄ±ktan sonra 6. taska geldiÄŸinde fonksiyon 2. satÄ±rda duracak ve bu handle(website) fonksiyonu bitene kadar durmayacak. Halbuki ÅŸÃ¶yle bir durum daha mantÄ±klÄ± olabilir. AynÄ± anda 5 kez handle(website) fonksiyonu Ã§alÄ±ÅŸsÄ±n, bir diÄŸer deyimle goroutineler yaratÄ±lsÄ±n ve hazÄ±rda beklesin. Bunun iÃ§in ÅŸu motto ile hareket edebiliriz. Acquire semaphores when youâ€™re ready to use them. AnlamÄ± ise semaphorelarÄ± ne zaman kullanmaya hazÄ±rsan o durumda acquire et. for _, website := range websites { go func() { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }() } Bu deÄŸiÅŸiklikten sonra artÄ±k bÃ¼tÃ¼n goroutineler yaratÄ±lÄ±r ve aynÄ± anda ancak 5 tanesi sadece handle(website) fonksiyonunu Ã§alÄ±ÅŸtÄ±rabilir. ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:2","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Ãœzerinde Ã‡alÄ±ÅŸma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"For Loop For-range loop da yeni bir deÄŸiÅŸken website yaratÄ±yoruz. Bir goroutine bu deÄŸiÅŸkeni updatelerken diÄŸer goroutineler bu deÄŸiÅŸken Ã¼zerinden iÅŸlem yapÄ±yor. Bundan dolayÄ± burada bir data race var. Onun yerine 2 ÅŸekilde halledebiliriz. Functiona parametre olarak verme for _, website := range websites { go func(website string) { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }(website) } Yeni DeÄŸiÅŸken Olarak TanÄ±mlama for _, website := range websites { website := website go func() { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }() } Bundan ayrÄ± olarak da genelde goroutineleri ayrÄ± fonksiyonlara almak Ã¶nerilir. Bu kod parÃ§asÄ±nÄ± go func() { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }() ÅŸu ÅŸekilde refactor edebiliriz. func handleWebsites(websites []string) error { errChan := make(chan error, 1) semaphores := make(chan struct{}, 5) // aynÄ± anda 5 iÅŸ Ã§alÄ±ÅŸtÄ±r var wg sync.WaitGroup wg.Add(len(websites)) for _, website := range websites { go worker(website, semaphores, \u0026wg, errChan) } wg.Wait() close(semaphores) close(errChan) return \u003c-errChan } func worker(website string, sem chan struct{}, wg *sync.WaitGroup, errChan chan err) { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } } ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:3","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Ãœzerinde Ã‡alÄ±ÅŸma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Error Channele Yazma BÃ¼tÃ¼n bu iÅŸlemleri yaptÄ±k ancak hala kodumuzda bir sorun var. Herhangi bir goroutine errChan \u003c- err iÅŸlemini yaptÄ±ÄŸÄ±nda diÄŸer bÃ¼tÃ¼n error goroutineler bu kanala yazarken sonsuza kadar bekleyecekler ve bu da deadlock yaratacak. Bekleme sebebi errChan kanalÄ±nÄ±n 1 uzunlukta bir channel olmasÄ±ndan dolayÄ±dÄ±r. Bir goroutine baÅŸlatmadan Ã¶nce ne zaman ve nasÄ±l duracaÄŸÄ±nÄ± bilmek gerekir. Bunun yerine select ve case kullanarak sorunu halletmiÅŸ oluruz. func handleWebsites(websites []string) error { errChan := make(chan error, 1) semaphores := make(chan struct{}, 5) // aynÄ± anda 5 iÅŸ Ã§alÄ±ÅŸtÄ±r var wg sync.WaitGroup wg.Add(len(websites)) for _, website := range websites { go worker(website, semaphores, \u0026wg, errChan) } wg.Wait() close(semaphores) close(errChan) return \u003c-errChan } func worker(website string, sem chan struct{}, wg *sync.WaitGroup, errChan chan err) { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { select { case errChan \u003c- err: default: } } } Bu durumda eÄŸer herhangi bir goroutine errChane yazabilirse yazacak ve yazamazsa default case Ã§alÄ±ÅŸacak. HiÃ§bir goroutine bloklanmayacak. Select Case ile blocking Ã§aÄŸrÄ±larÄ± non-blocking olarak deÄŸiÅŸtirebiliriz. ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:4","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Ãœzerinde Ã‡alÄ±ÅŸma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"REFERENCES Concurrency Made Easy From Dave Chevey ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:5","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Ãœzerinde Ã‡alÄ±ÅŸma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Bu yazÄ±daki bÃ¼tÃ¼n kodlar Bu repodan bulunmaktadÄ±r. EÄŸer demo versiyonunu gÃ¶rmek isterseniz http://banafilmoner.herokuapp.com/ sitesinden gÃ¶rebilirsiniz. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:0:0","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Ã–nerme Sitesi YapalÄ±m","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"Gereksinimler Bu yazÄ±mÄ±zda yapacaÄŸÄ±mÄ±z siteyi eÄŸer kendiniz de yapmak istiyorsanÄ±z Flask ve Scikit-learn kÃ¼tÃ¼phanelerini yÃ¼klemeniz gerekmektedir. BunlarÄ± yÃ¼klemek iÃ§in terminalden ÅŸu komutlarÄ± yazabilirsiniz ya da her bir paketin dÃ¶kÃ¼mentasyonundan bakabilirsiniz. pip install Flask pip install scikit-learn ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:1:0","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Ã–nerme Sitesi YapalÄ±m","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"Sitenin YapÄ±sÄ± YapacaÄŸÄ±mÄ±z sitede film Ã¶nerileri metin benzerliÄŸi ile olacak. Bu filmlerin aÃ§Ä±klama metinlerini ise bir veri kÃ¼mesinden alacaÄŸÄ±z. Bu veri kÃ¼mesine TMDB 5000 Movies sayfasÄ±ndan ulaÅŸabilirsiniz. Bundan dolayÄ± Ã¶nerebileceÄŸimiz metinler sadece bu veri kÃ¼mesindekiler olacaktÄ±r. Metin benzerliÄŸini ise kosinÃ¼s benzerliÄŸi ile yapacaÄŸÄ±z. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:2:0","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Ã–nerme Sitesi YapalÄ±m","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"Veri Seti ve Metin BenzerliÄŸi Veri setindeki title sÃ¼tunu filmin baÅŸlÄ±ÄŸÄ±nÄ± ve overview sÃ¼tunu ise filmi basitÃ§e aÃ§Ä±klar.Bu yazÄ±da overview sÃ¼tununu kullanarak metin benzerliÄŸini kuracaÄŸÄ±z. Bunun iÃ§in Ã¶nce utils.py diye bir dosya oluÅŸturalÄ±m ve indirdiÄŸimiz veri setini de projedeki dosyaya koyalÄ±m. Ã–ncelikle filmlerin aÃ§Ä±klamalarÄ±nÄ± kullanarak kosinÃ¼s benzerliÄŸini verecek olan bir fonksiyon yazalÄ±m. from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.metrics.pairwise import linear_kernel def get_cosine_similarities(df): vectorizer = TfidfVectorizer(stop_words=\"english\") tf_idf_mat = vectorizer.fit_transform(df['overview']) cosine_sim = linear_kernel(tf_idf_mat, tf_idf_mat) return cosine_sim get_cosine_similarities(df) fonksiyonu parametere olarak DataFrame alÄ±r, DataFramei ise veri setini okuduktan sonra bu fonksiyona parametre olarak vereceÄŸiz. Fonksiyonda kullanÄ±lan TfidfVectorizer metinlerden bilgi Ã§Ä±karmamÄ±za yarayan bir algoritmadÄ±r. AÃ§Ä±lÄ±mÄ± Term frequency (tf) -\u003e (terim sÄ±klÄ±ÄŸÄ±) ve inverse document frequency (ters dÃ¶kÃ¼man sÄ±klÄ±ÄŸÄ±)dÄ±r. Yani terimlerin her bir metinde ne kadar sÄ±klÄ±kla geÃ§tiÄŸine ve bu terimlerin bÃ¼tÃ¼n dÃ¶kÃ¼manda ne kadar sÄ±klÄ±kla geÃ§tiÄŸine bakÄ±p, hangi terimlerin cÃ¼mleleri ayÄ±rmada Ã¶nemli olduÄŸuna karar verir. Bu bize (4803, n) boyutunda bir matrix dÃ¶nderecektir. n ise bu algoritmanÄ±n bulduÄŸu belirleyici kelimelerin sayÄ±sÄ±dÄ±r. YazdÄ±ÄŸÄ±mÄ±z fonksiyonla beraber, her bir cÃ¼mle iÃ§in her bir kelimenin ne kadar Ã¶nemi olduÄŸunu gÃ¶steren bir matrix elde edilecek. Daha sonra bu matrixi kullanarak her bir metin arasÄ±ndaki benzerliÄŸi bulmak iÃ§in linear_kernel kullanÄ±yoruz. Bu algoritma ise bize (4803, 4803) boyutunda her bir metnin diÄŸer 4038 filmin metni ile benzerliÄŸini gÃ¶steren bir matrix dÃ¶ndÃ¼recek. Bu fonksiyondan Ã§Ä±kan sonuÃ§ ise ÅŸu ÅŸekildedir [[1. 0. 0. ... 0. 0. 0. ] [0. 1. 0. ... 0.02160533 0. 0. ] [0. 0. 1. ... 0.01488159 0. 0. ] ... [0. 0.02160533 0.01488159 ... 1. 0.01609091 0.00701914] [0. 0. 0. ... 0.01609091 1. 0.01171696] [0. 0. 0. ... 0.00701914 0.01171696 1. ]] GÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gibi bazÄ± deÄŸerler 0 bazÄ±larÄ± 1 (kÃ¶ÅŸegendekiler), bazÄ±larÄ± da 0 ile 1 arasÄ±nda. KÄ±saca Sonucu 0 olanlar arasÄ±nda hiÃ§bir benzerlik yok, 1 olanlar zaten kendileri ile Ã¶lÃ§Ã¼ldÃ¼ÄŸÃ¼ iÃ§in aynÄ± olarak Ã§Ä±kÄ±yor, Ã¶rnek olarak 1.film ile 1.film arasÄ±ndaki benzerlik 1 olacak doÄŸal olarak 0-1 arasÄ±ndakiler ise iki film arasÄ±ndaki benzerliÄŸi gÃ¶steriyor. Ne yaptÄ±ÄŸÄ±mÄ±zÄ± kÄ±saca yazalÄ±m. Veri setini okuduk KosinÃ¼s benzerlik matriksini oluÅŸturduk. Åžimdi yapÄ±lmasÄ± gerekenler ise bu matrixi kullanÄ±p film Ã¶nerileri alabilmek. Bunun iÃ§in yapÄ±lmasÄ± gerekenler KosinÃ¼s matrixini kullanÄ±p bize verilen film iÃ§in Ã¶nerileri dÃ¶ndÃ¼ren bir fonksiyon yazmak Flask ile web arayÃ¼zÃ¼ oluÅŸturup, kullanÄ±cÄ±n girdiÄŸi filme Ã¶neriler vermek Bu fonksiyonu flask ile kullanabilmek. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:3:0","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Ã–nerme Sitesi YapalÄ±m","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"Film Ã–nerme Fonksiyonu Bu fonksiyona geÃ§meden Ã¶nce veriyi okuyalÄ±m, ve kosinÃ¼s matriximizi alalÄ±m. Åžunu belirtmem gerekir ki, kullanÄ±cÄ±nÄ±n attÄ±ÄŸÄ± her requestte veri setini baÅŸtan okuyup kosinÃ¼s matrixini okumak yÃ¼k olur. Bundan dolayÄ±, bunu bir kez yapmak adÄ±na, bu iÅŸlemleri if __name__ == \"__main__\" altÄ±nda yapacaÄŸÄ±z. Ã–ncelikle bir app.py adÄ±nda bir dosya aÃ§alÄ±m. Bu dosyada Flask applikasyonumuzun kodlarÄ± olacak. DiÄŸer utils.py dan fonksiyonlarÄ± Ã§aÄŸÄ±racaÄŸÄ±z. app.py dosyasÄ±na ÅŸu kodlarÄ± girelim. from flask import Flask, render_template, request, redirect import pandas as pd import utils app = Flask(__name__) if __name__== \"__main__\": df = pd.read_csv(\"data.csv\") df['overview'] = df['overview'].fillna('') df['lower_name'] = df['title'].str.lower() titles = pd.Series(df.index, index=df['lower_name']).drop_duplicates() cosine_sim = utils.get_cosine_similarities(df) app.run() Åžuan app.py dosyasÄ±nda yapÄ±lan iÅŸlemler. Flask uygulamasÄ± oluÅŸturuldu. Veri okundu. KosinÃ¼s benzerlik matriksi oluÅŸturuldu. Main kÄ±smÄ±nda titles diye bir deÄŸiÅŸken oluÅŸturulma sebebi bu deÄŸiÅŸkenin filmleri Ã¶nerecek olan fonksiyonda kullanacaÄŸÄ±mÄ±zdan dolayÄ±dÄ±r. Titles deÄŸiÅŸkeni tip olarak Seriesdir. Konsola yazdÄ±rdÄ±ÄŸÄ±mÄ±z zaman ÅŸÃ¶yle bir sonuÃ§ Ã§Ä±kacaktÄ±r. lower_name avatar 0 pirates of the caribbean: at world's end 1 spectre 2 the dark knight rises 3 john carter 4 ... el mariachi 4798 newlyweds 4799 signed, sealed, delivered 4800 shanghai calling 4801 my date with drew 4802 Length: 4803, dtype: int64 Åžimdi filmleri Ã¶nerecek fonksiyonu yazmaya baÅŸlayabiliriz. Bunu utils.py dosyasÄ±nda yazalÄ±m. \"\"\" movie_title = istenilen filmin ismi cosine_similarity = kosinÃ¼s benzerlik matriksi titles= az Ã¶nce oluÅŸturduÄŸumuz filmin isimlerine sahip olan `Series` df = bÃ¼tÃ¼n filmleri barÄ±ndÄ±ran dataframe \"\"\" def get_recommendations(movie_title, cosine_similarity, titles, df): index_movie = titles[movie_title] #istenilen filmin indexini bul name_of_movie = df.iloc[index_movie]['title'] #daha sonra dataframeden filmin adÄ±nÄ± bul. #istenilen isim kÃ¼Ã§Ã¼k harfli olabilir, biz #dataframde nasÄ±lsa onu almak iÃ§in yapÄ±yoruz. similarities = cosine_similarity[index_movie] #daha sonra girilen filmin kosinÃ¼s benzerlik #arrayini al, diÄŸer filmlerle benzerlik arrayi similarity_scores = list(enumerate(similarities)) #iÅŸlem kolaylÄ±ÄŸÄ± iÃ§in her bir benzerliÄŸin indexini #alabilmemiz lazÄ±m. yani (0, 0.2), (1, 0.4), (2. 0.7) ... gibi. similarity_scores = sorted(similarity_scores , key=lambda x: x[1], reverse = True) #bÃ¼tÃ¼n benzerlik skorlarÄ±nÄ± sÄ±rala similarity_scores = similarity_scores[1:11] #en benzer 10 filmi al similar_indexes = [x[0] for x in similarity_scores] #benzer filmlerin indexlerini al return df.iloc[similar_indexes], name_of_movie #benzer filmlerin bilgilerini almak iÃ§in indexlerini kullan. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:3:1","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Ã–nerme Sitesi YapalÄ±m","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"HTML ArayÃ¼z Bu fonksiyon da yazÄ±ldÄ±ÄŸÄ±na gÃ¶re ÅŸimdi Flask ile baÄŸlayabiliriz. Ama Ã¶ncelikle bir arayÃ¼zÃ¼mÃ¼z olmasÄ± gerekiyor. Bunun iÃ§in aynÄ± klasÃ¶rde templates diye bir klasÃ¶r oluÅŸturun ve iÃ§ine index.html adÄ±nda bir dosya oluÅŸturun. Bu dosya bizim kullanÄ±cÄ±dan arayÃ¼zÃ¼ almamÄ±zÄ± saÄŸlayacak olan HTML kodunu iÃ§erecek. HTML kÄ±smÄ±nÄ± anlatmayacaÄŸÄ±m. Basit ÅŸekilde Flask bildiÄŸinizi varsayÄ±yorum. index.html dosyasÄ±na buradaki arayÃ¼z kodunu yapÄ±ÅŸtÄ±rÄ±n. HTML kÄ±smÄ± ÅŸuan Ã§ok ilgi alanÄ±mÄ±z deÄŸil, eÄŸer arayÃ¼z nasÄ±l gÃ¶rÃ¼nÃ¼yor diye merak ediyorsanÄ±z, buradan bakabilirsiniz. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:3:2","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Ã–nerme Sitesi YapalÄ±m","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"Flask Endpointleri halletme Bu kodda dikkatinizi Ã§ekmek istediÄŸim bir nokta var. FORM bir â€˜/â€™ yoluna POST request yapÄ±yor. Flask uygulamasÄ±nda â€˜/â€™ adresine bir POST request yapÄ±lacak. AyrÄ±ca websitesinin giriÅŸ sayfasÄ± da bu adrese GET request yapÄ±larak alÄ±nacak. Åžimdi app.py dosyasÄ±nda bu koÅŸullarÄ± saÄŸlayan kodumuzu yazalÄ±m. from flask import Flask, render_template, request, redirect, flash, url_for import pandas as pd import utils app = Flask(__name__) @app.route('/', methods=['GET', 'POST']) def hello(): length = 0 movie_name = \"\" context = { #Bu dictionary Ã¶nerilen filmlerin bilgilerini tutuyor. 'movies': [], #isimler 'urls': [], #filmlerin sayfalarÄ± 'release_dates': [], #filmlerin yayÄ±nlanma tarihleri 'runtimes': [], #filmlerin sÃ¼releri 'overviews': [] #filmleri anlatan metinler } if request.method == \"POST\": #KullanÄ±cÄ± bir input girdiyse text = request.form['fname'].lower() print(\"request text\", text) try: recommended_df, movie_name = utils.get_recommendations( text, cosine_sim, titles, df) #girilen inputtan filmleri al context['movies'] = recommended_df.title.values context['urls'] = recommended_df.homepage.values context['release_dates'] = recommended_df.release_date.values context['runtimes'] = recommended_df.runtime.values context['overviews'] = recommended_df.overview.values length = len(context['movies']) except: return render_template('index.html', error=True) #filmi bulamadÄ±ysak error dÃ¶ndÃ¼r. return render_template('index.html', length=length, context=context, movie_name=movie_name, error=False) if __name__ == '__main__': df = pd.read_csv(\"data.csv\") df['overview'] = df['overview'].fillna('') titles = pd.Series(df.index, index=df['lower_name']).drop_duplicates() cosine_sim = utils.get_cosine_similarities(df) app.run() Render templatede gÃ¶nderilen context deÄŸiÅŸkeni HTML dosyasÄ±nda parse ediliyor ve bilgiler gÃ¼zel bir ÅŸekilde gÃ¶steriliyor. DediÄŸim gibi basit ÅŸekilde Flask bildiÄŸiniz dÃ¼ÅŸÃ¼nÃ¼yorum. BeÄŸendiyseniz paylaÅŸÄ±rsanÄ±z Ã§ok sevinirim. Ä°yi Ã¶ÄŸrenmeler. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:3:3","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Ã–nerme Sitesi YapalÄ±m","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"TANIM PyTorch da bulunan torch.autograd otomatik tÃ¼rev alma motoru ÅŸeklinde Ã§alÄ±ÅŸÄ±r ve bu da nÃ¶ral aÄŸ eÄŸitimini gÃ¼Ã§lendirir. Bu yazÄ±mÄ±zda belirli Ã¶rnekler vererek konunun daha geniÅŸ ÅŸekilde anlaÅŸÄ±lmasÄ±nÄ± saÄŸlayacaÄŸÄ±z. Ã–ncelikle Ã§ok kÄ±sa bir Ã¶zetleyici metine bakalÄ±m. ","date":"2021-02-20","objectID":"/pytorch-autograd-nedir-ve-nasil-calisir/:1:0","tags":["pytorch","matematik"],"title":"Pytorch AutoGrad Nedir ve NasÄ±l Ã‡alÄ±ÅŸÄ±r","uri":"/pytorch-autograd-nedir-ve-nasil-calisir/"},{"categories":null,"content":"Arka Plan NÃ¶ral aÄŸlar (neural networks) kendisine verilen veriyi belirli fonksiyonlarda iÅŸleyen bir bÃ¼tÃ¼ndÃ¼r. Bu fonksiyonlarÄ±n her biri bazÄ± parametrelerden (aÄŸÄ±rlÄ±klar ve Ã¶nyargÄ± (weights and bias)) oluÅŸur. Bu belirlenen parametrelere Pytorch da tensor adlÄ± veri yapÄ±larÄ±nda tutulur. Bir NÃ¶ral aÄŸÄ±n eÄŸitilmesi iki kÄ±sÄ±mdan oluÅŸur. Birinci kÄ±sÄ±mda sadece ileriye gidilir (forward propagation) ve ikinci kÄ±sÄ±mda geriye doÄŸru gidilir (backward propagation). Peki bu ileri ve geri gitme iÅŸlemleri ne iÃ§in yapÄ±lÄ±r onlara bakalÄ±m. Ä°leriye Gitme (YayÄ±lma) Bu kÄ±sÄ±mda nÃ¶ral aÄŸ kendisine verilen veriden en iyi tahminini yapmaya Ã§alÄ±ÅŸÄ±r. Bu belirlenen veri, Ã¶nceden bahsettiÄŸimiz her bir fonksiyondan geÃ§er ve en sonunda bir tahmin ortaya atÄ±lmÄ±ÅŸ olur. Daha sonra belirlenen tahmin ve gerÃ§ek deÄŸer arasÄ±ndan bir kayÄ±p (loss) deÄŸeri bulunur ve hatta bu deÄŸeri bulan fonksiyona da loss function denilir. Geriye Gitme (YayÄ±lma) Bu kÄ±sÄ±mda ise nÃ¶ral aÄŸ, ilk bÃ¶lÃ¼mde hesaplanan kayÄ±p veya hata deÄŸerini azaltmaya yÃ¶nelik parametrelerinde iyileÅŸmeye gider. Bunu yaparken de sonuÃ§tan geriye dÃ¶nÃ¼k olarak her hata deÄŸerinin her bir parametreye baÄŸlÄ± olan tÃ¼revini (derivative) hesaplar ve bu parametreleri, gradient descent kullanarak optimize eder. Ancak bu her bir fonksiyonun parametrelere gÃ¶re tÃ¼revini tek tek elimizle alamayÄ±z ve bize otomatik bir sÃ¼reÃ§ lazÄ±m. Ä°ÅŸte bu kÄ±sÄ±mda pytorch.autograd devreye giriyor ve bÃ¼tÃ¼n yÃ¼kÃ¼ alÄ±yor. ","date":"2021-02-20","objectID":"/pytorch-autograd-nedir-ve-nasil-calisir/:1:1","tags":["pytorch","matematik"],"title":"Pytorch AutoGrad Nedir ve NasÄ±l Ã‡alÄ±ÅŸÄ±r","uri":"/pytorch-autograd-nedir-ve-nasil-calisir/"},{"categories":null,"content":"Autogradâ€™da TÃ¼rev Alma Ä°ÅŸlemleri Åžimdi autogradâ€˜Ä±n bÃ¼tÃ¼n bu deÄŸerleri nasÄ±l kayÄ±t ettiÄŸine bakalÄ±m. Ã–ncelikle iki tane a ve b tensor oluÅŸturalÄ±m. Bu tensorlarÄ± oluÅŸtururken parametre olan requires_grad parametresini True yapmamÄ±z gerekiyor aksi halde otomatik tÃ¼rev alma iÅŸlemleri gerÃ§ekleÅŸemez Ã§Ã¼nkÃ¼ bu parametre Tensorun grad adlÄ± attributunda bu deÄŸerleri kayÄ±t etmemize yardÄ±mcÄ± oluyor. import torch x = torch.tensor([1., 2.], requires_grad=True) y = torch.tensor([2., 4.], requires_grad=True) Åžimdi bu iki tensoru kullanarak yeni bir tensor z oluÅŸturalÄ±m. Basit ÅŸekilde formÃ¼l $$ z = 6x^2 - 2b^3 $$ z = 6*x**2 - 2*y**3 ÅžÃ¶yle varsayalÄ±m, x ve y bizim parametrelerimiz ve z bizim hata fonksiyonumuz olsun. NÃ¶ral aÄŸ eÄŸitiminde, hatanÄ±n bu parametreleri baÄŸlÄ± olan gradyantlarÄ±nÄ± (gradient) isteriz. PyTorchâ€™da .backward() fonksiyonunu Ã§aÄŸÄ±rdÄ±ÄŸÄ±mÄ±z zaman, auutograd her bir parametrenin (x, y) gradyantlarÄ±nÄ± bulur ve bunlarÄ± her bir tensorun .grad attributunda kayÄ±t eder. Ã–ncelikle ÅŸuan x ve y nin grad deÄŸerlerine bakalÄ±m. print(\"X.grad = \", x.grad) print(\"Y.grad = \", y.grad) #Output X.grad = None Y.grad = None Ancak ÅŸimdi z tensorunda .backward() Ã§aÄŸÄ±rdÄ±ÄŸÄ±mÄ±z zaman x ve y nin .grad attributularÄ±nda z'nin kendilerine gÃ¶re tÃ¼revler yer alacak. Ancak z.backward() argÃ¼manÄ±nÄ± Ã§aÄŸÄ±rabilmek iÃ§in parametre olarak gradyant (gradient) vermemiz gerekiyor Ã§Ã¼nkÃ¼ z bir vektÃ¶r. Gradyant z ile aynÄ± boyutlara sahip ve zâ€™nin z ye gÃ¶re tÃ¼revini temsil eder. Åžimdi z.backward() fonksiyonunu Ã§aÄŸÄ±rabiliriz. gradyant_parametre = torch.tensor([1., 1.]) z.backward(gradient=gradyant_parametre) Åžimdi x.grad ve y.grad deÄŸerleri oluÅŸacak. Ancak bu deÄŸerleri gÃ¶rmeden Ã¶nce kendimiz basit bir tÃ¼rev alalÄ±m. $$ \\frac{\\partial z}{\\partial x} = 12x $$ $$ \\frac{\\partial z}{\\partial y} = -6y^2 $$ Daha sonra bu kÄ±smi tÃ¼revlere x ve y tensorlarÄ±nÄ± koyduÄŸumuz zaman ortaya Ã§Ä±kacak sonuÃ§larÄ±n ÅŸu ÅŸekilde olmasÄ± lazÄ±m. print(\"x iÃ§in = \", 12 * x) print(\"y iÃ§in = \", -6 * y**2) x iÃ§in = tensor([12., 24.], grad_fn=\u003cMulBackward0\u003e) y iÃ§in = tensor([-24., -96.], grad_fn=\u003cMulBackward0\u003e)) Åžimdi basit bir ÅŸekilde kontrol edelim. print(\"x.grad = \", x.grad) print(\"y.grad = \", y.grad) x.grad = tensor([12., 24.]) y.grad = tensor([-24., -96.]) GÃ¶rdÃ¼ÄŸÃ¼mÃ¼z Ã¼zere sonuÃ§lar doÄŸru Ã§Ä±kÄ±yor. Ãœstte gÃ¶zÃ¼ken ggrad_fn=\u003cMulBackward0\u003e ise bu bu tensorun nasÄ±l bir matematiksel operatÃ¶r kullanarak oluÅŸturulduÄŸunu sÃ¶ylÃ¼yor. EÄŸer required_grad=False olsaydÄ± bu deÄŸer None olurdu. BÃ¼tÃ¼n yazdÄ±ÄŸÄ±mÄ±z operasyonlar iÃ§in required_grad=True idi. Åžimdi required_grad=False yapÄ±p bir de Ã¶yle deneyelim. x = torch.tensor([1., 2.], requires_grad=False) y = torch.tensor([2., 4.], requires_grad=False) z = 6*x**2 - 2*y**3 gradyant_parametre = torch.tensor([1., 1.]) z.backward(gradient=gradyant_parametre) print(\"X.grad = \", x.grad) print(\"Y.grad = \", y.grad) Bu iÅŸlemden ÅŸÃ¶yle bir sonuÃ§ alacaksÄ±nÄ±z. RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn Bu da demek oluyor ki x ve y nin grad deÄŸerleri yok ve bundan dolayÄ± grad_fn fonksiyonlarÄ± da yok. x ve y nin grad deÄŸerleri olmadÄ±ÄŸÄ± iÃ§in zâ€˜nin de grad deÄŸeri yok ve bu da hataya yol aÃ§Ä±yor. Derin Ã¶ÄŸrenmede genellike Ã¶nceden belirli datasetler ile eÄŸitilmiÅŸ hazÄ±r modeller bulunmaktadÄ±r ve bunlara pretrained model denir. Bu modelleri kullanÄ±rken genellikle son katmana kadar olan bÃ¼tÃ¼n katmanlarÄ±n parametrelerini eÄŸitmek istemeyiz Ã§Ã¼nkÃ¼ bu iÅŸlem hem pahalÄ± hem de Ã§ok da gerekli olmayan bir iÅŸlem. Bu parametreleri optimize etmeye Ã§alÄ±ÅŸmadÄ±ÄŸÄ±mÄ±zdan dolayÄ± bu parametrelerin required_grad deÄŸerleri False olacaktÄ±r. Ã–rnek bir kod olarak da from torch import nn, optim model = torchvision.models.resnet18(pretrained=True) # Freeze all the parameters in the network for param in model.parameters(): param.requires_grad = False Burada Resnet18 modelinin parametrelini dondurma (freeze) iÅŸlemi yapÄ±lÄ±yor ve bÃ¶ylece modeli kullanÄ±rken resnet18 modelini parametrelerinde herhangi bir optimize etme durumu sÃ¶z konusu olmayacak. Ancak, sonradan eklenilen layerlarda optimize Ã§al","date":"2021-02-20","objectID":"/pytorch-autograd-nedir-ve-nasil-calisir/:2:0","tags":["pytorch","matematik"],"title":"Pytorch AutoGrad Nedir ve NasÄ±l Ã‡alÄ±ÅŸÄ±r","uri":"/pytorch-autograd-nedir-ve-nasil-calisir/"},{"categories":null,"content":"REFERENCES Pytorch Tutorials ","date":"2021-02-20","objectID":"/pytorch-autograd-nedir-ve-nasil-calisir/:3:0","tags":["pytorch","matematik"],"title":"Pytorch AutoGrad Nedir ve NasÄ±l Ã‡alÄ±ÅŸÄ±r","uri":"/pytorch-autograd-nedir-ve-nasil-calisir/"},{"categories":null,"content":"YazÄ±ya baÅŸlamadan Ã¶nce belirmek isterim ki, bu tarz derin Ã¶ÄŸrenme terimlerinin Ä°ngilizce ile kullanÄ±lmasÄ± taraftarÄ±yÄ±m. Teknik terimlerin TÃ¼rkÃ§e karÅŸÄ±lÄ±klarÄ± genelde her zaman duymadÄ±ÄŸÄ±mÄ±z kelimeler oluyor ve internette TÃ¼rkÃ§e pek kaynak yok. Ondan dolayÄ± ben bu terimlerin Ä°ngilizce Ã¶ÄŸrenilip, Ä°ngilizce kullanÄ±lmasÄ± taraftarÄ±yÄ±m. Herkes global olmaya Ã§alÄ±ÅŸÄ±rken, bizim Ã¶yle davranmamamÄ±z iÃ§in hiÃ§bir sebep yok. ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:0:0","tags":["numpy","pytorch","cnn"],"title":"EvriÅŸimsel Sinir AÄŸlarÄ±  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"TANIM Convolutional sinir aÄŸlarÄ± genel olarak sÄ±radan sinir aÄŸlarÄ±na Ã§ok benzerdir. Bu sinir aÄŸlarÄ± da Ã¶ÄŸrenebilir aÄŸÄ±rlÄ±k (weight) ve Ã¶nyargÄ±sÄ± (bias) olan sinirlerden (neuron) oluÅŸur. Her bir nÃ¶ron bazÄ± inputlar alÄ±r, dot product uygular ve bu iÅŸlemi lineer olmayan bir yolla devam ettirir. BÃ¼tÃ¼n network hala tek bir ayÄ±rt edilebilir skoru aÃ§Ä±klar. Network resim pixellerini alÄ±p, sonda bir tahmin Ã¼retir. Networkun sonunda belirli bir kayÄ±p fonksiyonu (loss function) bulunur. Peki bu convolutional sinir aÄŸlarÄ± normal sinir aÄŸlarÄ±na bu kadar benziyorsa ne deÄŸiÅŸiyor? Bu sorunun cevabÄ± ise ÅŸu ÅŸekildedir: Convolutional sinir aÄŸlarÄ± inputun resimlerden oluÅŸtuÄŸunu varsayar, bu varsayÄ±m bize bazÄ± Ã¶zellikleri sisteme entegre etmemize yardÄ±mcÄ± olur. ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:1:0","tags":["numpy","pytorch","cnn"],"title":"EvriÅŸimsel Sinir AÄŸlarÄ±  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"YAPISAL GÃ–ZLEM Normal Sinir AÄŸlarÄ±: Normal sinir aÄŸlarÄ± tek bir input alÄ±r, onu bazÄ± gizli katmanlardan (hidden layer) geÃ§irir. Her bir hidden layer nÃ¶ron kÃ¼melerinden oluÅŸur, her bir nÃ¶ron, bir Ã¶nceki katmandaki bÃ¼tÃ¼n nÃ¶ronlarla baÄŸlantÄ±lÄ±dÄ±r ve diÄŸer nÃ¶ronlardan baÄŸÄ±msÄ±z ÅŸekilde Ã§alÄ±ÅŸÄ±r. Son katman ise sonuÃ§ katmanÄ± (output layer) olarak adlandÄ±rÄ±lÄ±r ve bu katmanda her bir sÄ±nÄ±fÄ±n olasÄ±lÄ±ÄŸÄ± belli olur. Bu normal sinir aÄŸlarÄ± resimler kullanÄ±lÄ±nca pek iyi Ã¶lÃ§eklenemiyor. Ã–rnek olarak $(32, 32, 3)$ lÃ¼k boyutlarda resimler kullanÄ±rsak, ilk katman $32 * 32 * 3 = 3072$ aÄŸÄ±rlÄ±ÄŸa sahip olacaktÄ±r. Bu yÃ¼k halledilebilir ÅŸekilde gÃ¶rÃ¼lÃ¼yor ancak, bu fully-connected yapÄ± bÃ¼yÃ¼k resimlere Ã¶lÃ§eklenmiyor. Ã–rnek olarak eÄŸer biz boyutlarÄ± $(200, 200, 3)$ olan resimler kullanÄ±rsak, bu sefer nilk nÃ¶ronlar $200 * 200 * 3 = 120, 000$ aÄŸÄ±rlÄ±ÄŸa sahip olacaklar. Ancak bu bÃ¼yÃ¼k numaralÄ± aÄŸÄ±rlÄ±klar aÅŸÄ±rÄ± uyma (overfitting) denilen olaya sebep olacaktÄ±r. Convolutional sinir aÄŸlarÄ± ise inputun resimlerden oluÅŸmasÄ±nÄ±ndan faydalanÄ±r ve buna gÃ¶re yapÄ±yÄ± daha mantÄ±klÄ± ÅŸekilde kurar. Normal sinir aÄŸlarÄ±nÄ±n aksine, Convolutiona sinir aÄŸlarÄ±nÄ±n nÃ¶ronlarÄ± 3 boyuta ayarlanmÄ±ÅŸ ÅŸekildedir. geniÅŸlik, yÃ¼kseklik, derinlik. Ã–rnek olarak $(32, 32, 3)$ boyutlu resimlerde GeniÅŸlik = 32 YÃ¼kseklik = 32 Derinlik = 3 olacaktÄ±r. ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:2:0","tags":["numpy","pytorch","cnn"],"title":"EvriÅŸimsel Sinir AÄŸlarÄ±  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"PEKI BU CONVOLUTIONAL SINIR AÄžLARI NASIL OLUÅžTURULUYOR? Bu sinir aÄŸlarÄ± katman dizilerinden oluÅŸur ve bu katmanlar ise ÅŸu ÅŸekildedir. Convolutional Katman Pooling KatmanÄ± Fully-Connected KatmanÄ± Bu 3 katmandan oluÅŸan katmanlarÄ± birleÅŸtirip bir sinir aÄŸÄ± oluÅŸturacaÄŸÄ±z. CONVOLUTIONAL KATMAN Convolutional katman Convolutional sinir aÄŸlarÄ±nÄ±n bÃ¼yÃ¼k aÄŸÄ±r iÅŸini yapan katmanlardÄ±r. Conv katmanlar parametreleri Ã¶ÄŸrenilebilir filtrelerden oluÅŸur. Her bir filtre boyut olarak kÃ¼Ã§Ã¼ktÃ¼r, ancak input derinliÄŸi boyunca uzanÄ±rlar. Ã–rnek olarak, tipik bir filtre $5 * 5 * 3$ boyutlarÄ±nda olabilir. Ä°lk 5 geniÅŸlik, ikinci 5 yÃ¼kseklik ve Ã¼Ã§Ã¼ncÃ¼ 3 ise resimin 3 derinlikli olmasÄ±ndan kaynaklanÄ±r. DoÄŸrudan iletme kÄ±smÄ±nda, her bir filtreyi input resmi Ã¼zerinde kaydÄ±rÄ±yoruz, bu kaydÄ±rma sÄ±rasÄ±nda resimlerde pixeller ile filtredeki sayÄ±lar ile dot product alÄ±yoruz. Filtreyi kaydÄ±rma iÅŸlemi sÄ±rasÄ±nda 2 boyutlu bir aktivite haritasÄ± oluÅŸturuyoruz. Bu harita ise bize her bir pozisyondaki cevabÄ± veriyor. Sinir aÄŸÄ±, bu filtreler ne zaman belirli bir gÃ¶rsel Ã¶zellik, Ã¶rnek olarak kenar, gÃ¶rdÃ¼ÄŸÃ¼ zaman Ã¶ÄŸrenecek. Her bir filtrenin oluÅŸturduÄŸu haritalarÄ± Ã¼st Ã¼ste sÄ±kÄ±ÅŸtÄ±rÄ±p bunu bir sonraki katmana iletiyoruz. BOYUTSAL AYARLAMA Her bir nÃ¶ronun nasÄ±l baÄŸlÄ± olduÄŸunu anlattÄ±k ancak output hacminde kaÃ§ tane nÃ¶ron olduÄŸundan bahsetmedik. Output hacmini belirleyen 3 ayrÄ± parametre vardÄ±r. DERÄ°NLÄ°K: Bu parametre kaÃ§ tane nÃ¶ron kullandÄ±ÄŸÄ±nÄ±za iÅŸaret eder. Ã–rnek olarak ilk convolutional katman input olarak resmi alÄ±rken, farklÄ± nÃ¶ronlar bu resimde farklÄ± detaylarÄ± fark edebilir. STRIDE (KAYDIRMA ADIMI): Bu parametre ise filtreyi kaÃ§ pixel kaydÄ±racaÄŸÄ±mÄ±za iÅŸaret eder. EÄŸer stride bir ise, filtreleri bir pixel kaydÄ±racaÄŸÄ±mÄ±z anlamÄ±na gelir. ZERO-PADDING: (SIFIRLARLA DOLDURMA) BazÄ± durumlarda inputun etrafÄ±nÄ± sÄ±fÄ±rlarla doldurmak uygun olmaktadÄ±r. Bu iÅŸlemin gÃ¼zel bir tarafÄ± ise, bize output boyutunu kontrol altÄ±nda tutma olanaÄŸÄ± vermesidir. Ã–rnek olarak daha yÃ¼ksek boyutlu outputlar istersek, inputu filtre boyutu kadar sÄ±fÄ±rlarla doldurup, bir sonraki katmana aktarÄ±lacak outputun boyutunu, ÅŸuanki katmandaki input boyutuna eÅŸit tutabiliriz. Output hacminin boyutunu ÅŸu ÅŸekilde hesaplayabiliriz. Input Boyutu = $W$ Convolutional katman nÃ¶ronlarÄ± filtre boyutu = $F$ Stride = $S$ Zero-Padding = $P$ Output hacmi boyutu formÃ¼lÃ¼ = $(W - F + 2P) / S + 1$. Ã–rnek olarak eÄŸer elimizde $10 * 10$ boyutlu bir resim varsa ve bizim filtre boyutumuz $3 * 3$, stride = $1$ ve padding = $0$ ise $$ Output Boyutu = (10 - 3 + 2*0) / 1 + 1 = 8 * 8 $$ Åžimdi bu boyut tek bir nÃ¶rondan Ã§Ä±kan sonuÃ§. EÄŸer elimizde $n$ tane nÃ¶ron varsa, bu katmandan Ã§Ä±kan sonucun boyutu $8 * 8 * n$ olacaktÄ±. YukarÄ±daki Ã¶rnekten de gÃ¶rÃ¼leceÄŸi Ã¼zere filtre boyutumuz $3 3$, bundan dolayÄ± resimde de (33) lÃ¼k alanlar alÄ±p, bu aldÄ±ÄŸÄ±mÄ±z alanla filtre arasÄ±nda bir dot product iÅŸlemi uyguluyoruz. Peki resimdeki $31$ sayÄ±sÄ±na nasÄ±l ulaÅŸtÄ±k onu inceleyelim. $$ (1 * 1) + (0 * 2) + (1 * 3) + (0 * 4) + (1 * 5) + (1 * 6) + (1 * 7) + (0 * 8) + (1 * 9) $$ $$ 1 + 3 + 5 + 6 + 7 + 9 = 31 $$ Ã–zetlemek gerekirse Conv layer $W_1 * H_1 * D_1$ boyutlarÄ±nda input alÄ±r 4 parametreye ihtiyaÃ§ duyar Filtre sayÄ±sÄ± $K$ Filtrenin boyutlarÄ± $F$ Stride $S$ Zero padding sayÄ±sÄ± $P$ $W_2 * H_2 * D_2$ boyutlarÄ±nda output Ã¼retir. $W_2 = (W_1 - F + 2P)/S + 1)$ $H_2 = (H_1 - F + 2P)/S + 1$ $D_2 = K$ ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:3:0","tags":["numpy","pytorch","cnn"],"title":"EvriÅŸimsel Sinir AÄŸlarÄ±  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"PYTHON Ä°LE UFAK BÄ°R GÃ–STERÄ°M Åžimdi tensorflow ile basit bir gÃ¶sterim yapÄ±p bu boyutlarÄ± daha iyi anlayalÄ±m. import tensorflow as tf # The inputs are 28x28 RGB images with `channels_last` and the batch # size is 4. input_shape = (4, 28, 28, 3) x = tf.random.normal(input_shape) y = tf.keras.layers.Conv2D( 2, 3, activation='relu', input_shape=input_shape[1:])(x) print(y.shape) (4, 26 , 26, 2) Burada olan iÅŸlemler ÅŸu ÅŸekildedir input_shape Conv layerâ€™a verilecek olan inputun boyutlarÄ±dÄ±r. (4, 28, 28, 3) ÅŸu anlama gelmektedir. Bizim elimizde 4 adet resim var, ve bu resimlerin boyutlarÄ± (28, 28, 3)tÃ¼r. Conv2D â€™ e verilen parametreler ise ÅŸu ÅŸekildedir. Ä°lk verilen parametre 2 kaÃ§ adet filtre kullanacaÄŸÄ±mÄ±zÄ± gÃ¶sterir. Ä°kinci parametre 3 ise filtre boyutunu vermektedir. Yani filtre boyutumuz $(3, 3)$ olacaktÄ±r. Åžimdi burada oluÅŸan outputun nasÄ±l oluÅŸtuÄŸuna bakalÄ±m. YukarÄ±da Ã¶zetlediÄŸimiz gibi her ÅŸeyi tek tek yazalÄ±m Input boyutlarÄ± $W_1 * H_1 * D_1$ ÅŸeklindeydi. Bundan dolayÄ± $W_1 = 28$ $H_1 = 28$ $D_1 = 3$ Daha sonra filtre sayÄ±mÄ±z $K = 2$, filtre boyutumuz ise $F = 3$, stride ise default olarak $S = 1$dir. Padding ise default olarak $P = 0$dÄ±r. O zaman ÅŸimdi output boyutlarÄ±mÄ±zÄ± $(W_2 * H_2 * D_2)$ hesaplayabiliriz. $W_2 = (28 - 3 + 2 * 0) / 1 + 1 = 25 + 1 = 26$ $H_2 = (28 - 3 + 2 * 0) / 1 + 1 = 25 + 1 = 26$ $D_2 = K = 2$ Her bir resim iÃ§in oluÅŸturulan output boyutlarÄ± $(26, 26, 2)$. Elimizde 4 adet resim var ve bundan dolayÄ± Ã§Ä±kan output boyutu $(4, 26, 26, 2)$ ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:3:1","tags":["numpy","pytorch","cnn"],"title":"EvriÅŸimsel Sinir AÄŸlarÄ±  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"POOLING LAYER Convolutional sinir aÄŸlarÄ±nda convolutional katmanlar arasÄ±na Pooling katmanlarÄ± eklemek Ã§ok yaygÄ±ndÄ±r. Pooling katmanÄ±nÄ±n gÃ¶revi verilen inputun boyutlarÄ±nÄ± kademeleri olarak azaltarak parametrelerin ve aÄŸÄ±n iÅŸlem yÃ¼kÃ¼nÃ¼n azaltÄ±masÄ±nÄ± saÄŸlamak. Bu ÅŸekilde aÅŸÄ±rÄ± uyma (overfitting) kontol altÄ±na alÄ±nmÄ±ÅŸ olur. Pooling katmanÄ±, baÄŸÄ±msÄ±z olarak Ã§alÄ±ÅŸÄ±r ve her bir inputu Max operasyonu kullanarak boyutlarÄ±nÄ± azaltÄ±r. En yaygÄ±n Pooling katmanÄ±, filtreleri $(2 * 2)$ boyutlarÄ±nda olan ve inputu hem boydan ve hem enden ikiye bÃ¶lenlerdir. Her bir Max operasyonu input olarak $(2 * 2)$ lik bir bÃ¶lÃ¼m alacak ve bu 4 sayÄ±dan en bÃ¼yÃ¼ÄŸÃ¼nÃ¼ gÃ¶nderecektir. Ã–zetlemek gerekirse, Pooling katmanÄ± input olarak $W_1 * H_1 * D_1$ boyutlarÄ±nÄ± kabul eder. Ä°ki parametreye ihtiyaÃ§ duyar Boyut $F$ Stride $S$ BoyutlarÄ± $W_2 * H_2 * D_2$ olan output Ã§Ä±karÄ±r. $W_2 = (W_1 - F)/S + 1$ $H_2 = (H_! - F)/S + 1$ $D_2 = D1$ Resimde de gÃ¶rÃ¼leceÄŸi Ã¼zere her bir $(2 * 2)$ lik bÃ¶lÃ¼mden en bÃ¼yÃ¼k sayÄ±lar alÄ±nÄ±p yeni bir Ã¶rnek elde ediliyor. Åžimdi bunu Python ile kodlamaya Ã§alÄ±ÅŸalÄ±m. ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:4:0","tags":["numpy","pytorch","cnn"],"title":"EvriÅŸimsel Sinir AÄŸlarÄ±  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"Pooling Layer Python Ä°le Ä°mplementasyonu Bu layerÄ± hem sÄ±fÄ±rdan hem de kÃ¼tÃ¼phane kullanarak kodlayabiliriz. Ã–nce kÃ¼tÃ¼phane kullanarak gÃ¶sterelim. x = tf.constant([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]) x = tf.reshape(x, [1, 3, 3, 1]) max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid') max_pool_2d(x) Bu koddan Ã§Ä±kacak output ise \u003ctf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy= array([[[[5.], [6.]], [[8.], [9.]]]], dtype=float32)\u003e Ã‡Ä±kan sonucun nasÄ±l Ã§Ä±ktÄ±ÄŸÄ±nÄ± bence rahatlÄ±kla yapabilirsiniz. Åžimdi kendimiz sÄ±fÄ±rdan bu layerÄ± basit bir ÅŸekilde implement edelim. import numpy as np def pool2d(X, pool_size, mode='max'): p_h, p_w = pool_size #pool size Ä± al Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)) #Outputu oluÅŸtur for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] = X[i: i + p_h, j: j + p_w].max() #Her bir pool size kadar pixelin max'Ä±nÄ± al return Y Åžimdi kodumuzu yukarÄ±da yazdÄ±ÄŸÄ±mÄ±z x arrayi ile test edersek, yine aynÄ± sonucun Ã§Ä±kacaÄŸÄ±nÄ± gÃ¶receÄŸiz. Bu yazÄ±mÄ±zda konuÅŸulacaklar bu kadar. BeÄŸendiyseniz paylaÅŸmayÄ± unutmayÄ±n. ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:4:1","tags":["numpy","pytorch","cnn"],"title":"EvriÅŸimsel Sinir AÄŸlarÄ±  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"REFERENCES https://anhreynolds.com/blogs/cnn.html https://cs231n.github.io/convolutional-networks/ https://cezannec.github.io/Convolutional_Neural_Networks/ https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D https://medium.com/ai-in-plain-english/pooling-layer-beginner-to-intermediate-fa0dbdce80eb ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:5:0","tags":["numpy","pytorch","cnn"],"title":"EvriÅŸimsel Sinir AÄŸlarÄ±  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"Makine Ã¶ÄŸrenmesinde modellerin veriyi gÃ¶rme ÅŸekli biz insanlardan farklÄ±dÄ±r. Biz kolayca KÄ±rmÄ±zÄ± arabayÄ± gÃ¶rÃ¼yorum. cÃ¼mlesini anlayabilirken, model bu kelimeleri anlayacak vektÃ¶rlere ihtiyaÃ§ duyar. Bu vektÃ¶rlere word embeddings denir. ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:0:0","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden NasÄ±l Ã–ÄŸrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"WORD VECTORLERÄ° NASIL Ã‡ALIÅžIR - Tablodan Bak Her kelimemiz iÃ§in belirli bir boyutta vektÃ¶rÃ¼mÃ¼z olacak ve bu vektÃ¶rleri kelimeyi isteyerek alabiliriz. Buna key-value pair Ã¶rneÄŸi verilebilir. key: kelime value: vektÃ¶r Bundan dolayÄ± herhangi bir kelimenin vektÃ¶rÃ¼ne bakmak iÃ§in dictionaryden kelimeyi istediÄŸimiz zaman vektÃ¶re ulaÅŸmÄ±ÅŸ olacaÄŸÄ±z. ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:1:0","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden NasÄ±l Ã–ÄŸrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"Word2Vec: Tahmin BazlÄ± bir Metod Ana amacÄ±mÄ±z kelimelerden, kelime vektÃ¶rleri oluÅŸturmak. Word2Vec parametreli word vektÃ¶rleri olan bir modeldir. Bu parametreler itaretive yÃ¶ntemle, objective function(kÃ¼Ã§Ã¼ltmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z fonksiyon) kullanarak optimize edilir. Peki bunu nasÄ±l yapacaÄŸÄ±z. Unutmadan: amaÃ§ : her bir vektÃ¶rÃ¼ kelimenin iÃ§eriÄŸini bilecek ÅŸekilde kodlamak nasÄ±l yapÄ±lacak: vektÃ¶rleri kelimelerden olasÄ± iÃ§erik tahmin edecek ÅŸekilde eÄŸitmek. Word2Vec iterative bir metottur. Ana fikirleri kÄ±saca ÅŸÃ¶yledir. bÃ¼yÃ¼k bir text corpusu alÄ±r texti, belirli bir sliding window(kayan pencere) kullanarak, her seferinde bir kelime ilerleyecek ÅŸekilde ilerlemek. Her bir adÄ±mda, bir tane central word (merkezi kelime) ve context words(iÃ§erik kelimeleri) -\u003e penceredeki diÄŸer kelimeler. merkezi kelime iÃ§in, iÃ§erik kelimelerinin olasÄ±lÄ±klarÄ±nÄ± hesapla. vektÃ¶rleri olasÄ±lÄ±klarÄ± artÄ±racak ÅŸekilde ayarla Resimde de gÃ¶rÃ¼leceÄŸi Ã¼zere her seferinde arkasÄ± mavi olan merkezi kelime ve diÄŸerleri de iÃ§erik kelimeleri. ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:2:0","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden NasÄ±l Ã–ÄŸrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"Objective Function (AmaÃ§ Fonksiyonu) Text corpusundaki her bir $ t = 1, â€¦ , T$ pozisyon iÃ§in, Word2Vec merkezi kelimesi $w_{t}$ verilmiÅŸ m-boyutlu penceredeki iÃ§erik kelimelerini tahmin eder. $$ Likelihood = L(\\theta) = \\prod_{t=1}^{T} \\prod_{-m \\leq j \\leq m, j \\neq 0} P(w_{t + j} \\mid w_t, \\theta) $$ Bu fonksiyonda $\\theta$ optimize edilecek bÃ¼tÃ¼n parametrelerdir. AmaÃ§ ve KayÄ±p Fonksiyonu $J(\\theta) ise ortalama negatif log olabilirlik fonksiyonudur. (Negative log-likelihood) $$ J(\\theta) = -\\frac{1}{T} \\log L(\\theta) = -\\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-m \\leq j \\leq m, j \\neq 0 } \\log P(w_{t + j} \\mid w_t, \\theta) $$ Bu formÃ¼ldeki parÃ§alara ayÄ±ralÄ±m. $\\sum_{t=1}^{T}$ Bu kÄ±sÄ±m bÃ¼tÃ¼n text Ã¼zerinde gezinir. $\\prod_{-m \\leq j \\leq m, y \\neq 0}$ bu ise kayma penceresini(sliding window) temsil eder. $\\log P(w_{t + j} \\mid w_t, \\theta)$ : bu ise merkezi kelimesi verilen iÃ§eriÄŸin olasÄ±lÄ±ÄŸÄ±nÄ± hesaplar. Peki asÄ±l sorulmasÄ± gereken soru bu olasÄ±lÄ±klar nasÄ±l hesaplanacak? ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:2:1","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden NasÄ±l Ã–ÄŸrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"OlasÄ±lÄ±klarÄ± NasÄ±l HesaplayacaÄŸÄ±z? Hesaplamak istediÄŸimiz olasÄ±lÄ±k $$ P(w_{t + j} \\mid w_t, \\theta) $$ Verilen her kelime $w$ iÃ§in, iki adet vektÃ¶rÃ¼mÃ¼z var. $v_w$ -\u003e kelimenin merkezi kelime (central word) olduÄŸu zaman $u_w$ -\u003e kelimenin iÃ§erik kelime (context word) olduÄŸu zaman VektÃ¶rler train edildikten sonra, genel olarak iÃ§erik vektÃ¶rlerini $u_w$ atar ve sadece merkezi kelime vektÃ¶rlerini $v_w$ kullanÄ±lÄ±r. Bundan sonra verilen merkezi kelime $c$ ve iÃ§erik kelimesi $o$ kelimeleri iÃ§in olasÄ±lÄ±k: $$ P(o \\mid c) = \\frac{exp(u_{o}^{T})}{\\sum_{v \\in V} exp(u_{w}^{T} v_c)} $$ NOT: Bu bir softmax fonksiyonudur. Softmax ile alakalÄ± yazÄ±ma bu yazÄ±mdan ulaÅŸabilirsiniz. Åžimdi bu olasÄ±lÄ±klarÄ± nasÄ±l hesaplayacaÄŸÄ±mÄ±z gÃ¶rdÃ¼ÄŸÃ¼mÃ¼ze gÃ¶re, vektÃ¶rleri nasÄ±l eÄŸiteceÄŸimizi gÃ¶relim. ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:2:2","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden NasÄ±l Ã–ÄŸrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"NASIL EÄžÄ°TÄ°LÄ°R KÄ±saca bu sorunun cevabÄ± Gradient Descent ile her seferinde bir kelime alarak gerÃ§ekleÅŸir. Parametrelerimiz $\\theta$ bÃ¼tÃ¼n kelimelerin $v_w$ ve $u_w$ vektÃ¶rleri olduÄŸunu hatÄ±rlayalÄ±m. Bu vektÃ¶rleri gradient descent kullanarak optimize edeceÄŸiz. $$ \\theta^{new} = \\theta^{old} - \\alpha \\nabla_{\\theta} J(\\theta) $$ Bu parametre gÃ¼ncellemerini her seferinde bir kelime kullanarak yapÄ±yoruz. Her bir gÃ¼ncelleme bir merkez kelime ve iÃ§erik kelimesi ikilileriyle yapÄ±lÄ±r. Tekrardan kayÄ±p fonksiyonuna bakalÄ±m. $$ J(\\theta) = -\\frac{1}{T} \\log L(\\theta) = -\\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-m \\leq j \\leq m, j \\neq 0 } \\log P(w_{t + j} \\mid w_t, \\theta) $$ Merkezi kelime $w_t$ iÃ§in, kayÄ±p fonksiyonu ayrÄ± bir terimi her bir iÃ§erik kelimesi (w_{t + j}) (sliding window iÃ§erisindeki) (J_{t,j}(\\theta) = -\\log P(w_{t + j} \\mid w_t, \\theta\\ Bir Ã¶rnek vererek bu durumu daha iyi anlayalÄ±m. Åžu cÃ¼mleyi ele alalÄ±m. BugÃ¼n bahÃ§ede bir top gÃ¶rdÃ¼m. YeÅŸil renkli bir kelimesi burada bizim merkezi kelimemizdir. Her seferinde bir kelimeye bakacaÄŸÄ±mÄ±z iÃ§in, bir tane iÃ§erik kelimesi seÃ§eceÄŸiz. Ã–rnek olarak top kelimesini ele alalÄ±m. Bundan sonra bu iki kelime iÃ§in kayÄ±p fonksiyonu Buradaki $V$ kÃ¼mesi sliding windowu kapsayan kelimelerden oluÅŸur. Loss (kayÄ±p) fonksiyonumuzu aldÄ±ÄŸÄ±ma gÃ¶re, ÅŸimdi vektÃ¶rler Ã¼zerinde gÃ¼ncelleme yapalÄ±m. Burada hangi parameterlerin olduÄŸuna gÃ¶z atalÄ±m. merkezi kelime vektÃ¶rlerinden sadece $v_{bir}$ iÃ§erik kelime vektÃ¶rlerinden ise sliding window iÃ§erisindeki bÃ¼tÃ¼n kelimeler $u_w \\forall w \\in V$ Åžuanki adÄ±mda sadece bu parametreler gÃ¼ncellenecek. $$ v_{bir} := v_{bir} - \\alpha \\frac{\\partial J_{t, j}(\\theta)}{\\partial v_{bir}} $$ $$ u_w = u_w - \\alpha \\frac{\\partial J_{t, j}(\\theta)}{\\partial u_{w}} \\forall w \\in V $$ KayÄ±p fonksiyonunu azaltacak ÅŸekilde yaptÄ±ÄŸÄ±mÄ±z her bir gÃ¼ncelleme, parametreler arasÄ±ndaki benzerliÄŸi $v_{bir} \\hspace{1mm} ve \\hspace{1mm} u_{top}$ dot productâ€™Ä±nÄ± artÄ±rÄ±yor ve aynÄ± zamanda diÄŸer her bir diÄŸer $u_w$ ile $v_{bir}$ arasÄ±ndaki benzerliÄŸi de azaltÄ±yor. Bu biraz garip gelebilir ancak neden bir kelimesinin top kelimesinden hariÃ§ diÄŸer kelimelerle benzerliÄŸini azaltmaya Ã§alÄ±ÅŸÄ±yoruz. DiÄŸerleri de mantÄ±klÄ±, iÃ§erik verecek kelimeler olabilir. Ancak bu bir sorun deÄŸil! Biz bu gÃ¼ncellemeyi her kelime iÃ§in tek tek yaptÄ±ÄŸÄ±mÄ±zdan dolayÄ±, yani her kelime bir kez merkezi kelime olacak, vektÃ¶rler Ã¼zerindeki bÃ¼tÃ¼n gÃ¼ncellemelerin ortalamasÄ± metin iÃ§eriÄŸininin daÄŸÄ±lÄ±mÄ±nÄ± Ã¶ÄŸrenecektir. Bu yazÄ±da partial derivative kÄ±sÄ±mlarÄ±na girilmemiÅŸtir. Ancak ben genel olarak Word2Vec modelinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlatabildiÄŸimi dÃ¼ÅŸÃ¼nÃ¼yorum. EÄŸer denemek isterseniz partial derivative kÄ±sÄ±mlarÄ±nÄ± kendiniz deneyebilirsiniz. DiÄŸer yazÄ±larda gÃ¶rÃ¼ÅŸmek Ã¼zere. EÄŸer yazÄ±yÄ± beÄŸendiyseniz paylaÅŸmayÄ± unutmayÄ±n ki diÄŸer insanlar da yararlansÄ±n. ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:2:3","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden NasÄ±l Ã–ÄŸrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"REFERENCES https://lena-voita.github.io/nlp_course/word_embeddings.html ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:3:0","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden NasÄ±l Ã–ÄŸrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"Problem TanÄ±mÄ± Knapsack problemi bilgisayar biliminde Ã§ok meÅŸhur bir problemdir. Bu problemdeki amaÃ§ verilen aÄŸÄ±rlÄ±k ve deÄŸerlerle en fazla deÄŸer toplayacak ÅŸekilde verilen aÄŸÄ±rlÄ±k limitini aÅŸmadan hangi itemlerin seÃ§ileceÄŸidir. Knapscak problemi bir yÃ¼zyÄ±ldan fazla bir sÃ¼redir, 1897 e kadar Ã§alÄ±ÅŸmalar vardÄ±r. Ä°smini matematikÃ§i Tobias Dantzig adlÄ± matematikÃ§inin eski Ã§alÄ±ÅŸmalarÄ±ndan alÄ±r. Buradaki problemimiz iÃ§in birden fazla yÃ¶ntem vardÄ±r. Biz dinamik programlama ile bu problemin nasÄ±l hallediliÄŸine bakacaÄŸÄ±z. Åžimdi problemdeki input ve istenilen outputa bakalÄ±m ","date":"2020-11-18","objectID":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/:1:0","tags":["algoritmalar","python"],"title":"Dinamik Programlama ile Knapsack Problemi NasÄ±l Ã‡Ã¶zÃ¼lÃ¼r","uri":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/"},{"categories":null,"content":"INPUT Maksimum aÄŸÄ±rlÄ±k limiti W ve elimizdeki paket sayÄ±sÄ± n AÄŸÄ±rlÄ±klarÄ±n bulunduÄŸu w[i] ve buna eÅŸ deÄŸer olan deÄŸer v[i] ","date":"2020-11-18","objectID":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/:1:1","tags":["algoritmalar","python"],"title":"Dinamik Programlama ile Knapsack Problemi NasÄ±l Ã‡Ã¶zÃ¼lÃ¼r","uri":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/"},{"categories":null,"content":"OUTPUT Maksimum deÄŸer Hangi paketlerin alÄ±ndÄ±ÄŸÄ± ","date":"2020-11-18","objectID":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/:1:2","tags":["algoritmalar","python"],"title":"Dinamik Programlama ile Knapsack Problemi NasÄ±l Ã‡Ã¶zÃ¼lÃ¼r","uri":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/"},{"categories":null,"content":"Ä°MPLEMENTASYON Bu problemi analiz ederken algoritmanÄ±n hangi deÄŸerlere baÄŸlÄ± olacaÄŸÄ±nÄ± bulmaktÄ±r. Buradaki algoritmamÄ±z 2 ayrÄ± deÄŸiÅŸkene dayanÄ±r. BunlarÄ±n birincisi kaÃ§ tane paket taÅŸÄ±yacaÄŸÄ±mÄ±z ve elimizde kalan aÄŸÄ±rlÄ±k limiti. Evet algoritmamÄ±zÄ± iki deÄŸiÅŸkene baÄŸlÄ± ÅŸekilde yazacaÄŸÄ±z. Ã–rnek olarak ilk 3 elemanÄ± alarak, j maksimum limitli bir prpblemde optimum deÄŸer kaÃ§tÄ±r. Buradaki ilk 3 eleman, hangi elemanlarÄ± seÃ§eceÄŸimiz deÄŸiÅŸkenine Ã¶rnektir. J limit ise ne kadar aÄŸÄ±rlÄ±k limitimizin olduÄŸudur. Bundan dolayÄ± bir matrix oluÅŸturup, her alt problemdeki optimum Ã§Ã¶zÃ¼mÃ¼ yazarsak bu ÅŸekilde istenilen sonuca ulaÅŸabiliriz. Bundan dolayÄ± [n+1][W+1] boyutlarÄ±nda bir matrixte elimizdeki her alt alt problem iÃ§in Ã§Ã¶zÃ¼mleri saklayacaÄŸÄ±z. K[i][j] deki deÄŸer ÅŸu anlama geliyor: Ä°lk i elemanÄ± alarak j aÄŸÄ±rlÄ±k limitli bir problemdeki optimum Ã§Ã¶zÃ¼m nedir. Peki bizim soruda ne isteniyordu? n elemanÄ± kullanarak W limitli bir problemdeki Ã§Ã¶zÃ¼m nedir. Bundan dolayÄ± bizim istediÄŸimiz sonuÃ§ ise matrixin en son elemanÄ± olan K[n][W] dir. Peki asÄ±l soru olan her bu K[i][j] nasÄ±l bulacaÄŸÄ±z. Ã–ncelikle matriximizin ilk satÄ±rÄ±nÄ±n hepsi 0 olacak. Bunun nedeni ise 0 item kullanÄ±rsak elde edebileceÄŸimiz maksimum deÄŸer 0 dÄ±r. DiÄŸer satÄ±rlarda ise durum farklÄ±dÄ±r. Bundan dolayÄ± her $1\\leq i \\leq n$ ve her $0 \\leq j \\leq W$ iÃ§in bir durumu kontrol etmemiz gerekiyor. Kontrol etmemiz gereken deÄŸiÅŸken ÅŸuanki durumda yani item i aÄŸÄ±rlÄ±ÄŸÄ± ÅŸuanki j (aÄŸÄ±rlÄ±k limiti) bÃ¼yÃ¼k mÃ¼. Ã‡Ã¼nkÃ¼ eÄŸer bizim ÅŸuanki itemimizin aÄŸÄ±rlÄ±ÄŸÄ± aÄŸÄ±rlÄ±k limitimizden bÃ¼yÃ¼kse o itemi basitÃ§e alamayÄ±z. Bu itemi alamadÄ±ÄŸÄ±mÄ±z iÃ§in K[i][j] == K[i-1][j] olacak. Nedeni ise bu itemi seÃ§mediÄŸimiz iÃ§in o durumdaki en optimum Ã§Ã¶zÃ¼m, o iteme kadar olanki en optimum Ã§Ã¶zÃ¼me eÅŸittir. if w[i] \u003e j: K[i][j] = K[i-1][j] EÄŸer bu durum gerÃ§ekleÅŸme ise elimizde iki seÃ§enek var. Birinci seÃ§enek ÅŸuanki itemi almamak. Bu durum yukarda bahsettiÄŸimizin aynÄ±sÄ± yani K[i][j] = K[i-1][j] Ä°kinci seÃ§enek ise bu itemi almak. Bu durumda elimizde olan optimum Ã§Ã¶zÃ¼m ÅŸu anlama geliyor. Åžuanki itemin deÄŸeri v[i] Bu itemi aldÄ±ÄŸÄ±mÄ±z iÃ§in geriye kalan j - w[i] aÄŸÄ±rlÄ±k limitli ve ilk i-1 item arasÄ±ndaki optimum Ã§Ã¶zÃ¼m, yani K[i-1][j-w[i]] Bu durumda ise optimum Ã§Ã¶zÃ¼m ÅŸu anlama geliyor. K[i][j] = v[i] + K[i-1][j - w[i]] Elimizde iki seÃ§enek var. Peki hangisini seÃ§eceÄŸiz. Ã‡ok basit, en yÃ¼ksek olan hangisi ise bunu seÃ§eceÄŸiz. Yani K[i][j] = max(K[i])[j], v[i] + K[i-1][j - w[i]]) EÄŸer bir basit bir kod yazmak istersek for j in range(W+1) K[0][j] = 0 //Yani Ä°lk satÄ±rÄ± 0 yap for i in range(1, n+1) for j in range(0, W + 1) if w[i] \u003e j // EÄŸer ÅŸuanki aÄŸÄ±rlÄ±ÄŸÄ±mÄ±z ÅŸuanki limitten bÃ¼yÃ¼kse K[i][j] = 0 else K[i][j] = max(K[i-1][j], v[i] + K[i-1][j - w[i]]) Bizim Ã§Ã¶zÃ¼mÃ¼mÃ¼z ise K[n][W] deki deÄŸerdir. BackTracking kÄ±smÄ±nÄ± sonra ekleyeceÄŸim. ","date":"2020-11-18","objectID":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/:1:3","tags":["algoritmalar","python"],"title":"Dinamik Programlama ile Knapsack Problemi NasÄ±l Ã‡Ã¶zÃ¼lÃ¼r","uri":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/"},{"categories":null,"content":"NUMPY import numpy as np ","date":"2020-11-09","objectID":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/:0:0","tags":["numpy"],"title":"Kapsamli Åžekilde Python Numpy Ã–ÄŸrenelim","uri":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/"},{"categories":null,"content":"NUMPY ARRAY Pythonâ€™daki listelere Ã§ok benzerdir. Numoy arrayleri sadece aynÄ± veri tÃ¼rÃ¼ne sahip listeleri barÄ±ndÄ±rabilir. Arrayler daha az hafÄ±zada yer kaplar. Array oluÅŸturmak iÃ§in yapmamÄ±z gereken a = np.array([1, 2, 3, 4]) type(a) numpy.ndarray Buna ek olarak da, arraylere tuple ekleyebiliriz. Ã–rnek olarak a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) print(\"Birinci eleman {}\".format(a[0])) print(\"Birinci elemanÄ±n birinci elemanÄ± {}\".format(a[0][0])) Birinci eleman [1 2 3] Birinci elemanÄ±n birinci elemanÄ± 1 ","date":"2020-11-09","objectID":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/:1:0","tags":["numpy"],"title":"Kapsamli Åžekilde Python Numpy Ã–ÄŸrenelim","uri":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/"},{"categories":null,"content":"ARRAY Ã–ZELLÄ°KLERÄ° Arrayin boyutlarÄ±nÄ± Ã¶ÄŸrenmek iÃ§in yapmamÄ±z gereken **array.shape** yazmak olacaktÄ±r Arrayin rankini Ã¶ÄŸrenmek iÃ§in yapmamÄ±z gereken **array.ndim** yazmak olacaktÄ±r Arrayin boyutunu Ã¶ÄŸrenmek iÃ§in yapmamÄ±z gereken **array.size** yazmak olacaktÄ±r Arrayin barÄ±ndÄ±rdÄ±ÄŸÄ± veri tipini Ã¶ÄŸrenmek iÃ§in yapmamÄ±z gereken **array.dtype** yazmak olacaktÄ±r print(\"Arrayin boyutlarÄ± {}\".format(a.shape)) print(\"Arrayin ranki {}\".format(a.ndim)) print(\"Arraydeki eleman sayÄ±sÄ± {}\".format(a.size)) print(\"Arrayin veri tipi {}\".format(a.dtype)) Arrayin boyutlarÄ± (3, 3) Arrayin ranki 2 Arraydeki eleman sayÄ±sÄ± 9 Arrayin veri tipi int64 ","date":"2020-11-09","objectID":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/:1:1","tags":["numpy"],"title":"Kapsamli Åžekilde Python Numpy Ã–ÄŸrenelim","uri":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/"},{"categories":null,"content":"ARRAY FONKSÄ°YONLARI Arraylerden SÄ±fÄ±r OluÅŸturmak iÃ§in yapmamÄ±z gereken shape yerine istediÄŸimiz boyutlarÄ± girmek. Numpy bizim iÃ§in gerekli arrayi oluÅŸturacaktÄ±r. shape = (2, 2) zeros = np.zeros(shape) zeros array([[0., 0.], [0., 0.]]) Arraylerden Bir OluÅŸturmak iÃ§in yapmamÄ±z gereken shape yerine istediÄŸimiz boyutlarÄ± girmek. Numpy bizim iÃ§in gerekli arrayi oluÅŸturacaktÄ±r. shape = (2, 2) ones = np.ones(shape) ones array([[1., 1.], [1., 1.]]) Ä°stediÄŸimiz bir deÄŸerle istediÄŸimiz boyutta bir array oluÅŸturmak iÃ§in ise np.full kullanÄ±yoruz. a = np.full((6,5), 29) print(a) [[29 29 29 29 29] [29 29 29 29 29] [29 29 29 29 29] [29 29 29 29 29] [29 29 29 29 29] [29 29 29 29 29]] Ä°dentity Matrix (Birim Matris) oluÅŸturmak iÃ§in ise np.eyeyazmak olacaktÄ±r. np.eye(3) array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) EÄŸer belirli bir aralÄ±kta belirli sayÄ±larla artan bir array oluÅŸturmak istiyorsak np.arange kullanmalÄ±yÄ±z. rangearray = np.arange(10,100,10, dtype=float) rangearray array([10., 20., 30., 40., 50., 60., 70., 80., 90.]) EÄŸer yine belirli bir aralÄ±kta deÄŸerler oluÅŸturmak istiyorsak ve kaÃ§ tane oluÅŸturacaÄŸÄ±mÄ±zÄ± biliyorsak np.linspace kullanabiliriz. linarray = np.linspace(10, 100, 5) linarray array([ 10. , 32.5, 55. , 77.5, 100. ]) np.arange de 100 dahil deÄŸildi. Ancak np.linspace de dahil. Bunu da gÃ¶zden kaÃ§Ä±rmamak gerekir. Åžimdi ise Ã§ok Ã¶nemli bir fonksiyon olan np.reshape fonksiyonuna bakalÄ±m. Bu fonksiyon ile arraylerimizi istediÄŸimiz formata Ã§evirme ÅŸansÄ±mÄ±z var. array = np.arange(20) print(\"Ã–nceki hali : \\n\", array) new_array = np.reshape(array, (4,5)) print(\"Sonraki hali : \\n\", new_array) Ã–nceki hali : [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19] Sonraki hali : [[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14] [15 16 17 18 19]] ","date":"2020-11-09","objectID":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/:1:2","tags":["numpy"],"title":"Kapsamli Åžekilde Python Numpy Ã–ÄŸrenelim","uri":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/"},{"categories":null,"content":"ARRAY INDEKSLEME (ARRAY INDEXING) Numpy arrayleri indekslemede Ã§ok kolaylÄ±k saÄŸlÄ±yor. Bir Boyutlu Array a1 = np.array([1, 3, 4, 5, 2, 10]) a1[0] 1 a1[4] 2 a1[-1] 10 a1[-3] 5 Ã‡OK BOYUTLU ARRAY a2 = np.array([[3, 4, 5, 6], [1, 3, 7, 2], [8, 4, 5, 10], [12, 124, 125, 126]]) a2[0] array([3, 4, 5, 6]) a2[0, 0] 3 a2[2, -1] # 2.indexin son elemanÄ± 10 a2[2, 0] = 100 # 2.elemanÄ±n 0.elemanÄ±nÄ± 100 yap a2 array([[ 3, 4, 5, 6], [ 1, 3, 7, 2], [100, 4, 5, 10], [ 12, 124, 125, 126]]) a2[[0, 0, 2, 1]] # 0.index, 0.index, 2.index, 1.index array([[ 3, 4, 5, 6], [ 3, 4, 5, 6], [100, 4, 5, 10], [ 1, 3, 7, 2]]) a2[:2, ::2] # 2.satÄ±ra kadar 0 ile 2. indexler array([[3, 5], [1, 7]]) a2[::-1, ::-1] # Arrayi ters Ã§evir array([[126, 125, 124, 12], [ 10, 5, 4, 100], [ 2, 7, 3, 1], [ 6, 5, 4, 3]]) a2[:, 0] # Ä°lk sutÃ¼n array([ 3, 1, 100, 12]) a2[0, :] # Ä°lk satÄ±r array([3, 4, 5, 6]) I will ad other features to see how it is going ","date":"2020-11-09","objectID":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/:1:3","tags":["numpy"],"title":"Kapsamli Åžekilde Python Numpy Ã–ÄŸrenelim","uri":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/"},{"categories":null,"content":"Merhaba bu yazÄ±mÄ±zda Makine Ã–ÄŸrenmesinde meÅŸhur bir algoritma olan Knn algoritmasÄ±nÄ± sÄ±fÄ±rdan yazacaÄŸÄ±z. Tabii ki hazÄ±r bir sÃ¼rÃ¼ kÃ¼tÃ¼phane var ancak sÄ±fÄ±rdan algoritmayÄ± yazabilmek bize algoritmanÄ±n nasÄ±l Ã§alÄ±ÅŸacaÄŸÄ±nÄ± gÃ¶sterecektir. BÃ¶ylece Knn algoritmasÄ± bir tahmin yaparken nasÄ±l yapÄ±yor olayÄ±n arkasÄ±nda neler dÃ¶nÃ¼yor bunlarÄ± anlayabiliyor olacaÄŸÄ±z. ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:0:0","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"K-Nearest Neighbour Nedir Ã–ncelikle ÅŸunu bilmek gerekir ki K-Nearest-Neighbour adÄ±ndan da anlaÅŸÄ±lacaÄŸÄ± Ã¼zere en yakÄ±n k komÅŸu noktalara bakÄ±p en Ã§ok hangi label varsa o labelÄ± tahmin(prediction) olarak verir. Peki bu yakÄ±nlÄ±k uzaklÄ±k iliÅŸkisi nasÄ±l kurulur Ã¶nce ona bakalÄ±m. UzaklÄ±ÄŸÄ± Ã¶lÃ§ebilmek iÃ§in belli baÅŸlÄ± algoritmalar vardÄ±r. Bunlardan biri eucledian diÄŸeri de manhattan uzaklÄ±ÄŸÄ±dÄ±r. ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:1:0","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"Eucledian UzaklÄ±ÄŸÄ± Manhattan uzaklÄ±ÄŸÄ±nda aslÄ±nda iki nokta arasÄ±nda uzaklÄ±ÄŸÄ± alÄ±rken normal 2 boyutlu denklemde nasÄ±l alÄ±yorsak, bunun n boyutlu formÃ¼le dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ halidir. Ã–rnek olarak $a = (x_1, y_1)$ ve $b = (x_2, y_2)$ olsun. Bu noktalar arasÄ±nda uzaklÄ±ÄŸÄ± bulurken yaptÄ±ÄŸÄ±mÄ±z iÅŸlem $$d(a, b) = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$$ Peki eÄŸer bizim verimiz n boyutlu olursa bu uzaklÄ±k nasÄ±l Ã¶lÃ§Ã¼lecek?. Bu durumda ise uzaklÄ±k $$d(a,b)= \\sum_{i=1}^n (a_i - b_i)^2$$ Bu formulu ise Numpy ile ÅŸu ÅŸekilde yazabiliriz np.sqrt(np.sum(np.square(a - b), axis=1)) ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:1:1","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"Manhattan UzaklÄ±ÄŸÄ± Manhattan uzaklÄ±ÄŸÄ±nda iki nokta arasÄ±ndaki uzaklÄ±k her bir alt noktanÄ±n farkÄ±nÄ±n mutlak deÄŸerlerinin toplamÄ± ile bulunur. Ã–rnek olarak $a = (x_1, y_1)$ ve $b = (x_2, y_2)$ olsun. Bu noktalar arasÄ±nda uzaklÄ±ÄŸÄ± bulurken yaptÄ±ÄŸÄ±mÄ±z iÅŸlem $$d(a, b) = \\lvert x_1 - x_2\\rvert + \\lvert y_1 - y_2 \\rvert$$ Peki eÄŸer bizim verimiz n boyutlu olursa bu uzaklÄ±k nasÄ±l Ã¶lÃ§Ã¼lecek?. Bu durumda ise uzaklÄ±k $$d(a,b)= \\sum_{i=1}^n \\lvert a_i - b_i\\rvert$$ Bu formulu ise Numpy ile ÅŸu ÅŸekilde yazabiliriz np.sum(np.abs(a - b), axis=1) ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:1:2","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"Algoritma AkÄ±ÅŸÄ± KNN algoritmasÄ±nda eÄŸitme (training) iÅŸlemi aslÄ±nda sadece verilen veriyi ezberlemekten ibarettir. Bundan dolayÄ± eÄŸitme kÄ±smÄ±nda bir ÅŸey yapmayacaÄŸÄ±z ancak tahmin etme (prediction) kÄ±smÄ±nda ise asÄ±l Ã¼stteki formuÃ¼lleri kullanÄ±p iÅŸlem yapacaÄŸÄ±z. Bu algoritmayÄ± Python ile Numpy Kullanarak implement edeceÄŸiz. Ã–nceklikle ÅŸu komut ile Numpy kÃ¼tÃ¼phanesini import edelim. import numpy as np Åžimdi Bir tane class tanÄ±mlayalÄ±m. Ã–ncelikle kaÃ§ tane komÅŸu kullanacaÄŸÄ± modelin bir parametresi k olacak. Daha sonra hangi uzaklÄ±k formÃ¼lÃ¼nÃ¼ kullanacaÄŸÄ± da modelin bir parametresi olacak. Hadi baÅŸlayalÄ±m. class KNN: def __init__(self, k=2, uzaklÄ±k=\"eucledian\"): self.k = 2 self.uzaklÄ±k = uzaklÄ±k Ãœstteki kod bloÄŸunda yaptÄ±ÄŸÄ±mÄ±z iÅŸlem aslÄ±nda modelin parametrelerini constructor fonskiyonunda tanÄ±mlamak oldu. Åžimdi modelin eÄŸitme fonksiyonunu yazalÄ±m. class KNN: def __init__(self, k=2, uzaklÄ±k=\"eucledian\"): self.k = 2 self.uzaklÄ±k = uzaklÄ±k def fit(self, X, y): self.X = X self.y = y YukarÄ±da da bahsettiÄŸimiz gibi Knn algoritmasÄ± aslÄ±nda sadece eÄŸitme verisini ezberler. BÃ¼tÃ¼n iÅŸlemler prediction kÄ±smÄ±nda yapÄ±lÄ±r. Bundan dolayÄ± eÄŸitme verisini modelin eÄŸitim seti olarak deÄŸiÅŸtirebiliriz. Åžimdi en Ã¶nemli konu olan prediction kÄ±smÄ±na gelelim. ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:2:0","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"Tahmin Etme (Prediction) KÄ±smÄ± NasÄ±l Olacak? Ã–ncelikle uzaklÄ±klar hesaplanacak Daha sonra en yakÄ±n k tane nokta alÄ±nacak Daha sonra bu en yakÄ±n k noktanÄ±n label sayÄ±larÄ±nÄ± belirleyeceÄŸiz. Yani hangi labeldan kaÃ§ tane olduÄŸunu belirleyeceÄŸiz. Daha sonra en Ã§ok sayÄ±sÄ± olan label bizim tahminimiz olarak Diyelim ki bizim elimizde bir tane a verisi olsun ve eucledian uzaklÄ±k kullanÄ±yor olalÄ±m. Bir nokta iÃ§in nasÄ±l bir iÅŸlem gerekiyor ona bakalÄ±m. #UzaklÄ±k Hesaplama uzaklÄ±klar = np.sqrt(np.sum(np.square(X - a), axis=1)) #En yakÄ±n k noktanÄ±n indexlerini bulalÄ±m en_yakÄ±n_k_index = np.argsort(uzaklÄ±klar)[:k] #Åžimdi bu en yakÄ±n k indexin hangi labellara ait olduÄŸunu bulalÄ±m. en_yakÄ±n_labellar = y[en_yakÄ±n_k_index] #Daha sonra bu en yakÄ±n labellarda her labeldan kaÃ§ tane olduÄŸunu bulalÄ±m labellar, adetler = np.unique(en_yakÄ±n_labellar, return_counts=True) #Daha sonra en Ã§ok hangi labelÄ±n sayÄ±sÄ± var bunu bulalÄ±m max_label_index = np.argmax(adetler) #Daha sonra en Ã§ok sayÄ±sÄ± olan label dÃ¶ndÃ¼relim return labellar[max_label_index] Åžimdi burada bir sÃ¼rÃ¼ numpy fonksiyonu kullandÄ±k, bunlar kafa karÄ±ÅŸtÄ±rmÄ±ÅŸ olabilir. Bundan dolayÄ± bu fonksiyonlar ne iÅŸe yarÄ±yor kÄ±saca anlatayÄ±m. np.argsort(array): Bu fonksiyon parametre olarak aldÄ±ÄŸÄ± arrayi sortlayacak indexleri verir. AslÄ±nda arrayi sortlamaz, ancak hangi indexler arrayi sortlar onu verir. np.unique(array, return_counts=True): Bu fonksiyon ise array iÃ§erisindeki unique elemanlarÄ± dÃ¶nderir. EÄŸer return_counts=True ise o zaman bu unique elemanlardan kaÃ§ tane var onu da gÃ¶sterir. Ã–rnek olarak array = [2, 3, 4, 3, 2, 10, 2] labellar, sayÄ±lar = np.unique(array, return_counts) print(labellar) #(2, 3, 4, 10) print(sayÄ±lar) #(3, 2, 1, 1) Labellar bizim arrayimizde hangi unique label var onlarÄ± dÃ¶nderir. SayÄ±lar ise hangi labeldan kaÃ§ tane var onu dÃ¶nderir. Ã–rnek olarak 2 den 3 tane var. 10â€™dan 1 tane var. np.argmax(array): Bu fonksiyon array iÃ§erisindeki maximum elemanÄ±n indexini verir. Mesela yukarÄ±daki arrayde maximum eleman 10 ve 10â€™un indexi 5 dir. np.argmax() bu 5 indexini dÃ¶nderir. Åžimdi bu bir nokta iÃ§indi. Bunu test verimizde her bir nokta iÃ§in yapalÄ±m. KNN ClassÄ±nÄ±n iÃ§erisinde implement edelim. class KNN: def __init__(self, k=2, uzaklÄ±k=\"eucledian\"): self.k = 2 self.uzaklÄ±k = uzaklÄ±k def fit(self, X, y): self.X = X self.y = y def predict(self, X_test): predictions = [] for point in X_test: if self.uzaklÄ±k == \"eucledian\": uzaklÄ±k = np.sqrt(np.sum(np.square(self.X - point), axis=1)) elif self.uzaklÄ±k == \"manhattan\": uzaklÄ±k = np.sum(np.abs(self.X - point), axis=1) indices = np.argsort(uzaklÄ±k)[:self.k] near_labels = self.y[indices] labels, values = np.unique(near_labels, return_counts=True) max_ind_label = np.argmax(values) prediction = labels[max_ind_label] predictions.append(prediction) return np.array(predictions) YaptÄ±ÄŸÄ±mÄ±z iÅŸlemler her nokta iÃ§in uzaklÄ±ÄŸÄ± hesapladÄ±k en yakÄ±n k noktanÄ±n labellarÄ±nÄ± aldÄ±k bu labellarÄ±n sayÄ±larÄ±nÄ± Ã¶ÄŸrendik en Ã§ok label kimdeyse onu tahmin olarak Ã¶ne sÃ¼rdÃ¼k Bu KNN modelini istediÄŸiniz veride kullabilirsiniz. Daha kapsamlÄ± koda bakmak isterseniz bu Github Repoâ€™ya bakabilirsiniz. Bir sonraki yazÄ±da gÃ¶rÃ¼ÅŸmek Ã¼zere. ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:2:1","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"TANIM Softmax fonksiyonu modelden Ã§Ä±kan sonuÃ§larÄ±n olasÄ±lÄ±ksal ÅŸekilde ifade edilmesi iÃ§in kullanÄ±lan bir fonksiyondur. Genellikle nÃ¶ral aÄŸlarda (neural network) aÄŸÄ±n sonucunu sÄ±nÄ±flara olasÄ±lÄ±k deÄŸerleri vermek iÃ§in kullanÄ±lÄ±r. Softmax fonksiyonu input olarak $K$ boyutlu uzaydan vektÃ¶r $z$ alÄ±r. Bu vektÃ¶rÃ¼ $K$ olasÄ±lÄ±k deÄŸerlerinden oluÅŸan bir olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±na Ã§evirir. Bu olasÄ±lÄ±klarÄ±n her biri exponentiallarÄ± ile doÄŸru orantÄ±lÄ±dÄ±r. Softmax fonksiyonu uygulamadan Ã¶nce bu $z$ vektÃ¶rÃ¼ndeki bazÄ± deÄŸerler negatif de olabilir 0 da olabilir, pozitif de olabilir. Softmax fonksiyonunu uyguladÄ±ktan sonra ise bÃ¼tÃ¼n deÄŸerler $(0, 1)$ aralÄ±ÄŸÄ±nda deÄŸer alÄ±r ve bÃ¼tÃ¼n deÄŸerlerin toplamÄ± 1 olur. Standart softmax function tanÄ±mÄ± ÅŸu ÅŸekildedir. $\\sigma : \\mathbb{R^{K}} \\rightarrow \\mathbb{R^K}$ Bir diÄŸer deyiÅŸle bizim yaptÄ±ÄŸÄ±mÄ±z iÅŸlem her bir deÄŸerin exponential fonksiyonunu almak ve bunu toplama bÃ¶lmek. BÃ¶ylece normalize etmiÅŸ oluyoruz ve bÃ¼tÃ¼n deÄŸerleri topladÄ±ÄŸÄ±mÄ±z zaman sonuÃ§ 1 ediyor. Ã–rnek olarak vektÃ¶r $k = [1, 1, 1] \\in \\mathbb{R^3}$ olsun. O zaman, $$ \\sigma(k) = [\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}] $$ Peki bunu nasÄ±l bulduk. Ã–ncelikle toplamÄ± hesaplayalÄ±m $$ \\sum_{j=1}^{K}e^{k_i} = e^1 + e^1 + e^1 = 3e $$ Toplam $3e$ Ã§Ä±ktÄ±. Åžimdi her bir deÄŸeri exponential fonskiyona input olarak verirsek Ã§Ä±kacak sonuÃ§ $e^1 = e$ olur. Bizim softmax fonksiyonunda yaptÄ±ÄŸÄ±mÄ±z iÅŸlem ise bu deÄŸerleri alÄ±p toplama bÃ¶lmek. Yani, $$ \\frac{e}{3e} = \\frac{1}{3} $$ ","date":"2020-08-12","objectID":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/:1:0","tags":["numpy","derin ogrenme","matematik"],"title":"Softmax Aktivasyon Fonksiyonu Nedir ve Numpy ile NasÄ±l Implement Edilir","uri":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/"},{"categories":null,"content":"NUMPY Ä°LE NASIL Ä°MPLEMENT EDÄ°LÄ°R Numpy fonksiyonunda arrayin direk exponential fonksiyonunu alabiliriz. Bunun iÃ§in for loop aÃ§mamÄ±za gerek yok import numpy as np arr = np.array([1, 3, 2]) exponential_arr = np.exp(arr) print(\"Array: {} \\nExponential Array: {} \\n\".format(arr, exponential_arr)) Array: [1 2 3] Exponential Array : [ 2.71828183 7.3890561 20.08553692] Arrayin direk Ã¼stel ÅŸekilde toplamÄ±nÄ± da alabiliriz. sum_of_exponentials = np.sum(exponential_arr) print(\"Exponential Array ToplamÄ±: \", sum_of_exponentials) Exponential Array ToplamÄ±: 30.19287485057736 Åžimdi softmax implement etmek iÃ§in her ÅŸeye sahibiz. Fonksiyon ÅŸeklinde implement edebiliriz. def softmax(arr): exp_array = np.exp(arr) exp_toplam = np.sum(exp_array) return exp_array/exp_toplam Åžimdi fonksiyonumuzu test edelim arr = np.array([1, 1, 1]) softmax_array = softmax(arr) print(\"Array: {} \\nSoftmax Array: {}\".format(arr, softmax_array)) Array: [1 1 1] Softmax Array: [0.33333333 0.33333333 0.33333333] GÃ¶rdÃ¼ÄŸÃ¼mÃ¼z Ã¼zere softmax fonksiyondan Ã§Ä±kan arrayin toplamÄ± 1 e eÅŸit oluyor np.sum(softmax_array) #SonuÃ§ 1 Ã§Ä±kÄ±yor. Softmax fonksiyonu bu kadar. Bir sonraki yazÄ±da gÃ¶rÃ¼ÅŸmek Ã¼zere. ","date":"2020-08-12","objectID":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/:2:0","tags":["numpy","derin ogrenme","matematik"],"title":"Softmax Aktivasyon Fonksiyonu Nedir ve Numpy ile NasÄ±l Implement Edilir","uri":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/"},{"categories":null,"content":"REFERENCES wikipedia-softmax ","date":"2020-08-12","objectID":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/:3:0","tags":["numpy","derin ogrenme","matematik"],"title":"Softmax Aktivasyon Fonksiyonu Nedir ve Numpy ile NasÄ±l Implement Edilir","uri":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/"},{"categories":null,"content":"TANIM Ä°statistik, verilen bir Ã¶rneklemden(sample) elde edilen herhangi bir deÄŸer demektir. Ä°statistiksel Ã¶ÄŸrenmede, verilen sampledan saÄŸlanan bilgi ile karar verilir. Ä°lk yaklaÅŸÄ±mÄ±mÄ±z, sampleâ€™Ä±n belirli bir daÄŸÄ±lÄ±mdan (distribution) geldiÄŸini farz ederek yapmak olacaktÄ±r. Bu daÄŸÄ±lÄ±ma Ã¶rnek olarak Gaussian daÄŸÄ±lÄ±m verilebilir. Bu durumun avantajÄ± ise, parametre sayÄ±sÄ±nÄ±n azaltÄ±lmasÄ± olacaktÄ±r. TÃ¼m parametrelerimiz ortalama deÄŸer (mean) ve varyans (variance) olacaktÄ±r. Bu parametreleri sample tarafÄ±ndan elde ettikten sonra, bÃ¼tÃ¼n daÄŸÄ±lÄ±mÄ± biliyor olacaÄŸÄ±z. Bu parametreleri verilen sample Ã¼zerinden Ã¶ÄŸrenip, daha sonra bu bulduÄŸumuz ortalama ve varyans deÄŸerlerini modele entegre ederek, tahmini bir daÄŸÄ±lÄ±m elde edeceÄŸiz. Daha sonra bu daÄŸÄ±lÄ±mÄ± da karar vermek iÃ§in kullanacaÄŸÄ±z. Ã–ncelikle olasÄ±lÄ±k kavramÄ± diÄŸer ismiyle density estimation (yoÄŸunluk tahmini) anlamÄ±na gelen $p\\left(x\\right)$ kavramÄ± ile baÅŸlÄ±yoruz. Bu kavramÄ±, Naive Bayesde de olduÄŸu gibi tahmini olasÄ±lÄ±klarÄ±n $p(x \\mid C_{i})$, ve prior olasÄ±lÄ±k olan $P\\left(C_{i}\\right)$ olduÄŸu ve bu olasÄ±lÄ±klarÄ±n daha sonra asÄ±l amaÃ§ olan $P\\left(C_{i} \\mid x\\right)$â€˜i tahmin ederek sÄ±nÄ±flandÄ±rma iÅŸlemi yapÄ±lmasÄ± iÃ§in kullanÄ±yoruz. Peki bu parametreleri nasÄ±l Ã¶ÄŸreneceÄŸiz. Maksimum Likelihood Estimation kullanarak yapacaÄŸÄ±z. ","date":"2020-01-12","objectID":"/makine-ogrenmesinde-parametrik-metodlar/:1:0","tags":["makine ogrenmesi","matematik"],"title":"Makine Ogrenmesinde Parametrik Metodlar","uri":"/makine-ogrenmesinde-parametrik-metodlar/"},{"categories":null,"content":"Maximum Likelihood Estimation (Maksimum OlasÄ±lÄ±k Tahmini) Elimizde birbirinden baÄŸÄ±msÄ±z ve aynÄ± ÅŸekilde daÄŸÄ±tÄ±lmÄ±ÅŸ olan bir sample var. Bu sampleâ€™Ä± $X = \\{ x^{t} \\}_{i=1}^{N}$ ÅŸeklinde gÃ¶sterebiliriz. Bu sampledan Ã§ekilen her bir $x^{t}$ Ã¶rneÄŸin, bilinen bir olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±na ait olduÄŸunu varsayÄ±yoruz. Bu olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ± da $p\\left(x \\mid \\theta \\right)$ gÃ¶steriyoruz. $$ x^{t} \\sim p(x|\\theta) $$ Bizim buradaki amacÄ±mÄ±z bize en yÃ¼ksek olasÄ±lÄ±ÄŸÄ± $p\\left(x \\mid \\theta \\right)$ verecek olan $\\theta$ deÄŸerini bulmak. BÃ¼tÃ¼n Ã¶rnekler $x^{t}$ birbirinden baÄŸÄ±msÄ±z olduÄŸundan parametre $\\theta$ nÄ±n olasÄ±lÄ±k fonksiyonu bÃ¼tÃ¼n verilen samplelarÄ±n olasÄ±lÄ±klarÄ±nÄ±n Ã§arpÄ±mÄ±na eÅŸittir. $$ l(\\theta | X) = p(X|\\theta) = \\prod_{t=1}^{N}p(x^{i}|\\theta) $$ Maksimum olasÄ±lÄ±k tahmininde, bu deÄŸeri maksimum yapan $\\theta$ deÄŸerini bulmak istiyoruz. Bunu bulmak iÃ§in Ã¶nce logaritma alÄ±p, daha sonra nerede maksimum yaptÄ±ÄŸÄ±na bakabiliriz. Logaritma alma sebebimiz ise logaritmanÄ±n Ã§arpÄ±m sembolÃ¼nÃ¼ toplama Ã§evirmesi ve baÅŸka kolaylÄ±klar saÄŸlamasÄ± dolayÄ±sÄ±yladÄ±r. Log olasÄ±lÄ±k ise ÅŸÃ¶yle tanÄ±mlanÄ±r. $$ l(\\theta | X) \\equiv \\log l(\\theta | X) = \\sum_{t = 1}^{N}\\log p(x^{t}|\\theta) $$ YazÄ±mÄ±zÄ±n baÅŸÄ±nda bu her sample Ä±n belirli bir daÄŸÄ±lÄ±mdan geldiÄŸini sÃ¶ylemiÅŸtik. Bunun iÃ§in bir sÃ¼rÃ¼ seÃ§enek olabilir. Bernouilli, Multinomial ve Gaussian(Normal) daÄŸÄ±lÄ±mlar olabilir. Ancak biz burada sadece Gaussian(Normal) daÄŸÄ±lÄ±m ile ilgilineceÄŸiz. ","date":"2020-01-12","objectID":"/makine-ogrenmesinde-parametrik-metodlar/:1:1","tags":["makine ogrenmesi","matematik"],"title":"Makine Ogrenmesinde Parametrik Metodlar","uri":"/makine-ogrenmesinde-parametrik-metodlar/"},{"categories":null,"content":"NORMAL DAÄžILIMDA MAXÄ°MUM LIKELIHOOD ESTIMATION X, ortalama yani $E[X] \\equiv \\mu$ ve varyans $Var(X) \\equiv \\sigma^{2}$ deÄŸerlerine sahip normal daÄŸÄ±lÄ±mla daÄŸÄ±tÄ±lmÄ±ÅŸ bir random variable olsun. O zaman density (yoÄŸunluk) fonksiyonu ÅŸu ÅŸekilde $$ N(\\mu , \\sigma^{2}) = p(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x - \\mu)^2}{2\\sigma^{2}}} $$ O zaman verilen sampleÄ±n $X = \\{ x^t \\}_{t=1}^{N}$ log likelihood deÄŸeri de ÅŸu ÅŸekilde olur. $$ l(\\mu, \\sigma | X) = -\\frac{N}{2}\\log(2\\pi) - N \\log(\\sigma) - \\frac{\\sum_{t}(x^t - \\mu)^{2}}{2\\sigma^{2}} $$ Daha sonra sÄ±rayla bu fonksiyonun ortalama deÄŸer ve varyans iÃ§in partial tÃ¼revlerini alÄ±p sÄ±fÄ±ra eÅŸitlediÄŸimizde ortaya ÅŸÃ¶yle bir sonuÃ§ Ã§Ä±kÄ±yor. $$ m = \\frac{\\sum_{t}x^t}{N} $$ $$ s^2 = \\frac{\\sum_{t}(x^t - m)^2}{N} $$ Burada $m$ ortalama deÄŸer iÃ§in maximum likelihood estimate oluyor ve $s^2$ ise varyans iÃ§in maximum likelihood estimate oluyor. Bu durumda istenilen parametreleri bulmuÅŸ olduk. Bundan sonraki yazÄ±da ise bias(Ã¶nyargÄ±) ve Varyans(Variance) konularÄ± iÅŸleyeceÄŸiz. Sonraki yazÄ±larda gÃ¶rÃ¼ÅŸmek Ã¼zere. ","date":"2020-01-12","objectID":"/makine-ogrenmesinde-parametrik-metodlar/:1:2","tags":["makine ogrenmesi","matematik"],"title":"Makine Ogrenmesinde Parametrik Metodlar","uri":"/makine-ogrenmesinde-parametrik-metodlar/"},{"categories":null,"content":"Hello there, Welcome to Hasan Ocakâ€™s Blog. I recently graduated ðŸŽ“ from Sabanci University and I am currently working as Backend Developer ðŸ’» in Turkey. I love reading and one day I decided to start a blog. I am not a consistent writer but I will try to write more. Until now I only written in Turkish but I will write in English too. Please stay tuned, Bye Here are my social links Github Linkedin Email ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"}]