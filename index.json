[{"categories":null,"content":"In most of today’s services, there is almost always a data storage to store some data. This could be some relational databases such as MySQL or some document database such as MongoDB. In this blog I will show how to write some tests for MongoDB. All of the code can be received in ocakhasan/golang-mongo-integration-tests If you would like to learn more about how to use MongoDB with golang, please check Golang \u0026 MongoDB Query Cheat Sheet Integration Testing for MongoDB-Backed REST APIs with Golang ","date":"2024-01-19","objectID":"/golang-mongodb-integration-tests/:0:0","tags":["golang","mongodb","tests"],"title":"Write Integration Tests For Mongo With Golang","uri":"/golang-mongodb-integration-tests/"},{"categories":null,"content":"PREQUISITES You need to have Docker installed in your system since this project requires testcontainers. We are going to use the Official SDK provided by the MongoDB corporation. We are going to use testify/suite to setup and teardown tests. This is not a need but it would be feasible to use suite.Suite once there are more methods. Here are the packages used in this project github.com/stretchr/testify v1.8.4 github.com/testcontainers/testcontainers-go v0.27.0 go.mongodb.org/mongo-driver v1.13.1 ","date":"2024-01-19","objectID":"/golang-mongodb-integration-tests/:1:0","tags":["golang","mongodb","tests"],"title":"Write Integration Tests For Mongo With Golang","uri":"/golang-mongodb-integration-tests/"},{"categories":null,"content":"Code I think first we should see the methods we are going to test to get the idea. ","date":"2024-01-19","objectID":"/golang-mongodb-integration-tests/:2:0","tags":["golang","mongodb","tests"],"title":"Write Integration Tests For Mongo With Golang","uri":"/golang-mongodb-integration-tests/"},{"categories":null,"content":"Model First let’s see the database model we are dealing with type Book struct { ID primitive.ObjectID `bson:\"_id\"` Author string `bson:\"author\"` Title string `bson:\"title\"` Likes int `bson:\"likes\"` } ","date":"2024-01-19","objectID":"/golang-mongodb-integration-tests/:2:1","tags":["golang","mongodb","tests"],"title":"Write Integration Tests For Mongo With Golang","uri":"/golang-mongodb-integration-tests/"},{"categories":null,"content":"Repository We have an interface called Repository which has all the methods for our project needs. To make the blog shorter, I added 2 simple methods just to show the idea. Now let’s see the Repository interface. type Repository interface { CreateBook(ctx context.Context, book Book) (Book, error) FindBook(ctx context.Context, id primitive.ObjectID) (*Book, error) } We have a struct named mongoRepository which implements the Repository interface methods. func NewRepository(db *mongo.Database) *mongoRepository { return \u0026mongoRepository{db: db} } type mongoRepository struct { db *mongo.Database } func (m *mongoRepository) CreateBook(ctx context.Context, book Book) (Book, error) { if book.ID.IsZero() { book.ID = primitive.NewObjectID() } _, err := m.db.Collection(\"books\").InsertOne(ctx, book) if err != nil { return Book{}, err } return book, nil } func (m *mongoRepository) FindBook(ctx context.Context, id primitive.ObjectID) (*Book, error) { var book Book filter := bson.M{ \"_id\": id, } if err := m.db.Collection(\"books\").FindOne(ctx, filter).Decode(\u0026book); err != nil { return nil, err } return \u0026book, nil } As we can see, mongoRepository only accepts a client which is mongo.Database. The implementation is super straight forward. ","date":"2024-01-19","objectID":"/golang-mongodb-integration-tests/:2:2","tags":["golang","mongodb","tests"],"title":"Write Integration Tests For Mongo With Golang","uri":"/golang-mongodb-integration-tests/"},{"categories":null,"content":"MONGO DATABASE To be able to meet the needs of the mongoRepository we must create a client. package mongo import ( \"context\" \"time\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) func NewMongoDatabase(uri string, database string) (*mongo.Database, error) { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(uri)) if err != nil { return nil, err } db := client.Database(database) return db, nil } ","date":"2024-01-19","objectID":"/golang-mongodb-integration-tests/:2:3","tags":["golang","mongodb","tests"],"title":"Write Integration Tests For Mongo With Golang","uri":"/golang-mongodb-integration-tests/"},{"categories":null,"content":"TEST CONTAINERS SETUP First we need to create a container to be able to test our needs. Creating a container is quite easy with the followings. Let’s create a struct called TestDatabase which will have all of our needs to test the functionality. type TestDatabase struct { DbInstance *mongo.Database DbAddress string container testcontainers.Container } We need the *mongo.Database to create the Repository method. We need the container to terminate it when the testing is done. Now let’s create the rest. func SetupTestDatabase() *TestDatabase { ctx, _ := context.WithTimeout(context.Background(), time.Second*60) container, dbInstance, dbAddr, err := createMongoContainer(ctx) if err != nil { log.Fatal(\"failed to setup test\", err) } return \u0026TestDatabase{ container: container, DbInstance: dbInstance, DbAddress: dbAddr, } } func (tdb *TestDatabase) TearDown() { _ = tdb.container.Terminate(context.Background()) } The TearDown method of the TestDatabase will be used after all of the tests run to terminate the container so we free the resources. Now let’s see how to create the container func createMongoContainer(ctx context.Context) (testcontainers.Container, *mongo.Database, string, error) { var env = map[string]string{ \"MONGO_INITDB_ROOT_USERNAME\": \"root\", \"MONGO_INITDB_ROOT_PASSWORD\": \"pass\", \"MONGO_INITDB_DATABASE\": \"testdb\", } var port = \"27017/tcp\" req := testcontainers.GenericContainerRequest{ ContainerRequest: testcontainers.ContainerRequest{ Image: \"mongo\", ExposedPorts: []string{port}, Env: env, }, Started: true, } container, err := testcontainers.GenericContainer(ctx, req) if err != nil { return container, nil, \"\", fmt.Errorf(\"failed to start container: %v\", err) } p, err := container.MappedPort(ctx, \"27017\") if err != nil { return container, nil, \"\", fmt.Errorf(\"failed to get container external port: %v\", err) } log.Println(\"mongo container ready and running at port: \", p.Port()) uri := fmt.Sprintf(\"mongodb://root:pass@localhost:%s\", p.Port()) db, err := NewMongoDatabase(uri, \"testdb\") if err != nil { return container, db, uri, fmt.Errorf(\"failed to establish database connection: %v\", err) } return container, db, uri, nil } It can look complex but in reality. First you create the container Then you get the mapped port from mongo container to your localhost Then create the mongo URI to connect the database. All of the code can be seen below. package mongo import ( \"context\" \"fmt\" \"log\" \"time\" \"github.com/testcontainers/testcontainers-go\" \"go.mongodb.org/mongo-driver/mongo\" ) type TestDatabase struct { DbInstance *mongo.Database DbAddress string container testcontainers.Container } func SetupTestDatabase() *TestDatabase { ctx, _ := context.WithTimeout(context.Background(), time.Second*60) container, dbInstance, dbAddr, err := createMongoContainer(ctx) if err != nil { log.Fatal(\"failed to setup test\", err) } return \u0026TestDatabase{ container: container, DbInstance: dbInstance, DbAddress: dbAddr, } } func (tdb *TestDatabase) TearDown() { _ = tdb.container.Terminate(context.Background()) } func createMongoContainer(ctx context.Context) (testcontainers.Container, *mongo.Database, string, error) { var env = map[string]string{ \"MONGO_INITDB_ROOT_USERNAME\": \"root\", \"MONGO_INITDB_ROOT_PASSWORD\": \"pass\", \"MONGO_INITDB_DATABASE\": \"testdb\", } var port = \"27017/tcp\" req := testcontainers.GenericContainerRequest{ ContainerRequest: testcontainers.ContainerRequest{ Image: \"mongo\", ExposedPorts: []string{port}, Env: env, }, Started: true, } container, err := testcontainers.GenericContainer(ctx, req) if err != nil { return container, nil, \"\", fmt.Errorf(\"failed to start container: %v\", err) } p, err := container.MappedPort(ctx, \"27017\") if err != nil { return container, nil, \"\", fmt.Errorf(\"failed to get container external port: %v\", err) } log.Println(\"mongo container ready and running at port: \", p.Port()) uri := fmt.Sprintf(\"mongodb://root:pass@localhost:%s\", p.Port()) db, err := NewMongoDatabase(uri, \"testdb\") if err != nil { return container,","date":"2024-01-19","objectID":"/golang-mongodb-integration-tests/:2:4","tags":["golang","mongodb","tests"],"title":"Write Integration Tests For Mongo With Golang","uri":"/golang-mongodb-integration-tests/"},{"categories":null,"content":"TESTS Now that we will have Repository methods How to create the container and connect to it with Mongo We can pass to testing phase. As I mentioned in the beginning, we will use the `testify/suite’ method to write the tests. First, let’s create a struct called RepositorySuite which has the suite.Suite, so it can call the helper functions of the suite.Suite. type RepositorySuite struct { suite.Suite repository Repository testDatabase *TestDatabase } Now we will implement some interfaces from the testify/suite package. First let’s implement SetupAllSuite interface. type SetupAllSuite interface { SetupSuite() } SetupAllSuite has a SetupSuite method, which will run before the tests in the suite are run. We are going to implement this interface and we will create the mongo container and the repository. Now, let’s implement the TearDownAllSuite interface. type TearDownAllSuite interface { TearDownSuite() } TearDownAllSuite has a TearDownSuite method, which will run after all the tests in the suite have been run. We are going to implement this interface and we will terminate the mongo container. func (suite *RepositorySuite) SetupSuite() { suite.testDatabase = SetupTestDatabase() suite.repository = NewRepository(suite.testDatabase.DbInstance) } func (suite *RepositorySuite) TearDownSuite() { suite.testDatabase.container.Terminate(context.Background()) } Now we can write our tests. Now let’s write some tests for the CreateBook method. Let’s recall the method. func (m *mongoRepository) CreateBook(ctx context.Context, book Book) (Book, error) { if book.ID.IsZero() { book.ID = primitive.NewObjectID() } _, err := m.db.Collection(\"books\").InsertOne(ctx, book) if err != nil { return Book{}, err } return book, nil } The method is quite simple, it checks if the ID is provided by the function. If it is not provided, it generates a new unique id. So what we can test is Provide a book with no id Provide a book with id Then check whether they are created or not. // All methods that begin with \"Test\" are run as tests within a // suite. func (suite *RepositorySuite) TestCreateBook() { suite.Run(\"when id is not provided\", func() { book := Book{ Author: \"Irvin D. Yalom\", Title: \"Staring at the Sun: Overcoming the Terror of Death\", Likes: 100, } createdBook, createBookErr := suite.repository.CreateBook(context.Background(), book) suite.Nil(createBookErr) suite.Equal(createdBook.Title, \"Staring at the Sun: Overcoming the Terror of Death\") suite.Equal(createdBook.Author, \"Irvin D. Yalom\") suite.False(createdBook.ID.IsZero()) }) suite.Run(\"when id is provided\", func() { book := Book{ ID: primitive.NewObjectID(), Author: \"Dostoyevksi\", Title: \"Notes From the Underground\", Likes: 100, } createdBook, createBookErr := suite.repository.CreateBook(context.Background(), book) suite.Nil(createBookErr) suite.Equal(createdBook, book) }) } Now let’s write some tests for FindBook method of the mongoRepository. Let’s recall the method. func (m *mongoRepository) FindBook(ctx context.Context, id primitive.ObjectID) (*Book, error) { var book Book filter := bson.M{ \"_id\": id, } if err := m.db.Collection(\"books\").FindOne(ctx, filter).Decode(\u0026book); err != nil { return nil, err } return \u0026book, nil } It is quite simple, it tries to find the book with given id. So to test it, First, we need to create a book, then try to fetch it and it should be successful. Try to fetch a document which not exists, then it should not found it. func (suite *RepositorySuite) TestFindBook() { suite.Run(\"when there is no record\", func() { id := primitive.NewObjectID() foundBook, findBookErr := suite.repository.FindBook(context.Background(), id) suite.Equal(findBookErr, mongo.ErrNoDocuments) suite.Nil(foundBook) }) suite.Run(\"when there is record for given id\", func() { book := Book{ Author: \"Dostoyevksi\", Title: \"Notes From the Underground\", Likes: 100, } createdBook, createBookErr := suite.repository.CreateBook(context.Background(), book) suite.Nil(createBookErr) id := createdBook.ID foundBook","date":"2024-01-19","objectID":"/golang-mongodb-integration-tests/:2:5","tags":["golang","mongodb","tests"],"title":"Write Integration Tests For Mongo With Golang","uri":"/golang-mongodb-integration-tests/"},{"categories":null,"content":"REFERENCES mongodb go-sdk testify/suite testcontainers ","date":"2024-01-19","objectID":"/golang-mongodb-integration-tests/:3:0","tags":["golang","mongodb","tests"],"title":"Write Integration Tests For Mongo With Golang","uri":"/golang-mongodb-integration-tests/"},{"categories":null,"content":"2023 özet 2023 yılının son gününde bu sene neler yaptım diye bir bakalım. Geçen sene bu zamanlar ufak bir yazı yazmıştım, bakınca biraz garip geldi ama kısa ve net hedefler koymuşum. bu sefer öyle yapmayacağım. 2023 bence benim için verimli bir yıldı. Verimlilik açısından aşağıdaki maddeleri yazabilirim. nisan ayında iş değiştirdim ve yurtdışından bir şirkete çalışmaya başladım. eylül ayında askerliğimi yaptım. bunlar aklıma gelen hayatımdaki en büyük değişimler. bu sene olabildiğince bloguma zaman ayırmaya çalıştım ve gördüğüm kadarıyla irili ufaklı 10 tane yazı yazmışım. yazıları sayısıyla nitelendirmek saçma ancak bir yıl önce her ay en az 1 yazı yazarım gibisinden kendime hedef koymuştum ve neredeyse başarmışım. bazı aylar hiç yazmasam da görünen o ki yılın ikinci yarısında daha çok yazmışım çünkü farkındalığım daha çok arttı. blog yazmayı seviyorum ve bunun faydasını gördüm, blogum hiç okunmadığı kadar okunmaya başlandı, bazı sosyal mecralarda yazdığım yazıları paylaştım ve hatta iş yerimde bile ufak bir sunum yapmama yardımcı oldu. ","date":"2023-12-31","objectID":"/2024-expectations/:1:0","tags":["life","thoughts"],"title":"(tr) 2023 özet \u0026 2024 beklentileri","uri":"/2024-expectations/"},{"categories":null,"content":"2024 beklentileri 2024 yılı gelmek üzereyken kendime bazı maddi ve manevi hedefler koyacağım ve bunları uygulamaya çalışacağım. ehliyetimi almak ilk otomobilimi almak yurt dışına geziye çıkmak bloguma daha çok vakit ve özen göstermek yatırım yapmayı daha detaylı öğrenmek daha çok okumak, öğrenmek daha çok spor yapmak sevdiklerimle daha çok vakit geçirmek buradaki hedeflerin bazıları size çok basit şeyler gibi gelebilir ancak bazıları benim hiç yapmadığım şeyler. umarım yukarıda belirlediğim basit hedeflerimi gerçekleştirebilirim. bu yazıyı okuyan herkes için çok güzel bir 2024 diliyorum ve yazımı güzel bir alıntı ile bitiriyorum. Marcus Aurelis Mutlu bir yaşam elde edebilmek için çok az şeye ihtiyaç duyulduğunu unutma. ","date":"2023-12-31","objectID":"/2024-expectations/:2:0","tags":["life","thoughts"],"title":"(tr) 2023 özet \u0026 2024 beklentileri","uri":"/2024-expectations/"},{"categories":null,"content":"Concurrent programming in Go can be a bit like juggling—keeping many tasks in the air at once. The context package in Go acts as your trusty assistant, helping you manage this juggling act with finesse. In this blog post, we’re going to unravel the secrets of the context package. It’s your toolkit for handling tricky situations in concurrent programs, such as canceling tasks, setting deadlines, and smoothly passing information between different parts of your code. Think of it as your guide to becoming a concurrency maestro in Go. We’ll start with the basics, explore how to use the context package in real-life scenarios, and wrap up with tips to keep your concurrent programs running smoothly. ","date":"2023-11-24","objectID":"/golang-context-complete-guide/:0:0","tags":["golang","concurrency"],"title":"Golang Context Guide in Concurrent Programs","uri":"/golang-context-complete-guide/"},{"categories":null,"content":"Context Package Let’s have a look at the code for the context package. // A Context carries a deadline, a cancellation signal, and other values across // API boundaries. // // Context's methods may be called by multiple goroutines simultaneously. type Context interface { // Deadline returns the time when work done on behalf of this context // should be canceled. Deadline returns ok==false when no deadline is // set. Successive calls to Deadline return the same results. Deadline() (deadline time.Time, ok bool) // Done returns a channel that's closed when work done on behalf of this // context should be canceled. Done may return nil if this context can // never be canceled. Successive calls to Done return the same value. // The close of the Done channel may happen asynchronously, // after the cancel function returns. Done() \u003c-chan struct{} // If Done is not yet closed, Err returns nil. // If Done is closed, Err returns a non-nil error explaining why: // Canceled if the context was canceled // or DeadlineExceeded if the context's deadline passed. // After Err returns a non-nil error, successive calls to Err return the same error. Err() error // Value returns the value associated with this context for key, or nil // if no value is associated with key. Successive calls to Value with // the same key returns the same result. Value(key any) any } It is quite simple and we will be mostly using the Done() \u003c- chan struct{} function. Let’s have a look at the functions provided by the context package that we will use. // WithCancel returns a copy of parent with a new Done channel. The returned // context's Done channel is closed when the returned cancel function is called // or when the parent context's Done channel is closed, whichever happens first. // // Canceling this context releases resources associated with it, so code should // call cancel as soon as the operations running in this Context complete. func WithCancel(parent Context) (ctx Context, cancel CancelFunc) // WithDeadline returns a copy of the parent context with the deadline adjusted // to be no later than d. If the parent's deadline is already earlier than d, // WithDeadline(parent, d) is semantically equivalent to parent. The returned // [Context.Done] channel is closed when the deadline expires, when the returned // cancel function is called, or when the parent context's Done channel is // closed, whichever happens first. // // Canceling this context releases resources associated with it, so code should // call cancel as soon as the operations running in this [Context] complete. func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) // WithTimeout returns WithDeadline(parent, time.Now().Add(timeout)). // // Canceling this context releases resources associated with it, so code should // call cancel as soon as the operations running in this [Context] complete: // // func slowOperationWithTimeout(ctx context.Context) (Result, error) { // ctx, cancel := context.WithTimeout(ctx, 100*time.Millisecond) // defer cancel() // releases resources if slowOperation completes before timeout elapses // return slowOperation(ctx) // } func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) In most of the times these 3 functions are used and I will be giving examples on how to use them effectively. ","date":"2023-11-24","objectID":"/golang-context-complete-guide/:1:0","tags":["golang","concurrency"],"title":"Golang Context Guide in Concurrent Programs","uri":"/golang-context-complete-guide/"},{"categories":null,"content":"Demo Showcase of the Concurrency We will write some pseudo-code first to understand the flow, then implement it in golang. - channel is declared - some goroutine(s) is writing into the channel - some goroutines(s) are listening from channel in parallel and process the messages - wait for the listeners to finish the processing and exit the program For our example, we will be having 2 goroutines listening to a channel and the main goroutine writing into the channel. A simple program is with 2 second timeout can be written as package main import ( \"context\" \"log\" \"sync\" \"time\" ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second) defer cancel() dataChannel := make(chan int) var wg sync.WaitGroup wg.Add(2) for j := 0; j \u003c 2; j++ { go func(i int) { worker(ctx, dataChannel, i) wg.Done() }(j) } i := 0 for i \u003c 5 { dataChannel \u003c- i i++ } wg.Wait() } func worker(ctx context.Context, ch chan int, number int) { for { select { case \u003c-ctx.Done(): log.Printf(\"context canceled, exiting for worker number %d\\n\", number) return case i, ok := \u003c-ch: // It means channel is closed if !ok { log.Printf(\"channel is closed, exiting worker %d\\n\", number) return } log.Printf(\"worker: %d: read %v from channel\\n\", number, i) } } } ","date":"2023-11-24","objectID":"/golang-context-complete-guide/:2:0","tags":["golang","concurrency"],"title":"Golang Context Guide in Concurrent Programs","uri":"/golang-context-complete-guide/"},{"categories":null,"content":"Explanation of the Demo Let’s split the code and explain what each part is doing. // ... ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second) defer cancel() dataChannel := make(chan int) // ... We are initializing the context variable with 2 second timeout. So if our program is taking more than 2 second, we want the program to exit it and inform the sub-goroutines about it. Calling defer cancel() releases resources if the program completes before 2 second. In the last line, we are creating the channel which will be the main communication system for our program. // ... var wg sync.WaitGroup wg.Add(2) for j := 0; j \u003c 2; j++ { go func(i int) { worker(ctx, dataChannel, i) wg.Done() }(j) } // ... This line of code initializes a waitgroup and runs the goroutines in the background. sync.WaitGroup is used to make sure that we are waiting for goroutines to finish the processing so we can exit the code. // ... i := 0 for i \u003c 5 { dataChannel \u003c- i i++ } wg.Wait() // .. In this lines of code we are writing simple numbers to the channel, so the goroutines has something to read. In the last line, we are waiting on the sync.WaitGroup which means we are waiting goroutines to finish. 4. func worker(ctx context.Context, ch chan int, number int) { for { select { case \u003c-ctx.Done(): log.Printf(\"context canceled, exiting for worker number %d\\n\", number) return case i, ok := \u003c-ch: // It means channel is closed if !ok { log.Printf(\"channel is closed, exiting worker %d\\n\", number) return } log.Printf(\"worker: %d: read %v from channel\\n\", number, i) } } } worker function takes the context parameter and the data channel. ctx is passed to check if the context is canceled or not. if the context is canceled, the goroutine will exit which is the wanted behaviour of the code. channel is passed to read the data from the main goroutine if the channel is closed, it means that there are no data to read from so we can exit. When you run the code, here is what is going to happen: The goroutines will start to listen the channel. The main goroutine will write to the channel. Goroutines will receive some values from the channel and print some stuff. When the 2 second passes, the context will be canceled which means that the goroutines will also exit and the waitgroup value will be 0. the program will exit. Let’s run the code and see the output. go run main.go output 2023/11/24 21:15:27 worker: 1: read 0 from channel 2023/11/24 21:15:27 worker: 1: read 2 from channel 2023/11/24 21:15:27 worker: 0: read 1 from channel 2023/11/24 21:15:27 worker: 0: read 4 from channel 2023/11/24 21:15:27 worker: 1: read 3 from channel 2023/11/24 21:15:29 context canceled, exiting for worker number 0 2023/11/24 21:15:29 context canceled, exiting for worker number 1 As we can see from the output, the goroutines read some values from the channel, then waited for the context to cancel. When the context is canceled, it is the end time for the goroutines, so they exit, which also results in the main program exit. From the times of the logs, we can see that the program took nearly 2 seconds to finish. ","date":"2023-11-24","objectID":"/golang-context-complete-guide/:2:1","tags":["golang","concurrency"],"title":"Golang Context Guide in Concurrent Programs","uri":"/golang-context-complete-guide/"},{"categories":null,"content":"Channel Close Case Let’s say before the timeout, the channel is closed by the main goroutine which can mean we wrote all of the data we want to process into the channel, it is time to go. we processed all of the messages from the channel before the timeout, which is exactly what is wanted in real world case, the program should finish before the timeout value. The goroutines should process all of the messages and exit when the channel is closed. So, let’s modify our code to close the channel when there is no data to write to channel. package main import ( \"context\" \"log\" \"sync\" \"time\" ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second) defer cancel() dataChannel := make(chan int) var wg sync.WaitGroup wg.Add(2) for j := 0; j \u003c 2; j++ { go func(i int) { worker(ctx, dataChannel, i) wg.Done() }(j) } i := 0 for i \u003c 5 { dataChannel \u003c- i i++ } close(dataChannel) wg.Wait() } func worker(ctx context.Context, ch chan int, number int) { for { select { case \u003c-ctx.Done(): log.Printf(\"context canceled, exiting for worker number %d\\n\", number) return case i, ok := \u003c-ch: // It means channel is closed if !ok { log.Printf(\"channel is closed, exiting worker %d\\n\", number) return } log.Printf(\"worker: %d: read %v from channel\\n\", number, i) } } } At line 31, we are closing the channel. Now let’s run the code again and see the output \u003e go run main.go Output 2023/11/24 21:21:07 worker: 1: read 0 from channel 2023/11/24 21:21:07 worker: 1: read 2 from channel 2023/11/24 21:21:07 worker: 1: read 3 from channel 2023/11/24 21:21:07 worker: 1: read 4 from channel 2023/11/24 21:21:07 channel is closed, exiting worker 1 2023/11/24 21:21:07 worker: 0: read 1 from channel 2023/11/24 21:21:07 channel is closed, exiting worker 0 What we see from the output is that whenever the channel is closed, the worker exits and the program finishes. You can see from the log times that program exited really quickly before the 2 second timeout of the context, there was no chance for the context to cancel. Our program is safe by checking context cancellation channel close check There are 2 conditions we want our program to finish either process all of the data and exit or exit after the timeout. In golang, the best practice for goroutines is to know when they should exit and passing context.Context and checking if it is cancelled is one of the best way to handle the goroutines. In this example we used the context.Timeout but there are other options as we defined in the Context Package Section. You can use context.WithCancel and manually cancel the context whenever you want to. context.WithDeadline and set a deadline for your program to finish. I hope this blog helped you understand how to use context to propagate the program exit to the sub-goroutines. Any feedback is appreciated. ","date":"2023-11-24","objectID":"/golang-context-complete-guide/:2:2","tags":["golang","concurrency"],"title":"Golang Context Guide in Concurrent Programs","uri":"/golang-context-complete-guide/"},{"categories":null,"content":"REFERENCES pkg.go.dev/context ","date":"2023-11-24","objectID":"/golang-context-complete-guide/:3:0","tags":["golang","concurrency"],"title":"Golang Context Guide in Concurrent Programs","uri":"/golang-context-complete-guide/"},{"categories":null,"content":"Building a REST API that plays nice with MongoDB is a common challenge in web development. But how do you make sure it all works seamlessly? That’s where integration testing comes in. In this blog post, we’re going to break down the process of writing integration tests for your REST API, specifically when MongoDB is in the mix. You can get all of the code samples for this blog from this repository. ","date":"2023-11-10","objectID":"/golang-mongo-db-rest-api-integration-tests/:0:0","tags":["golang","mongodb","rest","tests"],"title":"Integration Testing for MongoDB-Backed REST APIs with Golang","uri":"/golang-mongo-db-rest-api-integration-tests/"},{"categories":null,"content":"Simple Design of the API simple design of api As you can see, only component of our API is MongoDB, which is kind of not realistic for real life examples but you will get the idea on how to apply for it for multiple components for integration tests. ","date":"2023-11-10","objectID":"/golang-mongo-db-rest-api-integration-tests/:1:0","tags":["golang","mongodb","rest","tests"],"title":"Integration Testing for MongoDB-Backed REST APIs with Golang","uri":"/golang-mongo-db-rest-api-integration-tests/"},{"categories":null,"content":"Database Models For the API Each author can have many books Each book can have many comments. Please do not try to validate the design of the models. It is just designed in a way where I can write the code fast and have the tests ready in short period of time. ","date":"2023-11-10","objectID":"/golang-mongo-db-rest-api-integration-tests/:2:0","tags":["golang","mongodb","rest","tests"],"title":"Integration Testing for MongoDB-Backed REST APIs with Golang","uri":"/golang-mongo-db-rest-api-integration-tests/"},{"categories":null,"content":"API Our api has 3 different endpoints. GET /api/books: returns all of the books with their corresponding comments. GET /api/author/{id}/books: returns the books of the author with given id. POST /api/book: creates a new book. You can check the example request and responses from the project readme. ","date":"2023-11-10","objectID":"/golang-mongo-db-rest-api-integration-tests/:3:0","tags":["golang","mongodb","rest","tests"],"title":"Integration Testing for MongoDB-Backed REST APIs with Golang","uri":"/golang-mongo-db-rest-api-integration-tests/"},{"categories":null,"content":"How to Design Integration Tests Let’s check our PostsController class which is basically handling all of the requests. type PostsController struct { repo repository.Repository } func New(repo repository.Repository) *PostsController { return \u0026PostsController{repo: repo} } As we can see, the only dependency for the PostsController is the Repository. Let’s check the Repository interface. type Repository interface { GetBooksWithComments(ctx context.Context, filter PostFilter) ([]models.BookWithComments, error) CreateBook(ctx context.Context, book models.Book) (models.Book, error) GetAuthorById(ctx context.Context, id string) (*models.Author, error) } func New(db *mongo.Database) Repository { return \u0026mongoRepository{db: db} } type mongoRepository struct { db *mongo.Database } mongoRepository implements the Repository interface and, the only dependency for it is the mongo.Database. In short terms, to be able to test our controller end2end, we need a MongoDB connection, but the real question is how to get a real MongoDB connection. ","date":"2023-11-10","objectID":"/golang-mongo-db-rest-api-integration-tests/:3:1","tags":["golang","mongodb","rest","tests"],"title":"Integration Testing for MongoDB-Backed REST APIs with Golang","uri":"/golang-mongo-db-rest-api-integration-tests/"},{"categories":null,"content":"Test Containers The answer is to use the Test-Containers. What is test-containers? Testcontainers is an open source framework for providing throwaway, lightweight instances of databases, message brokers, web browsers, or just about anything that can run in a Docker container1. So, here is our strategy for testing. Run a MongoDB container with Test-Containers before doing the test. Create the database connection with the MongoDB container. Pass this connection to our API Controllers Do the API Testing Remove the MongoDB container after doing the testing. ","date":"2023-11-10","objectID":"/golang-mongo-db-rest-api-integration-tests/:3:2","tags":["golang","mongodb","rest","tests"],"title":"Integration Testing for MongoDB-Backed REST APIs with Golang","uri":"/golang-mongo-db-rest-api-integration-tests/"},{"categories":null,"content":"How to Implement With Golang We can use the testing.Main. M is a type passed to a TestMain function to run the actual tests 2. Let’s implement the TestingMain var ( testDbInstance *mongo.Database ) func TestMain(m *testing.M) { log.Println(\"setup is running\") testDB := SetupTestDatabase() testDbInstance = testDB.DbInstance populateDB() exitVal := m.Run() log.Println(\"teardown is running\") _ = testDB.container.Terminate(context.Background()) os.Exit(exitVal) } populateDB() function inserts some data to the database so we can do our testing. Let’s check the SetupTestDatabase() which is basically creating the MongoDB container and creating the connection to that container. type TestDatabase struct { DbInstance *mongo.Database DbAddress string container testcontainers.Container } func SetupTestDatabase() *TestDatabase { ctx, _ := context.WithTimeout(context.Background(), time.Second*60) container, dbInstance, dbAddr, err := createMongoContainer(ctx) if err != nil { log.Fatal(\"failed to setup test\", err) } return \u0026TestDatabase{ container: container, DbInstance: dbInstance, DbAddress: dbAddr, } } func (tdb *TestDatabase) TearDown() { _ = tdb.container.Terminate(context.Background()) } func createMongoContainer(ctx context.Context) (testcontainers.Container, *mongo.Database, string, error) { var env = map[string]string{ \"MONGO_INITDB_ROOT_USERNAME\": \"root\", \"MONGO_INITDB_ROOT_PASSWORD\": \"pass\", \"MONGO_INITDB_DATABASE\": \"testdb\", } var port = \"27017/tcp\" req := testcontainers.GenericContainerRequest{ ContainerRequest: testcontainers.ContainerRequest{ Image: \"mongo\", ExposedPorts: []string{port}, Env: env, }, Started: true, } container, err := testcontainers.GenericContainer(ctx, req) if err != nil { return container, nil, \"\", fmt.Errorf(\"failed to start container: %v\", err) } p, err := container.MappedPort(ctx, \"27017\") if err != nil { return container, nil, \"\", fmt.Errorf(\"failed to get container external port: %v\", err) } log.Println(\"mongo container ready and running at port: \", p.Port()) uri := fmt.Sprintf(\"mongodb://root:pass@localhost:%s\", p.Port()) db, err := database.NewMongoDatabase(uri) if err != nil { return container, db, uri, fmt.Errorf(\"failed to establish database connection: %v\", err) } return container, db, uri, nil } Now that we have the mongo.Database, we can create the Repository and then we can create the PostsController. import ( \"github.com/labstack/echo/v4\" \"github.com/ocakhasan/mongoapi/internal/controllers\" \"github.com/ocakhasan/mongoapi/internal/repository\" \"github.com/ocakhasan/mongoapi/pkg/router\" ) func InitializeTestRouter() *echo.Echo { postgreRepo := repository.New(testDbInstance) userController := controllers.New(postgreRepo) return router.Initialize(userController) } Let’s also check the router.Initialize() to see which endpoints there are. func Initialize(controller *controllers.PostsController) *echo.Echo { e := echo.New() api := e.Group(\"/api\") api.GET(\"/books\", controller.GetBooksWithComments()) api.POST(\"/book\", controller.CreateBook()) api.GET(\"/author/:id/books\", controller.GetAuthorBooksWithComments()) return e } Now we have the router and we can test the endpoints. ","date":"2023-11-10","objectID":"/golang-mongo-db-rest-api-integration-tests/:3:3","tags":["golang","mongodb","rest","tests"],"title":"Integration Testing for MongoDB-Backed REST APIs with Golang","uri":"/golang-mongo-db-rest-api-integration-tests/"},{"categories":null,"content":"apitest package You can create the tests with net/http package but it will create a lot of boilerplate code. There is a package called apitest. It has a lot of easy features such as reading body from a file easily check the response status code checking body from a file and so on… One of the endpoints is to create books for given author. Let’s see the controller code for context on what it is doing. func (u PostsController) CreateBook() echo.HandlerFunc { return func(c echo.Context) error { req := new(CreateBookRequest) if err := c.Bind(\u0026req); err != nil { return c.JSON(http.StatusBadRequest, map[string]interface{}{ \"err\": err.Error(), }) } objId, err := primitive.ObjectIDFromHex(req.AuthorId) if err != nil { return c.JSON(http.StatusBadRequest, map[string]interface{}{ \"err\": err.Error(), }) } author, err := u.repo.GetAuthorById(c.Request().Context(), objId.Hex()) if err != nil { if errors.Is(err, mongo.ErrNoDocuments) { return c.JSON(http.StatusNotFound, map[string]interface{}{ \"err\": \"author does not exist\", }) } } createdBook, err := u.repo.CreateBook(c.Request().Context(), models.Book{ Title: req.BookName, Author: *author, Likes: 0, }) if err != nil { return c.JSON(http.StatusInternalServerError, map[string]interface{}{ \"err\": err.Error(), }) } return c.JSON(http.StatusCreated, map[string]interface{}{ \"book\": createdBook, }) } } it checks if the author exists if author exists, then create the book in the database. Here is an example request and response from the server. curl --location 'http://localhost:3030/api/book' \\ --header 'Content-Type: application/json' \\ --data '{ \"book_name\": \"The Idiot\", \"author_id\": \"654e619760034d917aa0ae64\" }' Response { \"book\": { \"title\": \"The Idiot\", \"author\": { \"id\": \"654e619760034d917aa0ae64\", \"name\": \"Marcus Aurelius\" }, \"likes\": 0 } } As we can see the book is created and returned from the response. To test this endpoint end2end way you need to pass the correct body, expected response and expected response status code. I already created the json files for you. request body: https://github.com/ocakhasan/golang-mongo-rest-api/blob/main/internal/controllers/integration_test/requests/create_book_success.json response body: https://github.com/ocakhasan/golang-mongo-rest-api/blob/main/internal/controllers/integration_test/responses/create_book_response.json Let’s write the test function package integrationtest import ( \"context\" \"fmt\" \"log\" \"net/http\" \"os\" \"testing\" \"github.com/labstack/echo/v4\" \"github.com/ocakhasan/mongoapi/internal/controllers\" \"github.com/ocakhasan/mongoapi/internal/repository\" \"github.com/ocakhasan/mongoapi/pkg/router\" \"github.com/steinfletcher/apitest\" \"github.com/steinfletcher/apitest-jsonpath\" \"go.mongodb.org/mongo-driver/mongo\" ) var ( testDbInstance *mongo.Database ) func TestMain(m *testing.M) { log.Println(\"setup is running\") testDB := SetupTestDatabase() testDbInstance = testDB.DbInstance populateDB() exitVal := m.Run() log.Println(\"teardown is running\") _ = testDB.container.Terminate(context.Background()) os.Exit(exitVal) } func InitializeTestRouter() *echo.Echo { postgreRepo := repository.New(testDbInstance) userController := controllers.New(postgreRepo) return router.Initialize(userController) } func TestCreatePostSuccess(t *testing.T) { apitest.New(). Handler(InitializeTestRouter()). Post(\"/api/book\"). Header(\"content-type\", \"application/json\"). BodyFromFile(\"requests/create_book_success.json\"). Expect(t). Status(http.StatusCreated). BodyFromFile(\"responses/create_book_response.json\"). End() } Let’s analyze the commands step by step. apitest.New(): New creates a new api test. The name is optional and will appear in test reports Handler(InitializeTestRouter()): initializes the endpoints and their corresponding handlers. Post(\"/api/book\").: sends a POST request to /api/book endpoint. Header(\"content-type\", \"application/json\").: sets the content-type header. BodyFromFile(\"requests/create_book_success.json\"): reads the body from given file and sets the request bo","date":"2023-11-10","objectID":"/golang-mongo-db-rest-api-integration-tests/:3:4","tags":["golang","mongodb","rest","tests"],"title":"Integration Testing for MongoDB-Backed REST APIs with Golang","uri":"/golang-mongo-db-rest-api-integration-tests/"},{"categories":null,"content":"beklenti nedir? beklenti, bir olayın sonunda olmasını umut ettiğiniz, gerçekleşmesini beklediğiniz şeye denir. çok basit gibi görünen bu kelimenin hayatımıza olan etkisi çok fazladır. çünkü insanlar hayatı boyunca sürekli bir şeyleri başarmak ya da elde etmek için çalışır ve çalışmalarının sonucunda bir ödül almayı beklerler. önemli bir sınavınız vardır, çok çalışmışsınızdır ve güzel bir not almayı bekliyorsunuzdur. işinizde gereğinden fazla çalışıyorsunuzdur, çünkü terfi almayı bekliyorsunuzdur. ilişkilerinizde bile karşınızdaki insandan belli beklentileriniz vardır. bu hayatın her alanında neredeyse böyledir. insan duygusal bir varlıktır ve belirlenen yüksek beklentiler, güzel şeyler başarsanız bile, sizin aslında hayattan daha az keyif almanıza yol açabilir. disclaimer benim bu konu hakkında herhangi bir uzmanlığım yok, sadece okuduğum ve deneyimlediğim şeyler üzerinde yazıyorum. ","date":"2023-10-27","objectID":"/expectations/:1:0","tags":["life","thoughts"],"title":"(tr) beklentiler","uri":"/expectations/"},{"categories":null,"content":"beklenti ve mutluluk hayatınızda eğer bir şeyler için çabaladığınızı düşünüyorsanız ve hala mutsuzsanız bunun birkaç sebebi olabilir. mutluluğunuzu çok fazla dış etkenlere bağlıyorsunuz (iş, başarı, ilişki vb.) beklentileriniz çok yüksek ve beklentilerinizi karşılayamıyorsunuz. nereden gördüm bilmiyorum ancak çok sevdiğim bir söz var unknown expect the worst, hope for the best. (en kötüsünü bekle, en iyisini umut et) şuanki durumunuzdan daha kötü durumda da olabilirdiniz. stoacılar genellikle kendilerini oldukları durumdan çok daha kötü bir durumda olabileceklerini düşünürler. bunları yapmalarının sebepleri: geleceği daha kötü hayal etmek sizi istenmeyen durumlara hazırlamaya yardım eder. durumunuzun çok daha kötü olabileceğini düşünmek aslında sizi şuanda sahip olduğunuz şeylerin değerini daha iyi anlamanıza yardımcı olacaktır. örnek bir alıntı ile devam edelim. unknown ayakkabım olmadığı için ağladım, daha sonra hiç ayağı olmayan biriyle tanıştım. bu hayatın her durumunda böyledir. sağlıklısınızdır, ekonomik olarak ortalama bir durumdasınızdır ancak mutlu değilsinizdir. sahip olduğunuz şeylerin mutlu olmanız için yeterli olmadığını düşünüyorsunuzdur. daha sonrasında ise bir yakınınızı kaybettiğinizde ya da sizin durumunuzdan daha kötü bir durumda olan birini gördüğünüzde içinizde bir şükür duygusu belirecektir. benim de kendim için beklentilerim hep yüksekti ve hala daha tam potensiyelimi kullanamadığımı düşünüyorum, lisede veya üniversite de kendimi hep daha büyük işler yaparken hayal ediyordum. böyle hedeflerimizin olması güzel ancak bu durum benim şuanda sahip olduklarımdan aldığım tatminlik duygusunu azaltabilir, bundan dolayı aslında kendime bir bakıma zarar vermiş oluyorum. aslında yaptığımın yanlış olduğunu, gayet iyi durumda olduğumun farkına varmam gerekir, çünkü çevremdeki çoğu insanın benim durumumda olmak için bir şeylerinden feragat edebileceğini biliyorum. insanın sahip olduklarının değerini bilmesi, şükretmesi gerekir. bunu herkes hayatında onlarca kez duymuştur ancak açgözlülük insana bu duyguları uygulamada zorluk çıkarıyor. ","date":"2023-10-27","objectID":"/expectations/:2:0","tags":["life","thoughts"],"title":"(tr) beklentiler","uri":"/expectations/"},{"categories":null,"content":"insanlardan beklentiler çoğu zaman beklentilerimizden çektiğimiz sorunlar tek bir cümle ile özetlenebilir. insanlar kendi bildikleri gibi davranırlar, bizim onlardan beklediğimiz gibi değil. insanlar birbirlerinden çok farklıdır ve bu farklılıkların eğitim, kültür, zenginlik, büyüdüğü çevre gibi bir sürü nedeni olabilir. insanlardan belirli başlı davranışları beklemek sizi hayal kırıklığına uğratabilir, bunun bilincinde olmalısınız. çünkü hiç kimse size sizin onlara davrandığınız gibi, ya da ondan davranmasını beklediğiniz gibi davranmak zorunda değil. insanlar sizin doğrularınız ile değil kendi bildikleri doğrular ile hareket eder. siz eğer insanlardan belirli bir beklentiyle davranmalarını beklerseniz, beklediğiniz gibi davranmadığını ilk gördüğünüz an hayal kırıklığına uğrayacaksınız. ondan dolayı hepimizin birbirimizden farklı bireyler olduğunu unutmamalı ve buna göre kendimizi hazırlamalıyız. ","date":"2023-10-27","objectID":"/expectations/:3:0","tags":["life","thoughts"],"title":"(tr) beklentiler","uri":"/expectations/"},{"categories":null,"content":"beklentiler nasıl belirlenmeli beklentilerimizin bizi mutsuz edebileceğini, bundan dolayı kendimiz için daha doğru ve gerçekçi hedefler, beklentiler belirlemenin daha iyi olduğunu yazdık. peki bu hayallerimizden vazgeçmemiz anlamına mı geliyor? tabi ki de hayır, hayatımızda her zaman bizi etkileyen olaylar, imrendiğiniz insanlar olacaktır. keşke şu durumda olsam diyeceksiniz ancak her şeyin sizin kontrolünüzde olmadığını da bilmek gerekir. eğer bir sınavdan yüksek almak istiyorsanız, böyle bir beklentiniz varsa o zaman çok çalışmalısınız. hiç çalışmayıp, güzel bir not beklediğiniz zaman, beklediğiniz notu alamadığınızı gördüğünüzde üzülmemek gerekir. kötü bir örnek oldu belki ama hedeflerimiz elbet olacak, ancak bu hedeflere ulaşmak için çabalamıyorsak belki de öyle hedeflere sahip olmamamız gerekir. yukarıda bahsettiğim gibi ben kendi potansiyelimi hala tam kullanamadığımı düşünüyorum ancak şuan bu konuyu düzeltmek için harcadığım ekstra bir mesai yok. bundan dolayı böyle bir düşünce bana ancak şükürsüzlük, dolayısıyla tatminsizlik verecektir ki ben bunun farkındayım ve bu yazıyı yazarken böyle bir düşünceye en azından şuan sahip olmamam gerektiğini görebiliyorum. umarım güzel bir yazı olmuştur, okuduğunuz için teşekkür ederim. güzel bir alıntı ile yazıyı bitiriyorum. Marcus Aurelius, Meditations very little is needed to make a happy life; it is all within yourself in your way of thinking. ","date":"2023-10-27","objectID":"/expectations/:4:0","tags":["life","thoughts"],"title":"(tr) beklentiler","uri":"/expectations/"},{"categories":null,"content":"references foundation 2: expectation reality vs expectations ","date":"2023-10-27","objectID":"/expectations/:5:0","tags":["life","thoughts"],"title":"(tr) beklentiler","uri":"/expectations/"},{"categories":null,"content":"SQS (Simple Queue Service) Query Examples This page should help you to understand how to use AWS SQS with golang using the official aws-sdk-go-v2/service/sqs. We will start with some basics like how to create the client to rather more complex operations such as Sending Message etc. ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:0:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"Setup Connecting Go application to SQS Client is quite easy. You just need to load your config and create the client. You need to get the below packages go get -u github.com/aws/aws-sdk-go-v2/config go get -u github.com/aws/aws-sdk-go-v2/service/sqs package main import ( \"context\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) func main() { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(err) } sqsClient := sqs.NewFromConfig(cfg) } ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:1:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"Create Queue AS we know, the messages are stored in the queues, so without a queue we will not be able to operate any function. Creating queues from AWS CLI is quite easy, it is also easy with AWS SDK. Let’s create a queue with the name test_queue. package main import ( \"context\" \"log\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) func main() { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(err) } sqsClient := sqs.NewFromConfig(cfg) queue, err := sqsClient.CreateQueue(context.TODO(), \u0026sqs.CreateQueueInput{ QueueName: aws.String(\"test_queue\"), Attributes: nil, Tags: nil, }) if err != nil { panic(err) } log.Printf(\"the queue url is %v\", *queue.QueueUrl) } Now we have a queue with the name test_queue. ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:2:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"Fetch Queue URL Some operations such as sending message to a queue or deleting the queue needs the queue url as input. Even though we know the name of the queue, we still need to fetch the URL of it. It is quite easy. package main import ( \"context\" \"log\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) func main() { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(err) } sqsClient := sqs.NewFromConfig(cfg) queue, err := sqsClient.GetQueueUrl(context.TODO(), \u0026sqs.GetQueueUrlInput{ QueueName: aws.String(\"test_queue\"), QueueOwnerAWSAccountId: nil, }) if err != nil { panic(err) } log.Printf(\"the queue url is %v\", *queue.QueueUrl) } ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:3:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"Delete Queue Deleting the queue is also quite easy. You just need to call the DeleteQueue function. You will be using this a lot if you create temporary queues and need to delete them after a while. package main import ( \"context\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) func main() { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(err) } sqsClient := sqs.NewFromConfig(cfg) queue, err := sqsClient.GetQueueUrl(context.TODO(), \u0026sqs.GetQueueUrlInput{ QueueName: aws.String(\"test_queue\"), QueueOwnerAWSAccountId: nil, }) if err != nil { panic(err) } _, err = sqsClient.DeleteQueue(context.TODO(), \u0026sqs.DeleteQueueInput{QueueUrl: queue.QueueUrl}) if err != nil { panic(err) } } ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:4:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"List Queues Sometimes we need to list the queues to see which queues there are in the AWS. You can even set a prefix to get the queues with wanted prefix. Let’s fetch the queues with prefix test. package main import ( \"context\" \"log\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) func main() { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(err) } sqsClient := sqs.NewFromConfig(cfg) queues, err := sqsClient.ListQueues(context.TODO(), \u0026sqs.ListQueuesInput{ MaxResults: nil, NextToken: nil, QueueNamePrefix: aws.String(\"test\"), }) if err != nil { panic(err) } for _, queueUrl := range queues.QueueUrls { log.Println(queueUrl) } } ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:5:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"Send Message The most important part of the queues is mostly is receiving \u0026 sending messages part. The whole point of the queue is to become the middle man which has the responsibility of taking and delivering the messages. Sending a message in SQS quite easy. package main import ( \"context\" \"encoding/json\" \"log\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) type YourStruct struct { Artist string Song string } func main() { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(err) } sqsClient := sqs.NewFromConfig(cfg) data := YourStruct{ Artist: \"Queen\", Song: \"The Show Must Go On\", } bytes, _ := json.Marshal(\u0026data) queue, _ := sqsClient.GetQueueUrl(context.TODO(), \u0026sqs.GetQueueUrlInput{ QueueName: aws.String(\"test_queue\"), }) res, err := sqsClient.SendMessage(context.TODO(), \u0026sqs.SendMessageInput{ MessageBody: aws.String(string(bytes)), QueueUrl: queue.QueueUrl, DelaySeconds: 0, MessageAttributes: nil, MessageDeduplicationId: nil, MessageGroupId: nil, MessageSystemAttributes: nil, }) if err != nil { panic(err) } log.Printf(\"the message with id %v is sent\", *res.MessageId) } ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:6:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"Receive Message The other most important part of the queues are receiving the message, because as we know the messages are only sent for someone to read it. I think that could be a good quote so let’s make a one. Hasan Ocak Messages are only sent for someone to read it. Handling messages in SQS can be quite complex. If you want to learn how to receive message and handle them in parallel, check out my other post Golang Sqs Consumer Worker Pool. package main import ( \"context\" \"log\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) func main() { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(err) } sqsClient := sqs.NewFromConfig(cfg) queue, _ := sqsClient.GetQueueUrl(context.TODO(), \u0026sqs.GetQueueUrlInput{ QueueName: aws.String(\"test_queue\"), }) messages, err := sqsClient.ReceiveMessage(context.TODO(), \u0026sqs.ReceiveMessageInput{ QueueUrl: queue.QueueUrl, AttributeNames: nil, MaxNumberOfMessages: 10, // max is 10 MessageAttributeNames: nil, ReceiveRequestAttemptId: nil, VisibilityTimeout: 0, WaitTimeSeconds: 0, }) if err != nil { panic(err) } for _, message := range messages.Messages { log.Printf(\"the message body is %v\", *message.Body) } } Output will be something like this 2023/10/18 22:22:57 the message body is {\"Artist\":\"Queen\",\"Song\":\"The Show Must Go On\"} ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:7:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"How to Decode the Message Into Your Struct You just need to decode it via json.Unmarshal to your struct. for _, message := range messages.Messages { var data YourStruct _ = json.Unmarshal([]byte(*message.Body), \u0026data) log.Printf(\"the received data is %+v\", data) } ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:7:1","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"Delete Message In general after handling the message, you will want to delete the message so it will not be received and handled again. Of course this can change according to your needs. Deleting the message is quite easy. package main import ( \"context\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) type YourStruct struct { University string Major string Level string } func main() { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(err) } sqsClient := sqs.NewFromConfig(cfg) queue, _ := sqsClient.GetQueueUrl(context.TODO(), \u0026sqs.GetQueueUrlInput{ QueueName: aws.String(\"test_queue\"), }) // It can be read from message variable after receiving from SQS messageHandle := \"YOUR_MESSAGE_HANDLE\" _, err = sqsClient.DeleteMessage(context.TODO(), \u0026sqs.DeleteMessageInput{ QueueUrl: queue.QueueUrl, ReceiptHandle: \u0026messageHandle, }) if err != nil { panic(err) } } ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:8:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"Purge Queue If you want to delete all of the messages in the queue, you need to use the PurgeQueue method. package main import ( \"context\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" ) func main() { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(err) } sqsClient := sqs.NewFromConfig(cfg) queue, _ := sqsClient.GetQueueUrl(context.TODO(), \u0026sqs.GetQueueUrlInput{ QueueName: aws.String(\"test_queue\"), }) _, err = sqsClient.PurgeQueue(context.TODO(), \u0026sqs.PurgeQueueInput{ QueueUrl: queue.QueueUrl, }) if err != nil { panic(err) } } ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:9:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"Motivation This post is too basic with SQS but it might help a beginner programmer who is trying to do some stuff with SQS. While I was doing some development with DynamoDB, I got help from this blog. It really helped me to get the development going. I wanted to do it the same with SQS. The reason I do it with SQS is I work with it often, so I know some stuff about it. Hope, it will help you. If it helps or not, you can reach out to me. Let’s end the topic with a calming music. Enjoy 🎵 💻 ","date":"2023-10-18","objectID":"/aws-sqs-golang-function-examples/:10:0","tags":["golang","sqs","aws"],"title":"AWS SQS SDK \u0026 Golang Complete Cheat Sheet","uri":"/aws-sqs-golang-function-examples/"},{"categories":null,"content":"Hello Guys, In this post we will analyze some of my bullet games on Lichess. I love playing chess, and I try to play bullet games almost every day, at least 3-4 games. I thought, it is time to analyze some of my games with Python. To be able to do it, we need to use the Lichess API to export my games. There is already a client package implemented in Python3 called Berserk, so I will be using it. We will use pandas to manipulate the data and matplotlib to plot some charts (hopefully we will get some meaning based on them). I have more than 5000 games as of the data 16th Oct 2023. We will be analyzing last 1000 games. Let’s begin. I got help from ChatGPT while creating this notebook. Lichess Server Crash Image ","date":"2023-10-16","objectID":"/analysis-of-chess-games/:0:0","tags":["chess","python","data"],"title":"Analysis Of My Lichess Bullet Games","uri":"/analysis-of-chess-games/"},{"categories":null,"content":"Fetch the Games import berserk import pandas as pd import numpy as np import matplotlib.pyplot as plt with open('./lichess.token') as f: token = f.read() session = berserk.TokenSession(token) client = berserk.Client(session) client.games.export_by_player('IsaacNewton29', opening=True, perf_type=\"bullet\", max=1000) \u003cgenerator object Games.export_by_player at 0x1455dbcf0\u003e games = list(_) df = pd.DataFrame(games) df = df.drop(columns=['id', 'rated', 'variant', 'speed', 'perf', 'clock', 'lastMoveAt']) df.head(2) createdAt status players winner opening moves 0 2023-10-16 17:34:35.325000+00:00 mate {'white': {'user': {'name': 'Chessington008', ... white {'eco': 'B01', 'name': 'Scandinavian Defense: ... e4 d5 exd5 Qxd5 Nc3 Qd8 Bc4 Nc6 Nf3 Nf6 d4 e6 ... 1 2023-10-16 14:06:40.830000+00:00 outoftime {'white': {'user': {'name': 'IsaacNewton29', '... black {'eco': 'C00', 'name': 'French Defense', 'ply'... e4 e6 Bc4 d5 exd5 exd5 Be2 c6 Nf3 Nf6 d4 Bd6 N... df.createdAt.min().date(), df.createdAt.max().date() (datetime.date(2022, 12, 15), datetime.date(2023, 10, 16)) It seems like I played the last 1000 games between the dates 12th December 2022 and 16th October 2023. Let’s extract the white and black players for each game. It will be useful df[\"white\"] = df[\"players\"].apply(lambda x: x[\"white\"][\"user\"][\"name\"]) df[\"black\"] = df[\"players\"].apply(lambda x: x[\"black\"][\"user\"][\"name\"]) df[df[\"white\"] == \"IsaacNewton29\"].shape (490, 8) df[df[\"black\"] == \"IsaacNewton29\"].shape (510, 8) df[((df[\"white\"] == \"IsaacNewton29\") \u0026 (df[\"winner\"] == \"white\")) | ((df[\"black\"] == \"IsaacNewton29\") \u0026 (df[\"winner\"] == \"black\"))].shape (495, 8) df[(df[\"black\"] == \"IsaacNewton29\") \u0026 (df[\"winner\"] == \"black\")].shape (224, 8) # Count the occurrences of each category category_counts = df['winner'].value_counts() # Plot a bar chart with counts displayed on top of each bar plt.figure(figsize=(8, 6)) bars = plt.bar(category_counts.index, category_counts.values, color='skyblue') # Add counts as labels on top of the bars for bar in bars: yval = bar.get_height() plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), ha='center', va='bottom') plt.xlabel('Player') plt.ylabel('Count') plt.title('Winner Counts Based on Color') plt.xticks(rotation=0) # Rotate x-axis labels if necessary plt.show() Let’s create a new column to check if I won that game. To get the value If the winner is white check if I play white If the winner is black check if I play black df[\"did_i_win\"] = ((df[\"white\"] == \"IsaacNewton29\") \u0026 (df[\"winner\"] == \"white\")) | ((df[\"black\"] == \"IsaacNewton29\") \u0026 (df[\"winner\"] == \"black\")) df[\"did_i_win\"].value_counts() did_i_win False 505 True 495 Name: count, dtype: int64 Let’s see on the chart to understand it better. # Count the occurrences of each category category_counts = df['did_i_win'].value_counts() # Plot a bar chart with counts displayed on top of each bar plt.figure(figsize=(8, 6)) bars = plt.bar(category_counts.index.values, category_counts.values, color='skyblue') # Add counts as labels on top of the bars for bar in bars: yval = bar.get_height() plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), ha='center', va='bottom') plt.xlabel('Is the Game a Win') plt.ylabel('Count') plt.title('Did I Win the Game') plt.xticks(range(len(category_counts.index)), category_counts.index) # Set x-tick labels plt.show() It seems like I lost 505 games whereas I won the 495 games, it is almost 50/50. No improvement at all 😄 It will be continued… ","date":"2023-10-16","objectID":"/analysis-of-chess-games/:1:0","tags":["chess","python","data"],"title":"Analysis Of My Lichess Bullet Games","uri":"/analysis-of-chess-games/"},{"categories":null,"content":" Disclaimer Ben bu konu hakkında uzman değilim, sadece kendi fikirlerimi beyan ediyorum. Son zamanlarda Stoacılık ile alakalı çok fazla içerik görmeye başladım. Daha sonra merak ettim ve aslında bana da çokça uyan bir felsefi düşünce olduğunu gördüm. Bunla alakalı meşhur bir kitap olan Donald Robertson’dan Marcus Aurelius'un Stoacı Felsefesi: Roma İmparatoru Gibi Düşünmek kitabını satın aldım ve bu kitabı okumak bana askerliğimi yaparken nasip oldu. Bol bol boş vaktim olunca hem okuyup hem de üstüne düşündüm ve bazı düşünceler gerçekten çok hoşuma gitmeye başladı, hatta askerliğime bile katkısı oldu diyebilirim. Bunu ilerleyen bölümlerde açıklayacağım. ","date":"2023-10-14","objectID":"/review-of-how-to-think-like-roman-emperor/:0:0","tags":["stoic","thoughts","life"],"title":"(TR) Stoacılık, Bilişsel Mesafe Koyma","uri":"/review-of-how-to-think-like-roman-emperor/"},{"categories":null,"content":"Stoacılık Vikipedia’ya göre Stoacılık Quote Stoacılık, MÖ 3. yüzyılın başlarında Atina Agorası’nda Kıbrıslı Zenon tarafından kurulan bir Helenistik felsefe ekolüdür. Mantık sistemi ve doğal dünya hakkındaki görüşleriyle beslenen bir kişisel erdem etiği felsefesidir ve erdem pratiğinin eudaimonia’ya ulaşmak için hem gerekli hem de yeterli olduğunu savunur: kişi etik bir yaşam sürerek gelişir. Stoacılar eudaimonia’ya giden yolu erdemi uygulayarak ve doğaya uygun yaşayarak geçirilen bir hayatla özdeşleştirmişlerdir. ","date":"2023-10-14","objectID":"/review-of-how-to-think-like-roman-emperor/:1:0","tags":["stoic","thoughts","life"],"title":"(TR) Stoacılık, Bilişsel Mesafe Koyma","uri":"/review-of-how-to-think-like-roman-emperor/"},{"categories":null,"content":"Kitap: Roma İmparatoru Gibi Düşünmek Bu kitap meşhur Stoacı Marcus Aurelius Stoacı felsefeyi gündelik hayatına nasıl uyguladığını ve günlük yaşamda nasıl kullanabileceğini anlatıyor. Kitapta genel olarak anlatılan konular Stoacı Felsefenin Temelleri Marcus Aurelius’un Hayatı ve Öğretileri Şimdiye Odaklanma Zorlukları Kabul Etme Erdemli Yaşam Peki kimdir Marcus Aurelius Wikipedia Marcus Aurelius Antoninus Augustus (26 Nisan 121 – 17 Mart 180), 161 - 180 yılları arası Roma İmparatoru. 96 - 180 yılları arasında görev yapan Beş İyi İmparator’dan sonuncusudur ve aynı zamanda en önemli Stoacı filozoflardan biri olarak kabul edilir. Tüm detayları internette kolayca bulabilirsiniz, bu yazıda ben sadece kitaptaki en çok ilgimi çeken terim olan Bilişsel Mesafe terimini tartışacağım. ","date":"2023-10-14","objectID":"/review-of-how-to-think-like-roman-emperor/:2:0","tags":["stoic","thoughts","life"],"title":"(TR) Stoacılık, Bilişsel Mesafe Koyma","uri":"/review-of-how-to-think-like-roman-emperor/"},{"categories":null,"content":"Bilişsel Mesafe Koyma (Cognitive Distancing) Bilişsel mesafe koyma Stoacı felsefede en önemli acı yönetimi stratejisidir, Marcus Aurelis ve hocası Epiktetos tarafından bolca dile getirilmiştir. Sadece acı yönetimi değil aynı zamanda arzulardan kurtulma yolunda da kullanabilen bir yöntemdir. Kısaca şöyle açıklanabilir. Bilişsel Mesafe Koyma Bizi üzen olayların kendisi değil, onlar hakkındaki yargılarımızdır. Eğer yargıları bir kenara koyarsak çektiğimiz acı hafifler. Stoacı bilgeler acının da yaşamın bir parçası olduğunu, bunu inkar etmememiz gerektiğinden bahsediyor. Duyguları bastırmamalı, duyguların doğal olduğunu ancak olabildiğince duygularımızdan da bağımsız kalabilmeyi öğütler. Buradaki en önemli konu duygulara zarar bakış açısından bakmamamız gerektiğidir. Herhangi bir şeyin size zararlı ya da faydalı olmasının sizin hayattaki hedef ve amaçlarınıza bağlı olduğunu söyler. Çok güzel bir alıntı ile devam edelim Marcus Aurelius Yargıyı yok et. ‘Zarar gördüm’ düşüncesi de yok olur: o düşünceyi yok et, zararın kendisi de yok olur. ","date":"2023-10-14","objectID":"/review-of-how-to-think-like-roman-emperor/:3:0","tags":["stoic","thoughts","life"],"title":"(TR) Stoacılık, Bilişsel Mesafe Koyma","uri":"/review-of-how-to-think-like-roman-emperor/"},{"categories":null,"content":"Örnekler İlk bu cümleyi okuduğumda aslında çok basit ama bir o kadar da gerçek olduğunu fark ettim. Kitapta bunu gündelik hayattaki örneklerle açıklayınca kendim ve çevremdeki bir çok insanın da bunu yaptığını fark ettim. Çok basit bir örnek olarak baş ağrınız bulunuyor, ve siz kendinize şu cümleyi söylüyorsunuz: Bu baş ağrısına dayanamıyorum, beni öldürecek! Bu tarz bir düşüncenin aslında sizin ağrınızı psikolojik olarak daha da çoğalttığını fark edeceksiniz, eğer objektif bir şekilde düşününce bu ağrının size zarar verdiğini ancak sizi öldürecek kadar şiddetli bir ağrı olmadığını göreceksiniz ve eninde sonunda bu ağrı gidecek. İlk defa bu terimi duyduğumda öncelikle çevremdeki hastalıkları hakkında çok fazla söylenen kişiler aklıma geldi, ben de bunlardan biriydim. Herhangi bir soğuk algınlığı vesaire durumunda sanki dünyanın sonuymuş gibi “Çok kötüyüm, ne zaman iyileşeceğim” moduna giriyordum ve bu söylemler hastalığı daha da beter bir hale getiriyordu. Bunu sadece hastalık anlamında düşünmeyin, hayatta sizi üzen herhangi bir olay olabilir. İşten kovulmuşsunuzdur, kız/erkek arkadaşınızdan ayrılmışsınızdır vesaire. Tabii ki yargılarını bir kenara bırak demek kolay ancak aksiyon almak zor. Askerdeyken bu kitabı okurken Bilişsel Mesafe Koyma yöntemi çok mantıklı geldi ve uygulamaya çalıştım. Bazı konularda başarılı olduğumu düşünüyorum ancak bazı konularda ne kadar olayları yargılamayı bıraksak da işin içine duygular girebiliyor, sizi üzebiliyor ya da sevindirebiliyor. Her ne kadar insanı acıdan uzaklaştırmasa da bu yönde çalışmak bile insana iyi gelebilir. Ne yazık ki çabaladığım halde bu terimi hayatıma tam uygulayabildiğimi düşünmüyorum ancak daha yolun başındayım ve bu konu hakkında daha fazla araştırma yapıp daha iyi hayatıma uygulayacağımı ümit ediyorum. İlk başta bu kitabın askerliğime yardımcı olduğunu söylemiştim. Kısa süreli bir askerlik yapsam da nasıl yardımcı olduğunu söyleyeyim. İlk zamanlar, ne zaman bitecek bu askerlik diyip kaç günüm kaldığını her gün kontrol ediyordum. Kitabı okuduktan sonra, bu düşüncenin aslında zararlı olduğunu, eninde sonunda bu görevin biteceğini, olabildiğince bu görevden faydalanmam gerektiğini düşündüm Daha çok insanla tanışmaya çalıştım, güzel insanlarla tanıştım ve artık gün saymayı bıraktım. Sadece şu tarihte eve döneceğim diyordum. Hatta bir ara askerlik çok keyifli gelmeye başladı ancak bu his kısa sürdü tabii ki Dediğim gibi hala bu konu üzerinde çalışıyorum. İleride bu terimi daha iyi entegre edebildiğimi görürsem bu yazıyı güncelleyeceğim. 🤝 Son Not Bundan sonra sadece teknik konular üzerinde değil canımın istediği her bir konu hakkında yazacağım. Bu yazılarımın az okunduğunu da biliyorum. Aslında burayı kendime bir arşiv olarak görüyorum. Blogumu bu zamana kadar destekleyen ve az sayıda olan düzenli okuyucularıma teşekkürlerimi sunarım 🙃 Umarım keyifli bir okuma olmuştur. Okuduğunuz için teşekkürler. ","date":"2023-10-14","objectID":"/review-of-how-to-think-like-roman-emperor/:3:1","tags":["stoic","thoughts","life"],"title":"(TR) Stoacılık, Bilişsel Mesafe Koyma","uri":"/review-of-how-to-think-like-roman-emperor/"},{"categories":null,"content":"REFERENCES Stoacılık Marcus Aurelius Epiktetos ","date":"2023-10-14","objectID":"/review-of-how-to-think-like-roman-emperor/:4:0","tags":["stoic","thoughts","life"],"title":"(TR) Stoacılık, Bilişsel Mesafe Koyma","uri":"/review-of-how-to-think-like-roman-emperor/"},{"categories":null,"content":"Introduction In the ever-evolving landscape of web development, GraphQL has emerged as a powerful alternative to traditional RESTful APIs. Its flexibility and efficiency have led many developers to consider migrating their REST endpoints to GraphQL. In this blog post, we will explore the process of converting a RESTful endpoint to GraphQL, unlocking the benefits of a more customizable and efficient data-fetching experience. Join us on this journey as we delve into the world of GraphQL and transform a RESTful API into a GraphQL powerhouse. ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:1:0","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"Rest API Implementation Let’s say that we have a server with a REST Endpoint structured as below. curl http://localhost:8080/artists and it returns [ { \"name\": \"The Weeknd\", \"age\": 30, \"tracks\": [ { \"name\": \"Creepin\", \"duration\": 222 } ] }, { \"name\": \"Tame Impala\", \"age\": 30, \"tracks\": [ { \"name\": \"Let It Happen\", \"duration\": 467 } ] } ] This endpoint simply can be handled by this below code. package main import ( \"encoding/json\" \"log\" \"net/http\" ) type Track struct { Name string `json:\"name\"` Duration int `json:\"duration\"` // in seconds } type Artist struct { Name string `json:\"name\"` Age int `json:\"age\"` Tracks []Track `json:\"tracks\"` } var data = []Artist{ { Name: \"The Weeknd\", Age: 30, Tracks: []Track{ {Name: \"Creepin\", Duration: 222}, }, }, { Name: \"Tame Impala\", Age: 35, Tracks: []Track{ {Name: \"Let It Happen\", Duration: 467}, }, }, } func main() { mux := http.NewServeMux() mux.HandleFunc(\"/artists\", func(w http.ResponseWriter, r *http.Request) { if err := json.NewEncoder(w).Encode(\u0026data); err != nil { return } }) log.Fatal(http.ListenAndServe(\":8080\", mux)) } ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:2:0","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"Structure Change But you only want some of the fields maybe like [ { \"name\": \"The Weeknd\", \"tracks\": [ { \"name\": \"Creepin\", } ] }, { \"name\": \"Tame Impala\", \"tracks\": [ { \"name\": \"Let It Happen\", } ] } ] You want to make it as a GraphQL query maybe something like query { getArtists { name tracks { name } } } Question is how to change this really simple API to a graphQL endpoint. ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:2:1","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"GraphQL Implementation For this we will use the package of https://github.com/99designs/gqlgen, you can have a look. To start the project, we will follow the quick quide. First create the project mkdir example cd example go mod init example Add 99designs/gqlgen to your project’s tools.go printf '// +build tools\\npackage tools\\nimport (_ \"github.com/99designs/gqlgen\"\\n _ \"github.com/99designs/gqlgen/graphql/introspection\")' | gofmt \u003e tools.go go mod tidy Initialise gqlgen config and generate models go run github.com/99designs/gqlgen init go mod tidy Start the graphql server go run server.go ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:3:0","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"Project structure Your folder structure should look like this ├── go.mod ├── go.sum ├── gqlgen.yml ├── graph │ ├── generated.go │ ├── model │ │ └── models_gen.go │ ├── resolver.go │ ├── schema.graphqls │ └── schema.resolvers.go ├── server.go └── tools.go ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:3:1","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"Generated Code and GraphiQL Playground Your server.go will look like this package main import ( \"log\" \"net/http\" \"os\" \"github.com/99designs/gqlgen/graphql/handler\" \"github.com/99designs/gqlgen/graphql/playground\" \"github.com/ocakhasan/graph/graph\" ) const defaultPort = \"8080\" func main() { port := os.Getenv(\"PORT\") if port == \"\" { port = defaultPort } srv := handler.NewDefaultServer(graph.NewExecutableSchema(graph.Config{Resolvers: \u0026graph.Resolver{}})) http.Handle(\"/\", playground.Handler(\"GraphQL playground\", \"/query\")) http.Handle(\"/query\", srv) log.Printf(\"connect to http://localhost:%s/ for GraphQL playground\", port) log.Fatal(http.ListenAndServe(\":\"+port, nil)) } When you run all of the commands above and run the project you should see something like this on your project We will be testing our query from the UI to easily see the results. ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:3:2","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"GraphQL File There is an autogenerated file schema.graphqls, we will be setting our Artist and Track models here. type Artist { name: String! age: Int! tracks: [Track!]! } type Track { name: String! duration: Int! } type Query { artists: [Artist!]! } Then run below command to auto-generate models resolver etc, we will just fill the logic. go run github.com/99designs/gqlgen generate Then the schema.resolvers.go file will be like this package graph // This file will be automatically regenerated based on the schema, any resolver implementations // will be copied through when generating and any unknown code will be moved to the end. // Code generated by github.com/99designs/gqlgen version v0.17.36 import ( \"context\" \"fmt\" \"github.com/ocakhasan/graph/graph/model\" ) // Artists is the resolver for the artists field. func (r *queryResolver) Artists(ctx context.Context) ([]*model.Artist, error) { panic(fmt.Errorf(\"not implemented: Artists - artists\")) } // Query returns QueryResolver implementation. func (r *Resolver) Query() QueryResolver { return \u0026queryResolver{r} } type queryResolver struct{ *Resolver } We will fill the Artists method, it will be a simple returning array of model.Artist which is in the model/models_gen.go (auto-generated file) // Code generated by github.com/99designs/gqlgen, DO NOT EDIT. package model type Artist struct { Name string `json:\"name\"` Age int `json:\"age\"` Tracks []*Track `json:\"tracks\"` } type Track struct { Name string `json:\"name\"` Duration int `json:\"duration\"` } ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:3:3","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"Implementation of the Resolver To implement the resolver we will return a hardcoded array of model.Artist struct. package graph // This file will be automatically regenerated based on the schema, any resolver implementations // will be copied through when generating and any unknown code will be moved to the end. // Code generated by github.com/99designs/gqlgen version v0.17.36 import ( \"context\" \"github.com/ocakhasan/graph/graph/model\" ) var data = []*model.Artist{ { Name: \"The Weeknd\", Age: 30, Tracks: []*model.Track{ {Name: \"Creepin\", Duration: 222}, }, }, { Name: \"Tame Impala\", Age: 60, Tracks: []*model.Track{ {Name: \"Let It Happen\", Duration: 467}, }, }, } // Artists is the resolver for the artists field. func (r *queryResolver) Artists(ctx context.Context) ([]*model.Artist, error) { return data, nil } // Query returns QueryResolver implementation. func (r *Resolver) Query() QueryResolver { return \u0026queryResolver{r} } type queryResolver struct{ *Resolver } Let’s run the server again and go to GraphiQL playground (http://localhost:8080/). go run server.go Then go to http://localhost:8080 and paste the query query { artists { name } } it will return { \"data\": { \"artists\": [ { \"name\": \"The Weeknd\" }, { \"name\": \"Tame Impala\" } ] } } You can play with the editor and convert your rest endpoints to GraphQL easily. ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:3:4","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"REFERENCES In summary, transitioning from REST to GraphQL offers numerous benefits for your API. It’s a journey worth taking, promising improved efficiency and flexibility. So, take that step, and may your GraphQL journey be both rewarding and transformative. Happy coding! https://github.com/99designs/gqlgen ","date":"2023-09-07","objectID":"/golang-setup-graphql-server/:4:0","tags":["golang","network","rest","graphql"],"title":"Setting up a GraphQL Server in Golang","uri":"/golang-setup-graphql-server/"},{"categories":null,"content":"MOTIVATION I work as a Backend engineer almost 2 years now as of August 2023. My work mostly relies on database systems such as MySQL, Redis, Mongo etc. So it would be great to learn the internals or system designs related to those database systems. Also it is stated in the book that, aynone working on backend side who processes data and the applications they developed uses internet should read this book, so I am quite a fit for the people who should read this book. I will make a blog post on each of the chapter I read, mostly I will read after my working hours so it will probably take months for me to really finish this book. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:0:0","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"CHAPTER 1 - Reliable, Scalable and Maintainable Applications Most applications are data-intensive nowadays, the problems mostly related to amount of data etc. Most of the tools developed are highly advanced nowadays but none of them can meet all of the needs of different data processing and storing requirements. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:1:0","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"Definitions Reliability The system should continue to work correctly even though a system error occurs. tolerate human errors prevents unauthorized access there could be some hardware problems such as hard disk crashs, ram becomes faulty etc. design systems in a way that human errors opportunity are minimized. test your system, froom unit to integration tests. setup monitoring tools, perfomance metrics and error rates. Scalability The system should handle the load gracefully if the volume (data, network etc) grows. what happens to system resources when you increase the load to your system how much resource you need to increase when you increase the load. response time is what client sees, request sent and response is received from the client latency is the duration that a request is waiting to be handled in response times it is better to use percentile, not the average. because it does not tell you how many users are affected by a specific number of delay. Maintainability Project should be easily developed by many other engineers who work on the project. cost of software are mostly based on the ongoing mainteiance, not the initial software development. projects should be evolvable: meaning making changes should be easy. simple: a project should not be complex, should be easy to work with. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:1:1","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"CHAPTER 2 - Data Models and Query Languages ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:2:0","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"Relational Vs Document Model Most famous data format is SQL. Goal of relational model was to hide the implementation detail behind a cleaner interface rather than forcing developers to think the internal representation of the data. The driving forces for NoSQL (Document) Databases need for greater scalability specialized query operations not supported by SQL more dynamic and expressive data models. Chapter 2 will be continued. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:2:1","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"CHAPTER 3 - STORAGE AND RETRIEVAL On the most basic model, a database needs to do 2 operations. it should store the given data when ask it again later, it should give the data back. The questions needs to be asked as an application developer probably would not be how the database handles storage and retrieval internally? But if you have to tune the program you use, it is better to know the internals of the tool. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:3:0","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"WORLD SIMPLEST DATABASE Would be a key value store written into a file. db_set () { echo \"$1,$2\" \u003e\u003e database } db_get () { grep \"^$1,\" database | sed -e \"s/^$1,//\" | tail -n 1 } Similarly to what db_set function does, the databasess also uses a log internally, append-only data file. db_get function performance is terrible on large scale of data since it traverse the all of the file O(N). ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:3:1","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"Index To retrieve the data efficiently, you need an index. Index is an additional data which can be derived from the original set of data. Creating indexes may create an overhead to write operations, since it cannot be more efficient than writing to end of file. ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:3:2","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"HASH INDEXES ","date":"2023-08-27","objectID":"/notes-on-designing-data-intensive-applications/:3:3","tags":["backend","database","books"],"title":"My Notes on Designing Data Intensive Applications","uri":"/notes-on-designing-data-intensive-applications/"},{"categories":null,"content":"Motivation The motivation for me to write this blog post is that I want to have a consumer which uses goroutines for the messages received from SQS but almost all of the posts I read was did not exactly implemented as a worker pool integration. The posts uses new goroutines for each of the messages received and it might be useful for their case but if you process millions of records, creating and deleting millions of records might be a burden to garbage collector. So in this post, 10 goroutines will listen for all of the messages received. Note This case only will work if you need to process and delete the messages from the queue in each of the ReceiveMessage call. Otherwise, it might not be useful for your case. ","date":"2023-07-07","objectID":"/golang-sqs-consumer-worker-pool/:1:0","tags":null,"title":"Golang Sqs Consumer Worker Pool","uri":"/golang-sqs-consumer-worker-pool/"},{"categories":null,"content":"Design ","date":"2023-07-07","objectID":"/golang-sqs-consumer-worker-pool/:1:1","tags":null,"title":"Golang Sqs Consumer Worker Pool","uri":"/golang-sqs-consumer-worker-pool/"},{"categories":null,"content":"Implementation There are some things to consider. For our case the consumer should do following steps Receive message from the queue it can receive at most 10 messages in one single call to sqs. Send these 10 messages to the channel for workers to listen. Wait for these 10 messages process to finish. Release the workers so they can process again. It might be useful for your case, so please use with care with your judgement. ","date":"2023-07-07","objectID":"/golang-sqs-consumer-worker-pool/:2:0","tags":null,"title":"Golang Sqs Consumer Worker Pool","uri":"/golang-sqs-consumer-worker-pool/"},{"categories":null,"content":"CODE To understand the functions and methods used here, please have a visit to aws-sdk-go-v2/sqs import ( \"context\" \"sync\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/service/sqs\" \"github.com/aws/aws-sdk-go-v2/service/sqs/types\" ) type Consumer struct { client sqs.Client queueName string } func (consumer *Consumer) Start(ctx context.Context) { params := \u0026sqs.ReceiveMessageInput{ AttributeNames: []types.QueueAttributeName{types.QueueAttributeNameAll}, MaxNumberOfMessages: 10, // max it can receive MessageAttributeNames: []string{string(types.QueueAttributeNameAll)}, QueueUrl: aws.String(consumer.queueName), WaitTimeSeconds: 20, // wait for 20 seconds at max for at least 1 message to be received } msgCh := make(chan types.Message) var wg sync.WaitGroup startPool(ctx, msgCh, \u0026wg) for { select { case \u003c-ctx.Done(): close(msgCh) return default: resp, err := consumer.client.ReceiveMessage(ctx, params) if err != nil { log.Msg(\"cannot receive messages\") continue } // add number of messages received from the queue wg.Add(len(resp.Messages)) // send received messages to sqs, so they can be processed for _, message := range resp.Messages { msgCh \u003c- message } // wait for workers in the pool to be finished. wg.Wait() } } } // startPool starts 10 goroutines which listens to the msgCh which receives the // messages from the SQS. func startPool(ctx context.Context, msgCh chan types.Message, wg *sync.WaitGroup) { for i := 0; i \u003c 10; i++ { go func() { for { select { case \u003c-ctx.Done(): return case msg, channelClosed := \u003c-msgCh: // If the channel is closed if !channelClosed { return } // handle the message here, insert your logic. // release the waitgroup to inform that the message has been processed. wg.Done() } } }() } } ","date":"2023-07-07","objectID":"/golang-sqs-consumer-worker-pool/:2:1","tags":null,"title":"Golang Sqs Consumer Worker Pool","uri":"/golang-sqs-consumer-worker-pool/"},{"categories":null,"content":"Some Points Let’s say you are receiving 1 million daily throughput from the SQS. For the 10 messages you received if you create 5 goroutines in each time in the end you will create 500_000 goroutines. if you create 5 goroutines which listens to a channel and process those messages, then you will only create 5 goroutines. Thanks for reading. Any feedback is appreciated. ","date":"2023-07-07","objectID":"/golang-sqs-consumer-worker-pool/:3:0","tags":null,"title":"Golang Sqs Consumer Worker Pool","uri":"/golang-sqs-consumer-worker-pool/"},{"categories":null,"content":"Introduction Go is an excellent programming language for building HTTP servers, thanks to its net/http package in the standard library, which makes it easy to attach HTTP handlers to any Go program. The standard library also includes packages that facilitate testing HTTP servers, making it just as effortless to test them as it is to build them. Nowadays, test coverage is widely accepted as an essential and valuable part of software development. Developers invest time in testing their code to get quick feedback when making changes, and a good test suite becomes an invaluable component of the software project when combined with continuous integration and delivery methodologies. Given the importance of a good test suite, what approach should developers using Go take when testing their HTTP servers? This article provides everything you need to know to test your Go HTTP servers thoroughly. ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:0:0","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"Http Server For Conversion of Roman Numerals We will have a web server which gives the roman numeral of the given number. We will only have 1 endpoint. Show the roman numeral of the number GET /roman ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:1:0","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"Example Request and Response Request curl --location --request GET 'http://localhost:8080/roman?query=1' Response { \"output\": \"I\" } ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:1:1","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"Code and Explanation package main import ( \"encoding/json\" \"log\" \"net/http\" \"strconv\" ) var ( nums = []int{1, 4, 5, 9, 10, 40, 50, 90, 100, 400, 500, 900, 1000} symbols = []string{\"I\", \"IV\", \"V\", \"IX\", \"X\", \"XL\", \"L\", \"XC\", \"C\", \"CD\", \"D\", \"CM\", \"M\"} ) func convertIntegerToRoman(input int) string { var ( i = len(nums) - 1 result string ) for input \u003e 0 { division := input / nums[i] input = input % nums[i] for division \u003e 0 { result += symbols[i] division = division - 1 } i = i - 1 } return result } type romanHandler struct{} func (h romanHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { w.Header().Set(\"Content-Type\", \"application/json\") if r.Method != http.MethodGet { http.Error(w, \"unsupported method\", http.StatusMethodNotAllowed) return } input := r.URL.Query().Get(\"query\") inputInt, err := strconv.Atoi(input) if err != nil { http.Error(w, \"invalid input\", http.StatusBadRequest) return } output := convertIntegerToRoman(inputInt) response := map[string]interface{}{ \"output\": output, } if err := json.NewEncoder(w).Encode(\u0026response); err != nil { return } } func main() { mux := http.NewServeMux() mux.Handle(\"/roman\", romanHandler{}) log.Fatal(http.ListenAndServe(\":8080\", mux)) } Points The function convertIntegerToRoman takes an integer and return the roman numeral conversion of the number. Please have a look on Convert Number Into Roman Numeral We accept a single query parameter named query in the URL which should have the number which will be converted. The struct implements the http.Handler interface by implementing the method of ServeHTTP(ResponseWriter, *Request) ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:1:2","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"Testing Of the Server The whole purpose of this blog was to learn how to test http servers in Go, so let’s find out. As we mentioned in the beginning Go has all of the tools we need to both create net/http and test net/http/httptest. All of the tools are included in the net module. Let’s create a file named main_test.go which has all of the tests for the HTTP Server. ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:2:0","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"Tests package main import ( \"fmt\" \"net/http\" \"net/http/httptest\" \"strings\" \"testing\" ) func TestRomanHandler(t *testing.T) { tt := []struct { name string httpMethod string query string responseBody string statusCode int }{ { name: \"unsupported httpMethod\", httpMethod: http.MethodPost, query: \"1\", responseBody: \"unsupported httpMethod\", statusCode: http.StatusMethodNotAllowed, }, { name: \"invalid input\", httpMethod: http.MethodGet, query: \"asd\", responseBody: `invalid input`, statusCode: http.StatusBadRequest, }, { name: \"correct query param\", httpMethod: http.MethodGet, query: \"1\", responseBody: `{\"output\":\"I\"}`, statusCode: http.StatusOK, }, } for _, tc := range tt { t.Run(tc.name, func(t *testing.T) { path := fmt.Sprintf(\"/roman?query=%s\", tc.query) request := httptest.NewRequest(tc.httpMethod, path, nil) responseRecorder := httptest.NewRecorder() romanHandler{}.ServeHTTP(responseRecorder, request) if responseRecorder.Code != tc.statusCode { t.Errorf(\"Want status '%d', got '%d'\", tc.statusCode, responseRecorder.Code) } if strings.TrimSpace(responseRecorder.Body.String()) != tc.responseBody { t.Errorf(\"Want '%s', got '%s'\", tc.responseBody, responseRecorder.Body) } }) } } To test the handler, we use the common table-driven approach and provide three cases: the http method is not correct http method is correct, but the query param is invalid both http method and query param is valid. For each case, we run a subtest that creates a new request and a response recorder. We use the httptest.NewRequest function to create an http.Request struct, which represents an incoming request to the handler. This allows us to simulate a real request without relying on an actual HTTP server. However, this function only handles the request half of the testing. To handle the response half, we use httptest.ResponseRecorder, which records the mutations of the http.ResponseWriter and enables us to make assertions on it later in the test. By using this duo of httptest.ResponseRecorder and http.Request, we can successfully test any HTTP handler in Go. Running the test will produce the following output. === RUN TestRomanHandler === RUN TestRomanHandler/unsupported_method === RUN TestRomanHandler/invalid_input === RUN TestRomanHandler/correct_query_param --- PASS: TestRomanHandler (0.00s) --- PASS: TestRomanHandler/unsupported_method (0.00s) --- PASS: TestRomanHandler/invalid_input (0.00s) --- PASS: TestRomanHandler/correct_query_param (0.00s) PASS ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:2:1","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"REFERENCES net/http Testing HTTP Servers By Ieftimov Converting Decimal To Roman ","date":"2023-03-05","objectID":"/testing-http-servers-in-go/:2:2","tags":["go","http","testing"],"title":"Testing HTTP Servers in Go","uri":"/testing-http-servers-in-go/"},{"categories":null,"content":"I have never written my long term goals into something and I just want to try it. Let’s see if I will be able to achieve my goals. Here is the list Read More Books (at least 25) Do more exercise 10000 pushups start to run regularly Write more blog posts at least 1 post per month write non-techincal stuff also (maybe some reviews on books) Go outside more 😄 Start to learn investing Get a promotion hopefully These are the things that comes to my mind. If anything comes up, I will add it to the list. Wish me luck! ","date":"2022-12-31","objectID":"/my-goals-for-2023/:0:0","tags":["goals","life"],"title":"My Goals For 2023","uri":"/my-goals-for-2023/"},{"categories":null,"content":"MongoDB \u0026 Golang Query Examples - Cheat Sheet This cheat sheet should help you about the MongoDB queries with Golang. We will start with some basic examples to more complex queries with Go Programming Language. The examples are written with Go 1.19 and go.mongodb.org/mongo-driver/mongo. ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:0:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Table Of Contents Connecting to MongoDB Inserting A Document to MongoDB Writing Multiple Documents To MongoDB Finding Single Document From MongoDB Finding All Documents From MongoDB Updating Document(s) From MongoDB Deleting Document(s) From MongoDB ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:1:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"How to Connect to MongoDB with Golang Connecting to MongoDB is fairly simple, you just connect the uri generated by the MongoDB. Then we can use the client.Database() function to make sure that we are connecting to the correct database. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") // disconnect the mongo client when main is completed defer func() { if err = client.Disconnect(ctx); err != nil { panic(err) } }() } To really make sure that we are connected to the correct database, we can use the Ping method. ctx, cancel = context.WithTimeout(context.Background(), 2*time.Second) defer cancel() err = client.Ping(ctx, readpref.Primary()) ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:2:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Inserting A Document to MongoDB with Golang To insert a document to MongoDB, we can use the bson.D provided by the MongoDB. But to make the operations more simple and more realistic to real world applications, we will use structs with bson tags. The model we are using is type Car struct { Id primitive.ObjectID `bson:\"_id\"` Brand string `bson:\"brand\"` Model string `bson:\"model\"` Year int `bson:\"year\"` } Then we can simply use the InsertOne() method to insert a document to MongoDB. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson/primitive\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) type Car struct { Id primitive.ObjectID `bson:\"_id\"` CreatedAt time.Time `bson:\"createdAt\"` Brand string `bson:\"brand\"` Model string `bson:\"model\"` Year int `bson:\"year\"` } func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") exampleData := Car{ Id: primitive.NewObjectID(), CreatedAt: time.Now().UTC(), Brand: \"Mercedes\", Model: \"G-360\", Year: 2002, } res, err := db.Collection(\"cars\").InsertOne(context.Background(), exampleData) if err != nil { log.Fatal(err) } // inserted id is ObjectID(\"639b62ae2518fbd9315e405d\") log.Printf(\"inserted id is %v\", res.InsertedID) } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:3:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Writing Multiple Documents To MongoDB with Golang We can use the InsertMany() method of the Collection object. However, the InsertMany() requires an []interface{} to work on. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson/primitive\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) type Car struct { Id primitive.ObjectID `bson:\"_id\"` CreatedAt time.Time `bson:\"createdAt\"` Brand string `bson:\"brand\"` Model string `bson:\"model\"` Year int `bson:\"year\"` } func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") var data []interface{} data = append(data, Car{ Id: primitive.NewObjectID(), CreatedAt: time.Now().UTC(), Brand: \"Toyota\", Model: \"Corolla\", Year: 2008, }) data = append(data, Car{ Id: primitive.NewObjectID(), CreatedAt: time.Now().UTC(), Brand: \"Ford\", Model: \"Focus\", Year: 2021, }) res, err := db.Collection(\"cars\").InsertMany(context.Background(), data) if err != nil { log.Fatal(err) } // 2 documents inserted log.Printf(\"%v documents inserted\", len(res.InsertedIDs)) } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:4:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Finding Single Document From MongoDB with Golang To find a single document with a condition, we can use the FindOne() method of *Collection object. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson/primitive\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) type Car struct { Id primitive.ObjectID `bson:\"_id\"` CreatedAt time.Time `bson:\"createdAt\"` Brand string `bson:\"brand\"` Model string `bson:\"model\"` Year int `bson:\"year\"` } func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") condition := bson.M{} cur, err := db.Collection(\"cars\").FindOne(context.Background(), condition) if err != nil { log.Fatal(err) } var data []Car if err := cur.All(context.Background(), \u0026data); err != nil { log.Fatal(err) } // now we can use the data array, which contains all of the documents for _, car := range data { log.Printf(\"the brand is %v\\n\", car.Brand) } } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:5:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Fetch the Lastly Created Document We can also pass mongo.Options to the Find() operation. Let’s say we want to fetch the lastly inserted document. we need to sort by the createdAt field it should be descending, that’s why we made the sort value as -1. var opts = options.FindOne().SetSort(bson.M{ \"createdAt\": -1, }) res := db.Collection(\"cars\").FindOne(context.Background(), bson.M{}, opts) if res.Err() != nil { log.Fatal(err) } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:5:1","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Finding All Documents From MongoDB with Golang To find the all documents in a collection, we can use the Find() method of *Collection object. In the below example, we did not specify any condition, which means that return all of the documents in the database. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson/primitive\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) type Car struct { Id primitive.ObjectID `bson:\"_id\"` CreatedAt time.Time `bson:\"createdAt\"` Brand string `bson:\"brand\"` Model string `bson:\"model\"` Year int `bson:\"year\"` } func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") condition := bson.M{} cur, err := db.Collection(\"cars\").Find(context.Background(), condition) if err != nil { log.Fatal(err) } var data []Car if err := cur.All(context.Background(), \u0026data); err != nil { log.Fatal(err) } // now we can use the data array, which contains all of the documents for _, car := range data { log.Printf(\"the brand is %v\\n\", car.Brand) } } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:6:0","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Finding Many Documents With Condition If we would like to return the cars where the brand is Toyota, then we can change the condition variable as condition := bson.M{ \"brand\": \"Toyota\" } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:6:1","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Use Projection in Find Operations If you want to use projection in Find() operation, we can use the mongo.Options for that. Let’s say we would like to return 2 fields return the brand of the car. return a boolean field to check if the car is new if the production year of the car is 2022, it is new else, it is old. SetProjection() sets the value for the projection field. var opts = options.Find().SetProjection( bson.M{ \"brand\": 1, \"isNew\": bson.M{ \"$cond\": bson.M{ \"if\": bson.M{\"$gte\": bson.A{\"$year\", 2022}}, \"then\": true, \"else\": false}, }, }) cur, err := db.Collection(\"cars\").Find(context.Background(), bson.M{}, opts) More will come, so please stay tuned! ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:6:2","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Update Single Document in MongoDB With Golang To update a single document, we should use the FindOneAndUpdate() or UpdateOne() operations. For this blog, we will use the FindOneAndUpdate() operation. package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") filter := bson.M{ \"brand\": \"Toyota\", \"model\": \"Corolla\", } update := bson.M{ \"year\": 2022, } res := db.Collection(\"cars\").FindOneAndUpdate(context.Background(), filter, update) if res.Err() != nil { log.Fatal(err) } // operation successful } How to return the updated document in MongoDB? We can use mongo.Options package to do that. We should set the return document option to after. opts := options.FindOneAndUpdate().SetReturnDocument(options.After) res := db.Collection(\"cars\").FindOneAndUpdate(context.Background(), filter, update, opts) // we can use the updated car document var updatedData Car if err := res.Decode(\u0026updatedData); err != nil { log.Fatal(err) } ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:6:3","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Delete Document(s) from MongoDB with Golang To delete a document we can use DeleteOne() method of the *Collection object. To delete many documents, we can use the DeleteMany() method of the *Collection package main import ( \"context\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/bson\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() client, err := mongo.Connect(ctx, options.Client().ApplyURI(\"mongodb://localhost:27017\")) if err != nil { log.Fatal(err) } db := client.Database(\"testdb\") filter := bson.M{ \"brand\": \"Toyota\", \"model\": \"Corolla\", } // for single document res, err := db.Collection(\"cars\").DeleteMany(context.Background(), filter) if err != nil { log.Fatal(err) } // 1 document is deleted. log.Printf(\"%v document is deleted\", res.DeletedCount) } More will come, so please stay tuned! ","date":"2022-12-15","objectID":"/golang-mongodb-query-examples/:6:4","tags":["golang","mongodb"],"title":"Golang \u0026 MongoDB Query Cheat Sheet","uri":"/golang-mongodb-query-examples/"},{"categories":null,"content":"Özet Bu yazıda basit bir kod parçasındaki bütün hataları bulup refactor edeceğim. Bunu yaparken de Go dilindeki temel unsurları açıklayarak yapacağım. Bu yazı Concurrency Made Easy videosundan ağır şekilde esinlenmiştir. Go dilinde concurreny baya öne çıkan bir unsur ancak doğru kullanmayı bilmek daha da önemli. Kendim de bu konuda mükemmel sayılmam ancak hala öğreniyorum. ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:0:0","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Üzerinde Çalışma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Elimizdeki Fonksiyon Elimizdeki fonksiyon sadece bir parametre websites alıyor. Bu websiteler üzerinde gezinirken handle diye error döndüren bir fonksiyon alıyor ve handle fonksiyonu herhangi bir error döndürdüğü anda ise bu erroru döndürmek istiyor. func handleWebsites(websites []string) error { errChan := make(chan error, 1) semaphores := make(chan struct{}, 5) // aynı anda 5 iş çalıştır var wg sync.WaitGroup wg.Add(len(websites)) for _, website := range websites { semaphores \u003c- struct{}{} // semaphore acquire et go func() { defer func() { wg.Done() \u003c-semaphores }() if err := handle(website); err != nil { errChan \u003c- err } }() } wg.Wait() close(semaphores) close(errChan) return \u003c-errChan } ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:1:0","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Üzerinde Çalışma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Sorunlar ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:0","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Üzerinde Çalışma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Semaphore ve WaitGroup Kısmı func handleWebsites(websites []string) error { errChan := make(chan error, 1) semaphores := make(chan struct{}, 5) // aynı anda 5 iş çalıştır var wg sync.WaitGroup wg.Add(len(websites)) for _, website := range websites { semaphores \u003c- struct{}{} // semaphore acquire et go func() { defer func() { wg.Done() \u003c-semaphores }() if err := handle(website); err != nil { errChan \u003c- err } }() } wg.Wait() close(semaphores) close(errChan) return \u003c-errChan } Bu kısımlar kodumuzda bir panic oluşturmuyor, ancak aşağıdaki 2 durumdan birisi oluşuyor. \u003c-semaphores işlemi close(semaphores) işleminden önce oluşabilir ve bu durumda zaten kanaldan bir değer okur. close(semaphores) işlemi daha önce gerçekleşir ve \u003c-semaphores ise zero value alır. Önce wg.Done() operasyonu wg.Wait() fonksiyonun bitmesine ve close(semaphores) satırının çalışmasına yol açabilir. Her iki durumda da bir sıkıntı yok ancak bu kod fonksiyonun takibini daha zor yapıyor. Bunu go dilindeki şu tavsiyeyle çözebiliriz. Release locks and semaphores in the reverse order you acquired them. Anlamı ise locklar ve semaphoreları onları aldığınız sıranın tersinde bırakın. Bu durumda kodumuz şu hale geliyor ve daha basit bir duruma dönüşüyor. func handleWebsites(websites []string) error { errChan := make(chan error, 1) semaphores := make(chan struct{}, 5) // aynı anda 5 iş çalıştır var wg sync.WaitGroup wg.Add(len(websites)) for _, website := range websites { semaphores \u003c- struct{}{} // semaphore acquire et go func() { defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }() } wg.Wait() close(semaphores) close(errChan) return \u003c-errChan } Şimdi ise sadece tek bir durum gerçekleşebilir o da \u003c-semaphores işlemi channel kapanmadan okuma işlemlerini yapabilir çünkü wg.Wait() işlemi ancak ve ancak bütün semaphores kanalından okuma işlemleri gerçekleştikten sonra gerçekleşebilir. ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:1","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Üzerinde Çalışma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Semaphoreların Kullanımı Semaphoreların kullanıldığı kısıma biraz daha yakından bakalım. for _, website := range websites { semaphores \u003c- struct{}{} // semaphore acquire et go func() { defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }() } semaphores channelı 5 uzunluklu bir channel olduğundan dolayı 5 goroutine çalıştıktan sonra 6. taska geldiğinde fonksiyon 2. satırda duracak ve bu handle(website) fonksiyonu bitene kadar durmayacak. Halbuki şöyle bir durum daha mantıklı olabilir. Aynı anda 5 kez handle(website) fonksiyonu çalışsın, bir diğer deyimle goroutineler yaratılsın ve hazırda beklesin. Bunun için şu motto ile hareket edebiliriz. Acquire semaphores when you’re ready to use them. Anlamı ise semaphoreları ne zaman kullanmaya hazırsan o durumda acquire et. for _, website := range websites { go func() { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }() } Bu değişiklikten sonra artık bütün goroutineler yaratılır ve aynı anda ancak 5 tanesi sadece handle(website) fonksiyonunu çalıştırabilir. ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:2","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Üzerinde Çalışma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"For Loop For-range loop da yeni bir değişken website yaratıyoruz. Bir goroutine bu değişkeni updatelerken diğer goroutineler bu değişken üzerinden işlem yapıyor. Bundan dolayı burada bir data race var. Onun yerine 2 şekilde halledebiliriz. Functiona parametre olarak verme for _, website := range websites { go func(website string) { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }(website) } Yeni Değişken Olarak Tanımlama for _, website := range websites { website := website go func() { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }() } Bundan ayrı olarak da genelde goroutineleri ayrı fonksiyonlara almak önerilir. Bu kod parçasını go func() { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } }() şu şekilde refactor edebiliriz. func handleWebsites(websites []string) error { errChan := make(chan error, 1) semaphores := make(chan struct{}, 5) // aynı anda 5 iş çalıştır var wg sync.WaitGroup wg.Add(len(websites)) for _, website := range websites { go worker(website, semaphores, \u0026wg, errChan) } wg.Wait() close(semaphores) close(errChan) return \u003c-errChan } func worker(website string, sem chan struct{}, wg *sync.WaitGroup, errChan chan err) { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { errChan \u003c- err } } ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:3","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Üzerinde Çalışma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Error Channele Yazma Bütün bu işlemleri yaptık ancak hala kodumuzda bir sorun var. Herhangi bir goroutine errChan \u003c- err işlemini yaptığında diğer bütün error goroutineler bu kanala yazarken sonsuza kadar bekleyecekler ve bu da deadlock yaratacak. Bekleme sebebi errChan kanalının 1 uzunlukta bir channel olmasından dolayıdır. Bir goroutine başlatmadan önce ne zaman ve nasıl duracağını bilmek gerekir. Bunun yerine select ve case kullanarak sorunu halletmiş oluruz. func handleWebsites(websites []string) error { errChan := make(chan error, 1) semaphores := make(chan struct{}, 5) // aynı anda 5 iş çalıştır var wg sync.WaitGroup wg.Add(len(websites)) for _, website := range websites { go worker(website, semaphores, \u0026wg, errChan) } wg.Wait() close(semaphores) close(errChan) return \u003c-errChan } func worker(website string, sem chan struct{}, wg *sync.WaitGroup, errChan chan err) { semaphores \u003c- struct{}{} // semaphore acquire et defer func() { \u003c-semaphores wg.Done() }() if err := handle(website); err != nil { select { case errChan \u003c- err: default: } } } Bu durumda eğer herhangi bir goroutine errChane yazabilirse yazacak ve yazamazsa default case çalışacak. Hiçbir goroutine bloklanmayacak. Select Case ile blocking çağrıları non-blocking olarak değiştirebiliriz. ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:4","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Üzerinde Çalışma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"REFERENCES Concurrency Made Easy From Dave Chevey ","date":"2022-09-14","objectID":"/go-dilinde-concurrency-calisma-ornegi/:2:5","tags":["golang","concurrency","refactor"],"title":"Go Dilinde Concurrency Üzerinde Çalışma","uri":"/go-dilinde-concurrency-calisma-ornegi/"},{"categories":null,"content":"Bu yazıdaki bütün kodlar Bu repodan bulunmaktadır. Eğer demo versiyonunu görmek isterseniz http://banafilmoner.herokuapp.com/ sitesinden görebilirsiniz. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:0:0","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Önerme Sitesi Yapalım","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"Gereksinimler Bu yazımızda yapacağımız siteyi eğer kendiniz de yapmak istiyorsanız Flask ve Scikit-learn kütüphanelerini yüklemeniz gerekmektedir. Bunları yüklemek için terminalden şu komutları yazabilirsiniz ya da her bir paketin dökümentasyonundan bakabilirsiniz. pip install Flask pip install scikit-learn ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:1:0","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Önerme Sitesi Yapalım","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"Sitenin Yapısı Yapacağımız sitede film önerileri metin benzerliği ile olacak. Bu filmlerin açıklama metinlerini ise bir veri kümesinden alacağız. Bu veri kümesine TMDB 5000 Movies sayfasından ulaşabilirsiniz. Bundan dolayı önerebileceğimiz metinler sadece bu veri kümesindekiler olacaktır. Metin benzerliğini ise kosinüs benzerliği ile yapacağız. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:2:0","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Önerme Sitesi Yapalım","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"Veri Seti ve Metin Benzerliği Veri setindeki title sütunu filmin başlığını ve overview sütunu ise filmi basitçe açıklar.Bu yazıda overview sütununu kullanarak metin benzerliğini kuracağız. Bunun için önce utils.py diye bir dosya oluşturalım ve indirdiğimiz veri setini de projedeki dosyaya koyalım. Öncelikle filmlerin açıklamalarını kullanarak kosinüs benzerliğini verecek olan bir fonksiyon yazalım. from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.metrics.pairwise import linear_kernel def get_cosine_similarities(df): vectorizer = TfidfVectorizer(stop_words=\"english\") tf_idf_mat = vectorizer.fit_transform(df['overview']) cosine_sim = linear_kernel(tf_idf_mat, tf_idf_mat) return cosine_sim get_cosine_similarities(df) fonksiyonu parametere olarak DataFrame alır, DataFramei ise veri setini okuduktan sonra bu fonksiyona parametre olarak vereceğiz. Fonksiyonda kullanılan TfidfVectorizer metinlerden bilgi çıkarmamıza yarayan bir algoritmadır. Açılımı Term frequency (tf) -\u003e (terim sıklığı) ve inverse document frequency (ters döküman sıklığı)dır. Yani terimlerin her bir metinde ne kadar sıklıkla geçtiğine ve bu terimlerin bütün dökümanda ne kadar sıklıkla geçtiğine bakıp, hangi terimlerin cümleleri ayırmada önemli olduğuna karar verir. Bu bize (4803, n) boyutunda bir matrix dönderecektir. n ise bu algoritmanın bulduğu belirleyici kelimelerin sayısıdır. Yazdığımız fonksiyonla beraber, her bir cümle için her bir kelimenin ne kadar önemi olduğunu gösteren bir matrix elde edilecek. Daha sonra bu matrixi kullanarak her bir metin arasındaki benzerliği bulmak için linear_kernel kullanıyoruz. Bu algoritma ise bize (4803, 4803) boyutunda her bir metnin diğer 4038 filmin metni ile benzerliğini gösteren bir matrix döndürecek. Bu fonksiyondan çıkan sonuç ise şu şekildedir [[1. 0. 0. ... 0. 0. 0. ] [0. 1. 0. ... 0.02160533 0. 0. ] [0. 0. 1. ... 0.01488159 0. 0. ] ... [0. 0.02160533 0.01488159 ... 1. 0.01609091 0.00701914] [0. 0. 0. ... 0.01609091 1. 0.01171696] [0. 0. 0. ... 0.00701914 0.01171696 1. ]] Görüldüğü gibi bazı değerler 0 bazıları 1 (köşegendekiler), bazıları da 0 ile 1 arasında. Kısaca Sonucu 0 olanlar arasında hiçbir benzerlik yok, 1 olanlar zaten kendileri ile ölçüldüğü için aynı olarak çıkıyor, örnek olarak 1.film ile 1.film arasındaki benzerlik 1 olacak doğal olarak 0-1 arasındakiler ise iki film arasındaki benzerliği gösteriyor. Ne yaptığımızı kısaca yazalım. Veri setini okuduk Kosinüs benzerlik matriksini oluşturduk. Şimdi yapılması gerekenler ise bu matrixi kullanıp film önerileri alabilmek. Bunun için yapılması gerekenler Kosinüs matrixini kullanıp bize verilen film için önerileri döndüren bir fonksiyon yazmak Flask ile web arayüzü oluşturup, kullanıcın girdiği filme öneriler vermek Bu fonksiyonu flask ile kullanabilmek. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:3:0","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Önerme Sitesi Yapalım","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"Film Önerme Fonksiyonu Bu fonksiyona geçmeden önce veriyi okuyalım, ve kosinüs matriximizi alalım. Şunu belirtmem gerekir ki, kullanıcının attığı her requestte veri setini baştan okuyup kosinüs matrixini okumak yük olur. Bundan dolayı, bunu bir kez yapmak adına, bu işlemleri if __name__ == \"__main__\" altında yapacağız. Öncelikle bir app.py adında bir dosya açalım. Bu dosyada Flask applikasyonumuzun kodları olacak. Diğer utils.py dan fonksiyonları çağıracağız. app.py dosyasına şu kodları girelim. from flask import Flask, render_template, request, redirect import pandas as pd import utils app = Flask(__name__) if __name__== \"__main__\": df = pd.read_csv(\"data.csv\") df['overview'] = df['overview'].fillna('') df['lower_name'] = df['title'].str.lower() titles = pd.Series(df.index, index=df['lower_name']).drop_duplicates() cosine_sim = utils.get_cosine_similarities(df) app.run() Şuan app.py dosyasında yapılan işlemler. Flask uygulaması oluşturuldu. Veri okundu. Kosinüs benzerlik matriksi oluşturuldu. Main kısmında titles diye bir değişken oluşturulma sebebi bu değişkenin filmleri önerecek olan fonksiyonda kullanacağımızdan dolayıdır. Titles değişkeni tip olarak Seriesdir. Konsola yazdırdığımız zaman şöyle bir sonuç çıkacaktır. lower_name avatar 0 pirates of the caribbean: at world's end 1 spectre 2 the dark knight rises 3 john carter 4 ... el mariachi 4798 newlyweds 4799 signed, sealed, delivered 4800 shanghai calling 4801 my date with drew 4802 Length: 4803, dtype: int64 Şimdi filmleri önerecek fonksiyonu yazmaya başlayabiliriz. Bunu utils.py dosyasında yazalım. \"\"\" movie_title = istenilen filmin ismi cosine_similarity = kosinüs benzerlik matriksi titles= az önce oluşturduğumuz filmin isimlerine sahip olan `Series` df = bütün filmleri barındıran dataframe \"\"\" def get_recommendations(movie_title, cosine_similarity, titles, df): index_movie = titles[movie_title] #istenilen filmin indexini bul name_of_movie = df.iloc[index_movie]['title'] #daha sonra dataframeden filmin adını bul. #istenilen isim küçük harfli olabilir, biz #dataframde nasılsa onu almak için yapıyoruz. similarities = cosine_similarity[index_movie] #daha sonra girilen filmin kosinüs benzerlik #arrayini al, diğer filmlerle benzerlik arrayi similarity_scores = list(enumerate(similarities)) #işlem kolaylığı için her bir benzerliğin indexini #alabilmemiz lazım. yani (0, 0.2), (1, 0.4), (2. 0.7) ... gibi. similarity_scores = sorted(similarity_scores , key=lambda x: x[1], reverse = True) #bütün benzerlik skorlarını sırala similarity_scores = similarity_scores[1:11] #en benzer 10 filmi al similar_indexes = [x[0] for x in similarity_scores] #benzer filmlerin indexlerini al return df.iloc[similar_indexes], name_of_movie #benzer filmlerin bilgilerini almak için indexlerini kullan. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:3:1","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Önerme Sitesi Yapalım","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"HTML Arayüz Bu fonksiyon da yazıldığına göre şimdi Flask ile bağlayabiliriz. Ama öncelikle bir arayüzümüz olması gerekiyor. Bunun için aynı klasörde templates diye bir klasör oluşturun ve içine index.html adında bir dosya oluşturun. Bu dosya bizim kullanıcıdan arayüzü almamızı sağlayacak olan HTML kodunu içerecek. HTML kısmını anlatmayacağım. Basit şekilde Flask bildiğinizi varsayıyorum. index.html dosyasına buradaki arayüz kodunu yapıştırın. HTML kısmı şuan çok ilgi alanımız değil, eğer arayüz nasıl görünüyor diye merak ediyorsanız, buradan bakabilirsiniz. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:3:2","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Önerme Sitesi Yapalım","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"Flask Endpointleri halletme Bu kodda dikkatinizi çekmek istediğim bir nokta var. FORM bir ‘/’ yoluna POST request yapıyor. Flask uygulamasında ‘/’ adresine bir POST request yapılacak. Ayrıca websitesinin giriş sayfası da bu adrese GET request yapılarak alınacak. Şimdi app.py dosyasında bu koşulları sağlayan kodumuzu yazalım. from flask import Flask, render_template, request, redirect, flash, url_for import pandas as pd import utils app = Flask(__name__) @app.route('/', methods=['GET', 'POST']) def hello(): length = 0 movie_name = \"\" context = { #Bu dictionary önerilen filmlerin bilgilerini tutuyor. 'movies': [], #isimler 'urls': [], #filmlerin sayfaları 'release_dates': [], #filmlerin yayınlanma tarihleri 'runtimes': [], #filmlerin süreleri 'overviews': [] #filmleri anlatan metinler } if request.method == \"POST\": #Kullanıcı bir input girdiyse text = request.form['fname'].lower() print(\"request text\", text) try: recommended_df, movie_name = utils.get_recommendations( text, cosine_sim, titles, df) #girilen inputtan filmleri al context['movies'] = recommended_df.title.values context['urls'] = recommended_df.homepage.values context['release_dates'] = recommended_df.release_date.values context['runtimes'] = recommended_df.runtime.values context['overviews'] = recommended_df.overview.values length = len(context['movies']) except: return render_template('index.html', error=True) #filmi bulamadıysak error döndür. return render_template('index.html', length=length, context=context, movie_name=movie_name, error=False) if __name__ == '__main__': df = pd.read_csv(\"data.csv\") df['overview'] = df['overview'].fillna('') titles = pd.Series(df.index, index=df['lower_name']).drop_duplicates() cosine_sim = utils.get_cosine_similarities(df) app.run() Render templatede gönderilen context değişkeni HTML dosyasında parse ediliyor ve bilgiler güzel bir şekilde gösteriliyor. Dediğim gibi basit şekilde Flask bildiğiniz düşünüyorum. Beğendiyseniz paylaşırsanız çok sevinirim. İyi öğrenmeler. ","date":"2021-03-01","objectID":"/flask-ve-sklearn-ile-film-onerme-sitesi/:3:3","tags":["flask","makine ogrenmesi"],"title":"Flask ve Sklearn ile Film Önerme Sitesi Yapalım","uri":"/flask-ve-sklearn-ile-film-onerme-sitesi/"},{"categories":null,"content":"TANIM PyTorch da bulunan torch.autograd otomatik türev alma motoru şeklinde çalışır ve bu da nöral ağ eğitimini güçlendirir. Bu yazımızda belirli örnekler vererek konunun daha geniş şekilde anlaşılmasını sağlayacağız. Öncelikle çok kısa bir özetleyici metine bakalım. ","date":"2021-02-20","objectID":"/pytorch-autograd-nedir-ve-nasil-calisir/:1:0","tags":["pytorch","matematik"],"title":"Pytorch AutoGrad Nedir ve Nasıl Çalışır","uri":"/pytorch-autograd-nedir-ve-nasil-calisir/"},{"categories":null,"content":"Arka Plan Nöral ağlar (neural networks) kendisine verilen veriyi belirli fonksiyonlarda işleyen bir bütündür. Bu fonksiyonların her biri bazı parametrelerden (ağırlıklar ve önyargı (weights and bias)) oluşur. Bu belirlenen parametrelere Pytorch da tensor adlı veri yapılarında tutulur. Bir Nöral ağın eğitilmesi iki kısımdan oluşur. Birinci kısımda sadece ileriye gidilir (forward propagation) ve ikinci kısımda geriye doğru gidilir (backward propagation). Peki bu ileri ve geri gitme işlemleri ne için yapılır onlara bakalım. İleriye Gitme (Yayılma) Bu kısımda nöral ağ kendisine verilen veriden en iyi tahminini yapmaya çalışır. Bu belirlenen veri, önceden bahsettiğimiz her bir fonksiyondan geçer ve en sonunda bir tahmin ortaya atılmış olur. Daha sonra belirlenen tahmin ve gerçek değer arasından bir kayıp (loss) değeri bulunur ve hatta bu değeri bulan fonksiyona da loss function denilir. Geriye Gitme (Yayılma) Bu kısımda ise nöral ağ, ilk bölümde hesaplanan kayıp veya hata değerini azaltmaya yönelik parametrelerinde iyileşmeye gider. Bunu yaparken de sonuçtan geriye dönük olarak her hata değerinin her bir parametreye bağlı olan türevini (derivative) hesaplar ve bu parametreleri, gradient descent kullanarak optimize eder. Ancak bu her bir fonksiyonun parametrelere göre türevini tek tek elimizle alamayız ve bize otomatik bir süreç lazım. İşte bu kısımda pytorch.autograd devreye giriyor ve bütün yükü alıyor. ","date":"2021-02-20","objectID":"/pytorch-autograd-nedir-ve-nasil-calisir/:1:1","tags":["pytorch","matematik"],"title":"Pytorch AutoGrad Nedir ve Nasıl Çalışır","uri":"/pytorch-autograd-nedir-ve-nasil-calisir/"},{"categories":null,"content":"Autograd’da Türev Alma İşlemleri Şimdi autograd‘ın bütün bu değerleri nasıl kayıt ettiğine bakalım. Öncelikle iki tane a ve b tensor oluşturalım. Bu tensorları oluştururken parametre olan requires_grad parametresini True yapmamız gerekiyor aksi halde otomatik türev alma işlemleri gerçekleşemez çünkü bu parametre Tensorun grad adlı attributunda bu değerleri kayıt etmemize yardımcı oluyor. import torch x = torch.tensor([1., 2.], requires_grad=True) y = torch.tensor([2., 4.], requires_grad=True) Şimdi bu iki tensoru kullanarak yeni bir tensor z oluşturalım. Basit şekilde formül $$ z = 6x^2 - 2b^3 $$ z = 6*x**2 - 2*y**3 Şöyle varsayalım, x ve y bizim parametrelerimiz ve z bizim hata fonksiyonumuz olsun. Nöral ağ eğitiminde, hatanın bu parametreleri bağlı olan gradyantlarını (gradient) isteriz. PyTorch’da .backward() fonksiyonunu çağırdığımız zaman, auutograd her bir parametrenin (x, y) gradyantlarını bulur ve bunları her bir tensorun .grad attributunda kayıt eder. Öncelikle şuan x ve y nin grad değerlerine bakalım. print(\"X.grad = \", x.grad) print(\"Y.grad = \", y.grad) #Output X.grad = None Y.grad = None Ancak şimdi z tensorunda .backward() çağırdığımız zaman x ve y nin .grad attributularında z'nin kendilerine göre türevler yer alacak. Ancak z.backward() argümanını çağırabilmek için parametre olarak gradyant (gradient) vermemiz gerekiyor çünkü z bir vektör. Gradyant z ile aynı boyutlara sahip ve z’nin z ye göre türevini temsil eder. Şimdi z.backward() fonksiyonunu çağırabiliriz. gradyant_parametre = torch.tensor([1., 1.]) z.backward(gradient=gradyant_parametre) Şimdi x.grad ve y.grad değerleri oluşacak. Ancak bu değerleri görmeden önce kendimiz basit bir türev alalım. $$ \\frac{\\partial z}{\\partial x} = 12x $$ $$ \\frac{\\partial z}{\\partial y} = -6y^2 $$ Daha sonra bu kısmi türevlere x ve y tensorlarını koyduğumuz zaman ortaya çıkacak sonuçların şu şekilde olması lazım. print(\"x için = \", 12 * x) print(\"y için = \", -6 * y**2) x için = tensor([12., 24.], grad_fn=\u003cMulBackward0\u003e) y için = tensor([-24., -96.], grad_fn=\u003cMulBackward0\u003e)) Şimdi basit bir şekilde kontrol edelim. print(\"x.grad = \", x.grad) print(\"y.grad = \", y.grad) x.grad = tensor([12., 24.]) y.grad = tensor([-24., -96.]) Gördüğümüz üzere sonuçlar doğru çıkıyor. Üstte gözüken ggrad_fn=\u003cMulBackward0\u003e ise bu bu tensorun nasıl bir matematiksel operatör kullanarak oluşturulduğunu söylüyor. Eğer required_grad=False olsaydı bu değer None olurdu. Bütün yazdığımız operasyonlar için required_grad=True idi. Şimdi required_grad=False yapıp bir de öyle deneyelim. x = torch.tensor([1., 2.], requires_grad=False) y = torch.tensor([2., 4.], requires_grad=False) z = 6*x**2 - 2*y**3 gradyant_parametre = torch.tensor([1., 1.]) z.backward(gradient=gradyant_parametre) print(\"X.grad = \", x.grad) print(\"Y.grad = \", y.grad) Bu işlemden şöyle bir sonuç alacaksınız. RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn Bu da demek oluyor ki x ve y nin grad değerleri yok ve bundan dolayı grad_fn fonksiyonları da yok. x ve y nin grad değerleri olmadığı için z‘nin de grad değeri yok ve bu da hataya yol açıyor. Derin öğrenmede genellike önceden belirli datasetler ile eğitilmiş hazır modeller bulunmaktadır ve bunlara pretrained model denir. Bu modelleri kullanırken genellikle son katmana kadar olan bütün katmanların parametrelerini eğitmek istemeyiz çünkü bu işlem hem pahalı hem de çok da gerekli olmayan bir işlem. Bu parametreleri optimize etmeye çalışmadığımızdan dolayı bu parametrelerin required_grad değerleri False olacaktır. Örnek bir kod olarak da from torch import nn, optim model = torchvision.models.resnet18(pretrained=True) # Freeze all the parameters in the network for param in model.parameters(): param.requires_grad = False Burada Resnet18 modelinin parametrelini dondurma (freeze) işlemi yapılıyor ve böylece modeli kullanırken resnet18 modelini parametrelerinde herhangi bir optimize etme durumu söz konusu olmayacak. Ancak, sonradan eklenilen layerlarda optimize çal","date":"2021-02-20","objectID":"/pytorch-autograd-nedir-ve-nasil-calisir/:2:0","tags":["pytorch","matematik"],"title":"Pytorch AutoGrad Nedir ve Nasıl Çalışır","uri":"/pytorch-autograd-nedir-ve-nasil-calisir/"},{"categories":null,"content":"REFERENCES Pytorch Tutorials ","date":"2021-02-20","objectID":"/pytorch-autograd-nedir-ve-nasil-calisir/:3:0","tags":["pytorch","matematik"],"title":"Pytorch AutoGrad Nedir ve Nasıl Çalışır","uri":"/pytorch-autograd-nedir-ve-nasil-calisir/"},{"categories":null,"content":"Yazıya başlamadan önce belirmek isterim ki, bu tarz derin öğrenme terimlerinin İngilizce ile kullanılması taraftarıyım. Teknik terimlerin Türkçe karşılıkları genelde her zaman duymadığımız kelimeler oluyor ve internette Türkçe pek kaynak yok. Ondan dolayı ben bu terimlerin İngilizce öğrenilip, İngilizce kullanılması taraftarıyım. Herkes global olmaya çalışırken, bizim öyle davranmamamız için hiçbir sebep yok. ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:0:0","tags":["numpy","pytorch","cnn"],"title":"Evrişimsel Sinir Ağları  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"TANIM Convolutional sinir ağları genel olarak sıradan sinir ağlarına çok benzerdir. Bu sinir ağları da öğrenebilir ağırlık (weight) ve önyargısı (bias) olan sinirlerden (neuron) oluşur. Her bir nöron bazı inputlar alır, dot product uygular ve bu işlemi lineer olmayan bir yolla devam ettirir. Bütün network hala tek bir ayırt edilebilir skoru açıklar. Network resim pixellerini alıp, sonda bir tahmin üretir. Networkun sonunda belirli bir kayıp fonksiyonu (loss function) bulunur. Peki bu convolutional sinir ağları normal sinir ağlarına bu kadar benziyorsa ne değişiyor? Bu sorunun cevabı ise şu şekildedir: Convolutional sinir ağları inputun resimlerden oluştuğunu varsayar, bu varsayım bize bazı özellikleri sisteme entegre etmemize yardımcı olur. ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:1:0","tags":["numpy","pytorch","cnn"],"title":"Evrişimsel Sinir Ağları  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"YAPISAL GÖZLEM Normal Sinir Ağları: Normal sinir ağları tek bir input alır, onu bazı gizli katmanlardan (hidden layer) geçirir. Her bir hidden layer nöron kümelerinden oluşur, her bir nöron, bir önceki katmandaki bütün nöronlarla bağlantılıdır ve diğer nöronlardan bağımsız şekilde çalışır. Son katman ise sonuç katmanı (output layer) olarak adlandırılır ve bu katmanda her bir sınıfın olasılığı belli olur. Bu normal sinir ağları resimler kullanılınca pek iyi ölçeklenemiyor. Örnek olarak $(32, 32, 3)$ lük boyutlarda resimler kullanırsak, ilk katman $32 * 32 * 3 = 3072$ ağırlığa sahip olacaktır. Bu yük halledilebilir şekilde görülüyor ancak, bu fully-connected yapı büyük resimlere ölçeklenmiyor. Örnek olarak eğer biz boyutları $(200, 200, 3)$ olan resimler kullanırsak, bu sefer nilk nöronlar $200 * 200 * 3 = 120, 000$ ağırlığa sahip olacaklar. Ancak bu büyük numaralı ağırlıklar aşırı uyma (overfitting) denilen olaya sebep olacaktır. Convolutional sinir ağları ise inputun resimlerden oluşmasınından faydalanır ve buna göre yapıyı daha mantıklı şekilde kurar. Normal sinir ağlarının aksine, Convolutiona sinir ağlarının nöronları 3 boyuta ayarlanmış şekildedir. genişlik, yükseklik, derinlik. Örnek olarak $(32, 32, 3)$ boyutlu resimlerde Genişlik = 32 Yükseklik = 32 Derinlik = 3 olacaktır. ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:2:0","tags":["numpy","pytorch","cnn"],"title":"Evrişimsel Sinir Ağları  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"PEKI BU CONVOLUTIONAL SINIR AĞLARI NASIL OLUŞTURULUYOR? Bu sinir ağları katman dizilerinden oluşur ve bu katmanlar ise şu şekildedir. Convolutional Katman Pooling Katmanı Fully-Connected Katmanı Bu 3 katmandan oluşan katmanları birleştirip bir sinir ağı oluşturacağız. CONVOLUTIONAL KATMAN Convolutional katman Convolutional sinir ağlarının büyük ağır işini yapan katmanlardır. Conv katmanlar parametreleri öğrenilebilir filtrelerden oluşur. Her bir filtre boyut olarak küçüktür, ancak input derinliği boyunca uzanırlar. Örnek olarak, tipik bir filtre $5 * 5 * 3$ boyutlarında olabilir. İlk 5 genişlik, ikinci 5 yükseklik ve üçüncü 3 ise resimin 3 derinlikli olmasından kaynaklanır. Doğrudan iletme kısmında, her bir filtreyi input resmi üzerinde kaydırıyoruz, bu kaydırma sırasında resimlerde pixeller ile filtredeki sayılar ile dot product alıyoruz. Filtreyi kaydırma işlemi sırasında 2 boyutlu bir aktivite haritası oluşturuyoruz. Bu harita ise bize her bir pozisyondaki cevabı veriyor. Sinir ağı, bu filtreler ne zaman belirli bir görsel özellik, örnek olarak kenar, gördüğü zaman öğrenecek. Her bir filtrenin oluşturduğu haritaları üst üste sıkıştırıp bunu bir sonraki katmana iletiyoruz. BOYUTSAL AYARLAMA Her bir nöronun nasıl bağlı olduğunu anlattık ancak output hacminde kaç tane nöron olduğundan bahsetmedik. Output hacmini belirleyen 3 ayrı parametre vardır. DERİNLİK: Bu parametre kaç tane nöron kullandığınıza işaret eder. Örnek olarak ilk convolutional katman input olarak resmi alırken, farklı nöronlar bu resimde farklı detayları fark edebilir. STRIDE (KAYDIRMA ADIMI): Bu parametre ise filtreyi kaç pixel kaydıracağımıza işaret eder. Eğer stride bir ise, filtreleri bir pixel kaydıracağımız anlamına gelir. ZERO-PADDING: (SIFIRLARLA DOLDURMA) Bazı durumlarda inputun etrafını sıfırlarla doldurmak uygun olmaktadır. Bu işlemin güzel bir tarafı ise, bize output boyutunu kontrol altında tutma olanağı vermesidir. Örnek olarak daha yüksek boyutlu outputlar istersek, inputu filtre boyutu kadar sıfırlarla doldurup, bir sonraki katmana aktarılacak outputun boyutunu, şuanki katmandaki input boyutuna eşit tutabiliriz. Output hacminin boyutunu şu şekilde hesaplayabiliriz. Input Boyutu = $W$ Convolutional katman nöronları filtre boyutu = $F$ Stride = $S$ Zero-Padding = $P$ Output hacmi boyutu formülü = $(W - F + 2P) / S + 1$. Örnek olarak eğer elimizde $10 * 10$ boyutlu bir resim varsa ve bizim filtre boyutumuz $3 * 3$, stride = $1$ ve padding = $0$ ise $$ Output Boyutu = (10 - 3 + 2*0) / 1 + 1 = 8 * 8 $$ Şimdi bu boyut tek bir nörondan çıkan sonuç. Eğer elimizde $n$ tane nöron varsa, bu katmandan çıkan sonucun boyutu $8 * 8 * n$ olacaktı. Yukarıdaki örnekten de görüleceği üzere filtre boyutumuz $3 3$, bundan dolayı resimde de (33) lük alanlar alıp, bu aldığımız alanla filtre arasında bir dot product işlemi uyguluyoruz. Peki resimdeki $31$ sayısına nasıl ulaştık onu inceleyelim. $$ (1 * 1) + (0 * 2) + (1 * 3) + (0 * 4) + (1 * 5) + (1 * 6) + (1 * 7) + (0 * 8) + (1 * 9) $$ $$ 1 + 3 + 5 + 6 + 7 + 9 = 31 $$ Özetlemek gerekirse Conv layer $W_1 * H_1 * D_1$ boyutlarında input alır 4 parametreye ihtiyaç duyar Filtre sayısı $K$ Filtrenin boyutları $F$ Stride $S$ Zero padding sayısı $P$ $W_2 * H_2 * D_2$ boyutlarında output üretir. $W_2 = (W_1 - F + 2P)/S + 1)$ $H_2 = (H_1 - F + 2P)/S + 1$ $D_2 = K$ ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:3:0","tags":["numpy","pytorch","cnn"],"title":"Evrişimsel Sinir Ağları  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"PYTHON İLE UFAK BİR GÖSTERİM Şimdi tensorflow ile basit bir gösterim yapıp bu boyutları daha iyi anlayalım. import tensorflow as tf # The inputs are 28x28 RGB images with `channels_last` and the batch # size is 4. input_shape = (4, 28, 28, 3) x = tf.random.normal(input_shape) y = tf.keras.layers.Conv2D( 2, 3, activation='relu', input_shape=input_shape[1:])(x) print(y.shape) (4, 26 , 26, 2) Burada olan işlemler şu şekildedir input_shape Conv layer’a verilecek olan inputun boyutlarıdır. (4, 28, 28, 3) şu anlama gelmektedir. Bizim elimizde 4 adet resim var, ve bu resimlerin boyutları (28, 28, 3)tür. Conv2D ’ e verilen parametreler ise şu şekildedir. İlk verilen parametre 2 kaç adet filtre kullanacağımızı gösterir. İkinci parametre 3 ise filtre boyutunu vermektedir. Yani filtre boyutumuz $(3, 3)$ olacaktır. Şimdi burada oluşan outputun nasıl oluştuğuna bakalım. Yukarıda özetlediğimiz gibi her şeyi tek tek yazalım Input boyutları $W_1 * H_1 * D_1$ şeklindeydi. Bundan dolayı $W_1 = 28$ $H_1 = 28$ $D_1 = 3$ Daha sonra filtre sayımız $K = 2$, filtre boyutumuz ise $F = 3$, stride ise default olarak $S = 1$dir. Padding ise default olarak $P = 0$dır. O zaman şimdi output boyutlarımızı $(W_2 * H_2 * D_2)$ hesaplayabiliriz. $W_2 = (28 - 3 + 2 * 0) / 1 + 1 = 25 + 1 = 26$ $H_2 = (28 - 3 + 2 * 0) / 1 + 1 = 25 + 1 = 26$ $D_2 = K = 2$ Her bir resim için oluşturulan output boyutları $(26, 26, 2)$. Elimizde 4 adet resim var ve bundan dolayı çıkan output boyutu $(4, 26, 26, 2)$ ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:3:1","tags":["numpy","pytorch","cnn"],"title":"Evrişimsel Sinir Ağları  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"POOLING LAYER Convolutional sinir ağlarında convolutional katmanlar arasına Pooling katmanları eklemek çok yaygındır. Pooling katmanının görevi verilen inputun boyutlarını kademeleri olarak azaltarak parametrelerin ve ağın işlem yükünün azaltımasını sağlamak. Bu şekilde aşırı uyma (overfitting) kontol altına alınmış olur. Pooling katmanı, bağımsız olarak çalışır ve her bir inputu Max operasyonu kullanarak boyutlarını azaltır. En yaygın Pooling katmanı, filtreleri $(2 * 2)$ boyutlarında olan ve inputu hem boydan ve hem enden ikiye bölenlerdir. Her bir Max operasyonu input olarak $(2 * 2)$ lik bir bölüm alacak ve bu 4 sayıdan en büyüğünü gönderecektir. Özetlemek gerekirse, Pooling katmanı input olarak $W_1 * H_1 * D_1$ boyutlarını kabul eder. İki parametreye ihtiyaç duyar Boyut $F$ Stride $S$ Boyutları $W_2 * H_2 * D_2$ olan output çıkarır. $W_2 = (W_1 - F)/S + 1$ $H_2 = (H_! - F)/S + 1$ $D_2 = D1$ Resimde de görüleceği üzere her bir $(2 * 2)$ lik bölümden en büyük sayılar alınıp yeni bir örnek elde ediliyor. Şimdi bunu Python ile kodlamaya çalışalım. ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:4:0","tags":["numpy","pytorch","cnn"],"title":"Evrişimsel Sinir Ağları  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"Pooling Layer Python İle İmplementasyonu Bu layerı hem sıfırdan hem de kütüphane kullanarak kodlayabiliriz. Önce kütüphane kullanarak gösterelim. x = tf.constant([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]) x = tf.reshape(x, [1, 3, 3, 1]) max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid') max_pool_2d(x) Bu koddan çıkacak output ise \u003ctf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy= array([[[[5.], [6.]], [[8.], [9.]]]], dtype=float32)\u003e Çıkan sonucun nasıl çıktığını bence rahatlıkla yapabilirsiniz. Şimdi kendimiz sıfırdan bu layerı basit bir şekilde implement edelim. import numpy as np def pool2d(X, pool_size, mode='max'): p_h, p_w = pool_size #pool size ı al Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)) #Outputu oluştur for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] = X[i: i + p_h, j: j + p_w].max() #Her bir pool size kadar pixelin max'ını al return Y Şimdi kodumuzu yukarıda yazdığımız x arrayi ile test edersek, yine aynı sonucun çıkacağını göreceğiz. Bu yazımızda konuşulacaklar bu kadar. Beğendiyseniz paylaşmayı unutmayın. ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:4:1","tags":["numpy","pytorch","cnn"],"title":"Evrişimsel Sinir Ağları  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"REFERENCES https://anhreynolds.com/blogs/cnn.html https://cs231n.github.io/convolutional-networks/ https://cezannec.github.io/Convolutional_Neural_Networks/ https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D https://medium.com/ai-in-plain-english/pooling-layer-beginner-to-intermediate-fa0dbdce80eb ","date":"2020-12-17","objectID":"/evrisimsel-sinir-aglari-nedir/:5:0","tags":["numpy","pytorch","cnn"],"title":"Evrişimsel Sinir Ağları  (Convolutional Neural Network) Nedir","uri":"/evrisimsel-sinir-aglari-nedir/"},{"categories":null,"content":"Makine öğrenmesinde modellerin veriyi görme şekli biz insanlardan farklıdır. Biz kolayca Kırmızı arabayı görüyorum. cümlesini anlayabilirken, model bu kelimeleri anlayacak vektörlere ihtiyaç duyar. Bu vektörlere word embeddings denir. ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:0:0","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"WORD VECTORLERİ NASIL ÇALIŞIR - Tablodan Bak Her kelimemiz için belirli bir boyutta vektörümüz olacak ve bu vektörleri kelimeyi isteyerek alabiliriz. Buna key-value pair örneği verilebilir. key: kelime value: vektör Bundan dolayı herhangi bir kelimenin vektörüne bakmak için dictionaryden kelimeyi istediğimiz zaman vektöre ulaşmış olacağız. ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:1:0","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"Word2Vec: Tahmin Bazlı bir Metod Ana amacımız kelimelerden, kelime vektörleri oluşturmak. Word2Vec parametreli word vektörleri olan bir modeldir. Bu parametreler itaretive yöntemle, objective function(küçültmeye çalıştığımız fonksiyon) kullanarak optimize edilir. Peki bunu nasıl yapacağız. Unutmadan: amaç : her bir vektörü kelimenin içeriğini bilecek şekilde kodlamak nasıl yapılacak: vektörleri kelimelerden olası içerik tahmin edecek şekilde eğitmek. Word2Vec iterative bir metottur. Ana fikirleri kısaca şöyledir. büyük bir text corpusu alır texti, belirli bir sliding window(kayan pencere) kullanarak, her seferinde bir kelime ilerleyecek şekilde ilerlemek. Her bir adımda, bir tane central word (merkezi kelime) ve context words(içerik kelimeleri) -\u003e penceredeki diğer kelimeler. merkezi kelime için, içerik kelimelerinin olasılıklarını hesapla. vektörleri olasılıkları artıracak şekilde ayarla Resimde de görüleceği üzere her seferinde arkası mavi olan merkezi kelime ve diğerleri de içerik kelimeleri. ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:2:0","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"Objective Function (Amaç Fonksiyonu) Text corpusundaki her bir $ t = 1, … , T$ pozisyon için, Word2Vec merkezi kelimesi $w_{t}$ verilmiş m-boyutlu penceredeki içerik kelimelerini tahmin eder. $$ Likelihood = L(\\theta) = \\prod_{t=1}^{T} \\prod_{-m \\leq j \\leq m, j \\neq 0} P(w_{t + j} \\mid w_t, \\theta) $$ Bu fonksiyonda $\\theta$ optimize edilecek bütün parametrelerdir. Amaç ve Kayıp Fonksiyonu $J(\\theta) ise ortalama negatif log olabilirlik fonksiyonudur. (Negative log-likelihood) $$ J(\\theta) = -\\frac{1}{T} \\log L(\\theta) = -\\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-m \\leq j \\leq m, j \\neq 0 } \\log P(w_{t + j} \\mid w_t, \\theta) $$ Bu formüldeki parçalara ayıralım. $\\sum_{t=1}^{T}$ Bu kısım bütün text üzerinde gezinir. $\\prod_{-m \\leq j \\leq m, y \\neq 0}$ bu ise kayma penceresini(sliding window) temsil eder. $\\log P(w_{t + j} \\mid w_t, \\theta)$ : bu ise merkezi kelimesi verilen içeriğin olasılığını hesaplar. Peki asıl sorulması gereken soru bu olasılıklar nasıl hesaplanacak? ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:2:1","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"Olasılıkları Nasıl Hesaplayacağız? Hesaplamak istediğimiz olasılık $$ P(w_{t + j} \\mid w_t, \\theta) $$ Verilen her kelime $w$ için, iki adet vektörümüz var. $v_w$ -\u003e kelimenin merkezi kelime (central word) olduğu zaman $u_w$ -\u003e kelimenin içerik kelime (context word) olduğu zaman Vektörler train edildikten sonra, genel olarak içerik vektörlerini $u_w$ atar ve sadece merkezi kelime vektörlerini $v_w$ kullanılır. Bundan sonra verilen merkezi kelime $c$ ve içerik kelimesi $o$ kelimeleri için olasılık: $$ P(o \\mid c) = \\frac{exp(u_{o}^{T})}{\\sum_{v \\in V} exp(u_{w}^{T} v_c)} $$ NOT: Bu bir softmax fonksiyonudur. Softmax ile alakalı yazıma bu yazımdan ulaşabilirsiniz. Şimdi bu olasılıkları nasıl hesaplayacağımız gördüğümüze göre, vektörleri nasıl eğiteceğimizi görelim. ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:2:2","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"NASIL EĞİTİLİR Kısaca bu sorunun cevabı Gradient Descent ile her seferinde bir kelime alarak gerçekleşir. Parametrelerimiz $\\theta$ bütün kelimelerin $v_w$ ve $u_w$ vektörleri olduğunu hatırlayalım. Bu vektörleri gradient descent kullanarak optimize edeceğiz. $$ \\theta^{new} = \\theta^{old} - \\alpha \\nabla_{\\theta} J(\\theta) $$ Bu parametre güncellemerini her seferinde bir kelime kullanarak yapıyoruz. Her bir güncelleme bir merkez kelime ve içerik kelimesi ikilileriyle yapılır. Tekrardan kayıp fonksiyonuna bakalım. $$ J(\\theta) = -\\frac{1}{T} \\log L(\\theta) = -\\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-m \\leq j \\leq m, j \\neq 0 } \\log P(w_{t + j} \\mid w_t, \\theta) $$ Merkezi kelime $w_t$ için, kayıp fonksiyonu ayrı bir terimi her bir içerik kelimesi (w_{t + j}) (sliding window içerisindeki) (J_{t,j}(\\theta) = -\\log P(w_{t + j} \\mid w_t, \\theta\\ Bir örnek vererek bu durumu daha iyi anlayalım. Şu cümleyi ele alalım. Bugün bahçede bir top gördüm. Yeşil renkli bir kelimesi burada bizim merkezi kelimemizdir. Her seferinde bir kelimeye bakacağımız için, bir tane içerik kelimesi seçeceğiz. Örnek olarak top kelimesini ele alalım. Bundan sonra bu iki kelime için kayıp fonksiyonu Buradaki $V$ kümesi sliding windowu kapsayan kelimelerden oluşur. Loss (kayıp) fonksiyonumuzu aldığıma göre, şimdi vektörler üzerinde güncelleme yapalım. Burada hangi parameterlerin olduğuna göz atalım. merkezi kelime vektörlerinden sadece $v_{bir}$ içerik kelime vektörlerinden ise sliding window içerisindeki bütün kelimeler $u_w \\forall w \\in V$ Şuanki adımda sadece bu parametreler güncellenecek. $$ v_{bir} := v_{bir} - \\alpha \\frac{\\partial J_{t, j}(\\theta)}{\\partial v_{bir}} $$ $$ u_w = u_w - \\alpha \\frac{\\partial J_{t, j}(\\theta)}{\\partial u_{w}} \\forall w \\in V $$ Kayıp fonksiyonunu azaltacak şekilde yaptığımız her bir güncelleme, parametreler arasındaki benzerliği $v_{bir} \\hspace{1mm} ve \\hspace{1mm} u_{top}$ dot product’ını artırıyor ve aynı zamanda diğer her bir diğer $u_w$ ile $v_{bir}$ arasındaki benzerliği de azaltıyor. Bu biraz garip gelebilir ancak neden bir kelimesinin top kelimesinden hariç diğer kelimelerle benzerliğini azaltmaya çalışıyoruz. Diğerleri de mantıklı, içerik verecek kelimeler olabilir. Ancak bu bir sorun değil! Biz bu güncellemeyi her kelime için tek tek yaptığımızdan dolayı, yani her kelime bir kez merkezi kelime olacak, vektörler üzerindeki bütün güncellemelerin ortalaması metin içeriğininin dağılımını öğrenecektir. Bu yazıda partial derivative kısımlarına girilmemiştir. Ancak ben genel olarak Word2Vec modelinin nasıl çalıştığını anlatabildiğimi düşünüyorum. Eğer denemek isterseniz partial derivative kısımlarını kendiniz deneyebilirsiniz. Diğer yazılarda görüşmek üzere. Eğer yazıyı beğendiyseniz paylaşmayı unutmayın ki diğer insanlar da yararlansın. ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:2:3","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"REFERENCES https://lena-voita.github.io/nlp_course/word_embeddings.html ","date":"2020-12-14","objectID":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/:3:0","tags":["makine ogrenmesi","nlp"],"title":"Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir","uri":"/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"},{"categories":null,"content":"Problem Tanımı Knapsack problemi bilgisayar biliminde çok meşhur bir problemdir. Bu problemdeki amaç verilen ağırlık ve değerlerle en fazla değer toplayacak şekilde verilen ağırlık limitini aşmadan hangi itemlerin seçileceğidir. Knapscak problemi bir yüzyıldan fazla bir süredir, 1897 e kadar çalışmalar vardır. İsmini matematikçi Tobias Dantzig adlı matematikçinin eski çalışmalarından alır. Buradaki problemimiz için birden fazla yöntem vardır. Biz dinamik programlama ile bu problemin nasıl hallediliğine bakacağız. Şimdi problemdeki input ve istenilen outputa bakalım ","date":"2020-11-18","objectID":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/:1:0","tags":["algoritmalar","python"],"title":"Dinamik Programlama ile Knapsack Problemi Nasıl Çözülür","uri":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/"},{"categories":null,"content":"INPUT Maksimum ağırlık limiti W ve elimizdeki paket sayısı n Ağırlıkların bulunduğu w[i] ve buna eş değer olan değer v[i] ","date":"2020-11-18","objectID":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/:1:1","tags":["algoritmalar","python"],"title":"Dinamik Programlama ile Knapsack Problemi Nasıl Çözülür","uri":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/"},{"categories":null,"content":"OUTPUT Maksimum değer Hangi paketlerin alındığı ","date":"2020-11-18","objectID":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/:1:2","tags":["algoritmalar","python"],"title":"Dinamik Programlama ile Knapsack Problemi Nasıl Çözülür","uri":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/"},{"categories":null,"content":"İMPLEMENTASYON Bu problemi analiz ederken algoritmanın hangi değerlere bağlı olacağını bulmaktır. Buradaki algoritmamız 2 ayrı değişkene dayanır. Bunların birincisi kaç tane paket taşıyacağımız ve elimizde kalan ağırlık limiti. Evet algoritmamızı iki değişkene bağlı şekilde yazacağız. Örnek olarak ilk 3 elemanı alarak, j maksimum limitli bir prpblemde optimum değer kaçtır. Buradaki ilk 3 eleman, hangi elemanları seçeceğimiz değişkenine örnektir. J limit ise ne kadar ağırlık limitimizin olduğudur. Bundan dolayı bir matrix oluşturup, her alt problemdeki optimum çözümü yazarsak bu şekilde istenilen sonuca ulaşabiliriz. Bundan dolayı [n+1][W+1] boyutlarında bir matrixte elimizdeki her alt alt problem için çözümleri saklayacağız. K[i][j] deki değer şu anlama geliyor: İlk i elemanı alarak j ağırlık limitli bir problemdeki optimum çözüm nedir. Peki bizim soruda ne isteniyordu? n elemanı kullanarak W limitli bir problemdeki çözüm nedir. Bundan dolayı bizim istediğimiz sonuç ise matrixin en son elemanı olan K[n][W] dir. Peki asıl soru olan her bu K[i][j] nasıl bulacağız. Öncelikle matriximizin ilk satırının hepsi 0 olacak. Bunun nedeni ise 0 item kullanırsak elde edebileceğimiz maksimum değer 0 dır. Diğer satırlarda ise durum farklıdır. Bundan dolayı her $1\\leq i \\leq n$ ve her $0 \\leq j \\leq W$ için bir durumu kontrol etmemiz gerekiyor. Kontrol etmemiz gereken değişken şuanki durumda yani item i ağırlığı şuanki j (ağırlık limiti) büyük mü. Çünkü eğer bizim şuanki itemimizin ağırlığı ağırlık limitimizden büyükse o itemi basitçe alamayız. Bu itemi alamadığımız için K[i][j] == K[i-1][j] olacak. Nedeni ise bu itemi seçmediğimiz için o durumdaki en optimum çözüm, o iteme kadar olanki en optimum çözüme eşittir. if w[i] \u003e j: K[i][j] = K[i-1][j] Eğer bu durum gerçekleşme ise elimizde iki seçenek var. Birinci seçenek şuanki itemi almamak. Bu durum yukarda bahsettiğimizin aynısı yani K[i][j] = K[i-1][j] İkinci seçenek ise bu itemi almak. Bu durumda elimizde olan optimum çözüm şu anlama geliyor. Şuanki itemin değeri v[i] Bu itemi aldığımız için geriye kalan j - w[i] ağırlık limitli ve ilk i-1 item arasındaki optimum çözüm, yani K[i-1][j-w[i]] Bu durumda ise optimum çözüm şu anlama geliyor. K[i][j] = v[i] + K[i-1][j - w[i]] Elimizde iki seçenek var. Peki hangisini seçeceğiz. Çok basit, en yüksek olan hangisi ise bunu seçeceğiz. Yani K[i][j] = max(K[i])[j], v[i] + K[i-1][j - w[i]]) Eğer bir basit bir kod yazmak istersek for j in range(W+1) K[0][j] = 0 //Yani İlk satırı 0 yap for i in range(1, n+1) for j in range(0, W + 1) if w[i] \u003e j // Eğer şuanki ağırlığımız şuanki limitten büyükse K[i][j] = 0 else K[i][j] = max(K[i-1][j], v[i] + K[i-1][j - w[i]]) Bizim çözümümüz ise K[n][W] deki değerdir. BackTracking kısmını sonra ekleyeceğim. ","date":"2020-11-18","objectID":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/:1:3","tags":["algoritmalar","python"],"title":"Dinamik Programlama ile Knapsack Problemi Nasıl Çözülür","uri":"/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/"},{"categories":null,"content":"NUMPY import numpy as np ","date":"2020-11-09","objectID":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/:0:0","tags":["numpy"],"title":"Kapsamli Şekilde Python Numpy Öğrenelim","uri":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/"},{"categories":null,"content":"NUMPY ARRAY Python’daki listelere çok benzerdir. Numoy arrayleri sadece aynı veri türüne sahip listeleri barındırabilir. Arrayler daha az hafızada yer kaplar. Array oluşturmak için yapmamız gereken a = np.array([1, 2, 3, 4]) type(a) numpy.ndarray Buna ek olarak da, arraylere tuple ekleyebiliriz. Örnek olarak a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) print(\"Birinci eleman {}\".format(a[0])) print(\"Birinci elemanın birinci elemanı {}\".format(a[0][0])) Birinci eleman [1 2 3] Birinci elemanın birinci elemanı 1 ","date":"2020-11-09","objectID":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/:1:0","tags":["numpy"],"title":"Kapsamli Şekilde Python Numpy Öğrenelim","uri":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/"},{"categories":null,"content":"ARRAY ÖZELLİKLERİ Arrayin boyutlarını öğrenmek için yapmamız gereken **array.shape** yazmak olacaktır Arrayin rankini öğrenmek için yapmamız gereken **array.ndim** yazmak olacaktır Arrayin boyutunu öğrenmek için yapmamız gereken **array.size** yazmak olacaktır Arrayin barındırdığı veri tipini öğrenmek için yapmamız gereken **array.dtype** yazmak olacaktır print(\"Arrayin boyutları {}\".format(a.shape)) print(\"Arrayin ranki {}\".format(a.ndim)) print(\"Arraydeki eleman sayısı {}\".format(a.size)) print(\"Arrayin veri tipi {}\".format(a.dtype)) Arrayin boyutları (3, 3) Arrayin ranki 2 Arraydeki eleman sayısı 9 Arrayin veri tipi int64 ","date":"2020-11-09","objectID":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/:1:1","tags":["numpy"],"title":"Kapsamli Şekilde Python Numpy Öğrenelim","uri":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/"},{"categories":null,"content":"ARRAY FONKSİYONLARI Arraylerden Sıfır Oluşturmak için yapmamız gereken shape yerine istediğimiz boyutları girmek. Numpy bizim için gerekli arrayi oluşturacaktır. shape = (2, 2) zeros = np.zeros(shape) zeros array([[0., 0.], [0., 0.]]) Arraylerden Bir Oluşturmak için yapmamız gereken shape yerine istediğimiz boyutları girmek. Numpy bizim için gerekli arrayi oluşturacaktır. shape = (2, 2) ones = np.ones(shape) ones array([[1., 1.], [1., 1.]]) İstediğimiz bir değerle istediğimiz boyutta bir array oluşturmak için ise np.full kullanıyoruz. a = np.full((6,5), 29) print(a) [[29 29 29 29 29] [29 29 29 29 29] [29 29 29 29 29] [29 29 29 29 29] [29 29 29 29 29] [29 29 29 29 29]] İdentity Matrix (Birim Matris) oluşturmak için ise np.eyeyazmak olacaktır. np.eye(3) array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) Eğer belirli bir aralıkta belirli sayılarla artan bir array oluşturmak istiyorsak np.arange kullanmalıyız. rangearray = np.arange(10,100,10, dtype=float) rangearray array([10., 20., 30., 40., 50., 60., 70., 80., 90.]) Eğer yine belirli bir aralıkta değerler oluşturmak istiyorsak ve kaç tane oluşturacağımızı biliyorsak np.linspace kullanabiliriz. linarray = np.linspace(10, 100, 5) linarray array([ 10. , 32.5, 55. , 77.5, 100. ]) np.arange de 100 dahil değildi. Ancak np.linspace de dahil. Bunu da gözden kaçırmamak gerekir. Şimdi ise çok önemli bir fonksiyon olan np.reshape fonksiyonuna bakalım. Bu fonksiyon ile arraylerimizi istediğimiz formata çevirme şansımız var. array = np.arange(20) print(\"Önceki hali : \\n\", array) new_array = np.reshape(array, (4,5)) print(\"Sonraki hali : \\n\", new_array) Önceki hali : [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19] Sonraki hali : [[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14] [15 16 17 18 19]] ","date":"2020-11-09","objectID":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/:1:2","tags":["numpy"],"title":"Kapsamli Şekilde Python Numpy Öğrenelim","uri":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/"},{"categories":null,"content":"ARRAY INDEKSLEME (ARRAY INDEXING) Numpy arrayleri indekslemede çok kolaylık sağlıyor. Bir Boyutlu Array a1 = np.array([1, 3, 4, 5, 2, 10]) a1[0] 1 a1[4] 2 a1[-1] 10 a1[-3] 5 ÇOK BOYUTLU ARRAY a2 = np.array([[3, 4, 5, 6], [1, 3, 7, 2], [8, 4, 5, 10], [12, 124, 125, 126]]) a2[0] array([3, 4, 5, 6]) a2[0, 0] 3 a2[2, -1] # 2.indexin son elemanı 10 a2[2, 0] = 100 # 2.elemanın 0.elemanını 100 yap a2 array([[ 3, 4, 5, 6], [ 1, 3, 7, 2], [100, 4, 5, 10], [ 12, 124, 125, 126]]) a2[[0, 0, 2, 1]] # 0.index, 0.index, 2.index, 1.index array([[ 3, 4, 5, 6], [ 3, 4, 5, 6], [100, 4, 5, 10], [ 1, 3, 7, 2]]) a2[:2, ::2] # 2.satıra kadar 0 ile 2. indexler array([[3, 5], [1, 7]]) a2[::-1, ::-1] # Arrayi ters çevir array([[126, 125, 124, 12], [ 10, 5, 4, 100], [ 2, 7, 3, 1], [ 6, 5, 4, 3]]) a2[:, 0] # İlk sutün array([ 3, 1, 100, 12]) a2[0, :] # İlk satır array([3, 4, 5, 6]) I will ad other features to see how it is going ","date":"2020-11-09","objectID":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/:1:3","tags":["numpy"],"title":"Kapsamli Şekilde Python Numpy Öğrenelim","uri":"/python-numpy-nedir-ve-neden-numpy-kullanmaliyiz/"},{"categories":null,"content":"Merhaba bu yazımızda Makine Öğrenmesinde meşhur bir algoritma olan Knn algoritmasını sıfırdan yazacağız. Tabii ki hazır bir sürü kütüphane var ancak sıfırdan algoritmayı yazabilmek bize algoritmanın nasıl çalışacağını gösterecektir. Böylece Knn algoritması bir tahmin yaparken nasıl yapıyor olayın arkasında neler dönüyor bunları anlayabiliyor olacağız. ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:0:0","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"K-Nearest Neighbour Nedir Öncelikle şunu bilmek gerekir ki K-Nearest-Neighbour adından da anlaşılacağı üzere en yakın k komşu noktalara bakıp en çok hangi label varsa o labelı tahmin(prediction) olarak verir. Peki bu yakınlık uzaklık ilişkisi nasıl kurulur önce ona bakalım. Uzaklığı ölçebilmek için belli başlı algoritmalar vardır. Bunlardan biri eucledian diğeri de manhattan uzaklığıdır. ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:1:0","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"Eucledian Uzaklığı Manhattan uzaklığında aslında iki nokta arasında uzaklığı alırken normal 2 boyutlu denklemde nasıl alıyorsak, bunun n boyutlu formüle döndürülmüş halidir. Örnek olarak $a = (x_1, y_1)$ ve $b = (x_2, y_2)$ olsun. Bu noktalar arasında uzaklığı bulurken yaptığımız işlem $$d(a, b) = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$$ Peki eğer bizim verimiz n boyutlu olursa bu uzaklık nasıl ölçülecek?. Bu durumda ise uzaklık $$d(a,b)= \\sum_{i=1}^n (a_i - b_i)^2$$ Bu formulu ise Numpy ile şu şekilde yazabiliriz np.sqrt(np.sum(np.square(a - b), axis=1)) ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:1:1","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"Manhattan Uzaklığı Manhattan uzaklığında iki nokta arasındaki uzaklık her bir alt noktanın farkının mutlak değerlerinin toplamı ile bulunur. Örnek olarak $a = (x_1, y_1)$ ve $b = (x_2, y_2)$ olsun. Bu noktalar arasında uzaklığı bulurken yaptığımız işlem $$d(a, b) = \\lvert x_1 - x_2\\rvert + \\lvert y_1 - y_2 \\rvert$$ Peki eğer bizim verimiz n boyutlu olursa bu uzaklık nasıl ölçülecek?. Bu durumda ise uzaklık $$d(a,b)= \\sum_{i=1}^n \\lvert a_i - b_i\\rvert$$ Bu formulu ise Numpy ile şu şekilde yazabiliriz np.sum(np.abs(a - b), axis=1) ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:1:2","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"Algoritma Akışı KNN algoritmasında eğitme (training) işlemi aslında sadece verilen veriyi ezberlemekten ibarettir. Bundan dolayı eğitme kısmında bir şey yapmayacağız ancak tahmin etme (prediction) kısmında ise asıl üstteki formuülleri kullanıp işlem yapacağız. Bu algoritmayı Python ile Numpy Kullanarak implement edeceğiz. Önceklikle şu komut ile Numpy kütüphanesini import edelim. import numpy as np Şimdi Bir tane class tanımlayalım. Öncelikle kaç tane komşu kullanacağı modelin bir parametresi k olacak. Daha sonra hangi uzaklık formülünü kullanacağı da modelin bir parametresi olacak. Hadi başlayalım. class KNN: def __init__(self, k=2, uzaklık=\"eucledian\"): self.k = 2 self.uzaklık = uzaklık Üstteki kod bloğunda yaptığımız işlem aslında modelin parametrelerini constructor fonskiyonunda tanımlamak oldu. Şimdi modelin eğitme fonksiyonunu yazalım. class KNN: def __init__(self, k=2, uzaklık=\"eucledian\"): self.k = 2 self.uzaklık = uzaklık def fit(self, X, y): self.X = X self.y = y Yukarıda da bahsettiğimiz gibi Knn algoritması aslında sadece eğitme verisini ezberler. Bütün işlemler prediction kısmında yapılır. Bundan dolayı eğitme verisini modelin eğitim seti olarak değiştirebiliriz. Şimdi en önemli konu olan prediction kısmına gelelim. ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:2:0","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"Tahmin Etme (Prediction) Kısmı Nasıl Olacak? Öncelikle uzaklıklar hesaplanacak Daha sonra en yakın k tane nokta alınacak Daha sonra bu en yakın k noktanın label sayılarını belirleyeceğiz. Yani hangi labeldan kaç tane olduğunu belirleyeceğiz. Daha sonra en çok sayısı olan label bizim tahminimiz olarak Diyelim ki bizim elimizde bir tane a verisi olsun ve eucledian uzaklık kullanıyor olalım. Bir nokta için nasıl bir işlem gerekiyor ona bakalım. #Uzaklık Hesaplama uzaklıklar = np.sqrt(np.sum(np.square(X - a), axis=1)) #En yakın k noktanın indexlerini bulalım en_yakın_k_index = np.argsort(uzaklıklar)[:k] #Şimdi bu en yakın k indexin hangi labellara ait olduğunu bulalım. en_yakın_labellar = y[en_yakın_k_index] #Daha sonra bu en yakın labellarda her labeldan kaç tane olduğunu bulalım labellar, adetler = np.unique(en_yakın_labellar, return_counts=True) #Daha sonra en çok hangi labelın sayısı var bunu bulalım max_label_index = np.argmax(adetler) #Daha sonra en çok sayısı olan label döndürelim return labellar[max_label_index] Şimdi burada bir sürü numpy fonksiyonu kullandık, bunlar kafa karıştırmış olabilir. Bundan dolayı bu fonksiyonlar ne işe yarıyor kısaca anlatayım. np.argsort(array): Bu fonksiyon parametre olarak aldığı arrayi sortlayacak indexleri verir. Aslında arrayi sortlamaz, ancak hangi indexler arrayi sortlar onu verir. np.unique(array, return_counts=True): Bu fonksiyon ise array içerisindeki unique elemanları dönderir. Eğer return_counts=True ise o zaman bu unique elemanlardan kaç tane var onu da gösterir. Örnek olarak array = [2, 3, 4, 3, 2, 10, 2] labellar, sayılar = np.unique(array, return_counts) print(labellar) #(2, 3, 4, 10) print(sayılar) #(3, 2, 1, 1) Labellar bizim arrayimizde hangi unique label var onları dönderir. Sayılar ise hangi labeldan kaç tane var onu dönderir. Örnek olarak 2 den 3 tane var. 10’dan 1 tane var. np.argmax(array): Bu fonksiyon array içerisindeki maximum elemanın indexini verir. Mesela yukarıdaki arrayde maximum eleman 10 ve 10’un indexi 5 dir. np.argmax() bu 5 indexini dönderir. Şimdi bu bir nokta içindi. Bunu test verimizde her bir nokta için yapalım. KNN Classının içerisinde implement edelim. class KNN: def __init__(self, k=2, uzaklık=\"eucledian\"): self.k = 2 self.uzaklık = uzaklık def fit(self, X, y): self.X = X self.y = y def predict(self, X_test): predictions = [] for point in X_test: if self.uzaklık == \"eucledian\": uzaklık = np.sqrt(np.sum(np.square(self.X - point), axis=1)) elif self.uzaklık == \"manhattan\": uzaklık = np.sum(np.abs(self.X - point), axis=1) indices = np.argsort(uzaklık)[:self.k] near_labels = self.y[indices] labels, values = np.unique(near_labels, return_counts=True) max_ind_label = np.argmax(values) prediction = labels[max_ind_label] predictions.append(prediction) return np.array(predictions) Yaptığımız işlemler her nokta için uzaklığı hesapladık en yakın k noktanın labellarını aldık bu labelların sayılarını öğrendik en çok label kimdeyse onu tahmin olarak öne sürdük Bu KNN modelini istediğiniz veride kullabilirsiniz. Daha kapsamlı koda bakmak isterseniz bu Github Repo’ya bakabilirsiniz. Bir sonraki yazıda görüşmek üzere. ","date":"2020-11-08","objectID":"/python-numpy-ile-sifirdan-knn-yazalim/:2:1","tags":["numpy","knn","makine ogrenmesi"],"title":"Python Numpy ile Sifirdan K Nearest Neighbours Algoritmasini Yazalim","uri":"/python-numpy-ile-sifirdan-knn-yazalim/"},{"categories":null,"content":"TANIM Softmax fonksiyonu modelden çıkan sonuçların olasılıksal şekilde ifade edilmesi için kullanılan bir fonksiyondur. Genellikle nöral ağlarda (neural network) ağın sonucunu sınıflara olasılık değerleri vermek için kullanılır. Softmax fonksiyonu input olarak $K$ boyutlu uzaydan vektör $z$ alır. Bu vektörü $K$ olasılık değerlerinden oluşan bir olasılık dağılımına çevirir. Bu olasılıkların her biri exponentialları ile doğru orantılıdır. Softmax fonksiyonu uygulamadan önce bu $z$ vektöründeki bazı değerler negatif de olabilir 0 da olabilir, pozitif de olabilir. Softmax fonksiyonunu uyguladıktan sonra ise bütün değerler $(0, 1)$ aralığında değer alır ve bütün değerlerin toplamı 1 olur. Standart softmax function tanımı şu şekildedir. $\\sigma : \\mathbb{R^{K}} \\rightarrow \\mathbb{R^K}$ Bir diğer deyişle bizim yaptığımız işlem her bir değerin exponential fonksiyonunu almak ve bunu toplama bölmek. Böylece normalize etmiş oluyoruz ve bütün değerleri topladığımız zaman sonuç 1 ediyor. Örnek olarak vektör $k = [1, 1, 1] \\in \\mathbb{R^3}$ olsun. O zaman, $$ \\sigma(k) = [\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}] $$ Peki bunu nasıl bulduk. Öncelikle toplamı hesaplayalım $$ \\sum_{j=1}^{K}e^{k_i} = e^1 + e^1 + e^1 = 3e $$ Toplam $3e$ çıktı. Şimdi her bir değeri exponential fonskiyona input olarak verirsek çıkacak sonuç $e^1 = e$ olur. Bizim softmax fonksiyonunda yaptığımız işlem ise bu değerleri alıp toplama bölmek. Yani, $$ \\frac{e}{3e} = \\frac{1}{3} $$ ","date":"2020-08-12","objectID":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/:1:0","tags":["numpy","derin ogrenme","matematik"],"title":"Softmax Aktivasyon Fonksiyonu Nedir ve Numpy ile Nasıl Implement Edilir","uri":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/"},{"categories":null,"content":"NUMPY İLE NASIL İMPLEMENT EDİLİR Numpy fonksiyonunda arrayin direk exponential fonksiyonunu alabiliriz. Bunun için for loop açmamıza gerek yok import numpy as np arr = np.array([1, 3, 2]) exponential_arr = np.exp(arr) print(\"Array: {} \\nExponential Array: {} \\n\".format(arr, exponential_arr)) Array: [1 2 3] Exponential Array : [ 2.71828183 7.3890561 20.08553692] Arrayin direk üstel şekilde toplamını da alabiliriz. sum_of_exponentials = np.sum(exponential_arr) print(\"Exponential Array Toplamı: \", sum_of_exponentials) Exponential Array Toplamı: 30.19287485057736 Şimdi softmax implement etmek için her şeye sahibiz. Fonksiyon şeklinde implement edebiliriz. def softmax(arr): exp_array = np.exp(arr) exp_toplam = np.sum(exp_array) return exp_array/exp_toplam Şimdi fonksiyonumuzu test edelim arr = np.array([1, 1, 1]) softmax_array = softmax(arr) print(\"Array: {} \\nSoftmax Array: {}\".format(arr, softmax_array)) Array: [1 1 1] Softmax Array: [0.33333333 0.33333333 0.33333333] Gördüğümüz üzere softmax fonksiyondan çıkan arrayin toplamı 1 e eşit oluyor np.sum(softmax_array) #Sonuç 1 çıkıyor. Softmax fonksiyonu bu kadar. Bir sonraki yazıda görüşmek üzere. ","date":"2020-08-12","objectID":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/:2:0","tags":["numpy","derin ogrenme","matematik"],"title":"Softmax Aktivasyon Fonksiyonu Nedir ve Numpy ile Nasıl Implement Edilir","uri":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/"},{"categories":null,"content":"REFERENCES wikipedia-softmax ","date":"2020-08-12","objectID":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/:3:0","tags":["numpy","derin ogrenme","matematik"],"title":"Softmax Aktivasyon Fonksiyonu Nedir ve Numpy ile Nasıl Implement Edilir","uri":"/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/"},{"categories":null,"content":"TANIM İstatistik, verilen bir örneklemden(sample) elde edilen herhangi bir değer demektir. İstatistiksel öğrenmede, verilen sampledan sağlanan bilgi ile karar verilir. İlk yaklaşımımız, sample’ın belirli bir dağılımdan (distribution) geldiğini farz ederek yapmak olacaktır. Bu dağılıma örnek olarak Gaussian dağılım verilebilir. Bu durumun avantajı ise, parametre sayısının azaltılması olacaktır. Tüm parametrelerimiz ortalama değer (mean) ve varyans (variance) olacaktır. Bu parametreleri sample tarafından elde ettikten sonra, bütün dağılımı biliyor olacağız. Bu parametreleri verilen sample üzerinden öğrenip, daha sonra bu bulduğumuz ortalama ve varyans değerlerini modele entegre ederek, tahmini bir dağılım elde edeceğiz. Daha sonra bu dağılımı da karar vermek için kullanacağız. Öncelikle olasılık kavramı diğer ismiyle density estimation (yoğunluk tahmini) anlamına gelen $p\\left(x\\right)$ kavramı ile başlıyoruz. Bu kavramı, Naive Bayesde de olduğu gibi tahmini olasılıkların $p(x \\mid C_{i})$, ve prior olasılık olan $P\\left(C_{i}\\right)$ olduğu ve bu olasılıkların daha sonra asıl amaç olan $P\\left(C_{i} \\mid x\\right)$‘i tahmin ederek sınıflandırma işlemi yapılması için kullanıyoruz. Peki bu parametreleri nasıl öğreneceğiz. Maksimum Likelihood Estimation kullanarak yapacağız. ","date":"2020-01-12","objectID":"/makine-ogrenmesinde-parametrik-metodlar/:1:0","tags":["makine ogrenmesi","matematik"],"title":"Makine Ogrenmesinde Parametrik Metodlar","uri":"/makine-ogrenmesinde-parametrik-metodlar/"},{"categories":null,"content":"Maximum Likelihood Estimation (Maksimum Olasılık Tahmini) Elimizde birbirinden bağımsız ve aynı şekilde dağıtılmış olan bir sample var. Bu sample’ı $X = \\{ x^{t} \\}_{i=1}^{N}$ şeklinde gösterebiliriz. Bu sampledan çekilen her bir $x^{t}$ örneğin, bilinen bir olasılık dağılımına ait olduğunu varsayıyoruz. Bu olasılık dağılımını da $p\\left(x \\mid \\theta \\right)$ gösteriyoruz. $$ x^{t} \\sim p(x|\\theta) $$ Bizim buradaki amacımız bize en yüksek olasılığı $p\\left(x \\mid \\theta \\right)$ verecek olan $\\theta$ değerini bulmak. Bütün örnekler $x^{t}$ birbirinden bağımsız olduğundan parametre $\\theta$ nın olasılık fonksiyonu bütün verilen sampleların olasılıklarının çarpımına eşittir. $$ l(\\theta | X) = p(X|\\theta) = \\prod_{t=1}^{N}p(x^{i}|\\theta) $$ Maksimum olasılık tahmininde, bu değeri maksimum yapan $\\theta$ değerini bulmak istiyoruz. Bunu bulmak için önce logaritma alıp, daha sonra nerede maksimum yaptığına bakabiliriz. Logaritma alma sebebimiz ise logaritmanın çarpım sembolünü toplama çevirmesi ve başka kolaylıklar sağlaması dolayısıyladır. Log olasılık ise şöyle tanımlanır. $$ l(\\theta | X) \\equiv \\log l(\\theta | X) = \\sum_{t = 1}^{N}\\log p(x^{t}|\\theta) $$ Yazımızın başında bu her sample ın belirli bir dağılımdan geldiğini söylemiştik. Bunun için bir sürü seçenek olabilir. Bernouilli, Multinomial ve Gaussian(Normal) dağılımlar olabilir. Ancak biz burada sadece Gaussian(Normal) dağılım ile ilgilineceğiz. ","date":"2020-01-12","objectID":"/makine-ogrenmesinde-parametrik-metodlar/:1:1","tags":["makine ogrenmesi","matematik"],"title":"Makine Ogrenmesinde Parametrik Metodlar","uri":"/makine-ogrenmesinde-parametrik-metodlar/"},{"categories":null,"content":"NORMAL DAĞILIMDA MAXİMUM LIKELIHOOD ESTIMATION X, ortalama yani $E[X] \\equiv \\mu$ ve varyans $Var(X) \\equiv \\sigma^{2}$ değerlerine sahip normal dağılımla dağıtılmış bir random variable olsun. O zaman density (yoğunluk) fonksiyonu şu şekilde $$ N(\\mu , \\sigma^{2}) = p(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x - \\mu)^2}{2\\sigma^{2}}} $$ O zaman verilen sampleın $X = \\{ x^t \\}_{t=1}^{N}$ log likelihood değeri de şu şekilde olur. $$ l(\\mu, \\sigma | X) = -\\frac{N}{2}\\log(2\\pi) - N \\log(\\sigma) - \\frac{\\sum_{t}(x^t - \\mu)^{2}}{2\\sigma^{2}} $$ Daha sonra sırayla bu fonksiyonun ortalama değer ve varyans için partial türevlerini alıp sıfıra eşitlediğimizde ortaya şöyle bir sonuç çıkıyor. $$ m = \\frac{\\sum_{t}x^t}{N} $$ $$ s^2 = \\frac{\\sum_{t}(x^t - m)^2}{N} $$ Burada $m$ ortalama değer için maximum likelihood estimate oluyor ve $s^2$ ise varyans için maximum likelihood estimate oluyor. Bu durumda istenilen parametreleri bulmuş olduk. Bundan sonraki yazıda ise bias(önyargı) ve Varyans(Variance) konuları işleyeceğiz. Sonraki yazılarda görüşmek üzere. ","date":"2020-01-12","objectID":"/makine-ogrenmesinde-parametrik-metodlar/:1:2","tags":["makine ogrenmesi","matematik"],"title":"Makine Ogrenmesinde Parametrik Metodlar","uri":"/makine-ogrenmesinde-parametrik-metodlar/"},{"categories":null,"content":"Hello there, Welcome to My Blog. I graduated 🎓 from Sabanci University in 2022 and I am currently working as Backend Developer 💻 in Turkey. I love reading and one day I decided why I do not start a blog so people can read my writings. I am not a consistent writer but I will try to write more. There are both Turkish and English posts, and it will be like this in the future as well. Please stay tuned, Bye Here are my social links Github Linkedin Email ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"}]