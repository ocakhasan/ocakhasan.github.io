<!doctype html><html lang=tr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir - Hasan Ocak Tech Blog</title><meta name=Description content="Çeşitli konulardan bahseden bir tech blog"><meta property="og:title" content="Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir"><meta property="og:description" content="Natural Language Processing&rsquo;de kullanılan Word2Vec modelini inceliyoruz."><meta property="og:type" content="article"><meta property="og:url" content="https://ocakhasan.github.io/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/"><meta property="og:image" content="https://ocakhasan.github.io/logo.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-12-14T00:00:00+00:00"><meta property="article:modified_time" content="2022-12-11T23:28:32+03:00"><meta property="og:site_name" content="Hasan Ocak Tech Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://ocakhasan.github.io/logo.png"><meta name=twitter:title content="Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir"><meta name=twitter:description content="Natural Language Processing&rsquo;de kullanılan Word2Vec modelini inceliyoruz."><meta name=application-name content="Hasan Ocak Tech Blog"><meta name=apple-mobile-web-app-title content="Hasan Ocak Tech Blog"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://ocakhasan.github.io/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/><link rel=prev href=https://ocakhasan.github.io/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/><link rel=next href=https://ocakhasan.github.io/evrisimsel-sinir-aglari-nedir/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=/lib/fontawesome-free/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/lib/animate/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><meta name=google-site-verification content="6FsPs8qV_9zEnPMWf3bEQwRJFU2Q9imUdyZqX_99So4"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir","inLanguage":"tr","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/ocakhasan.github.io\/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir\/"},"genre":"posts","keywords":"makine ogrenmesi, nlp","wordcount":822,"url":"https:\/\/ocakhasan.github.io\/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir\/","datePublished":"2020-12-14T00:00:00+00:00","dateModified":"2022-12-11T23:28:32+03:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Hasan Ocak"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Hasan Ocak Tech Blog">Hasan Ocak</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/about>About </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span>
</span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Hasan Ocak Tech Blog">Hasan Ocak</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/ title>Posts</a><a class=menu-item href=/tags/ title>Tags</a><a class=menu-item href=/about title>About</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>Hasan Ocak</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2020-12-14>2020-12-14</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;822 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;4 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#word-vectorleri-nasil-çalişir---tablodan-bak>WORD VECTORLERİ NASIL ÇALIŞIR - Tablodan Bak</a></li><li><a href=#word2vec-tahmin-bazlı-bir-metod>Word2Vec: Tahmin Bazlı bir Metod</a><ul><li><a href=#objective-function-amaç-fonksiyonu>Objective Function (Amaç Fonksiyonu)</a></li><li><a href=#olasılıkları-nasıl-hesaplayacağız>Olasılıkları Nasıl Hesaplayacağız?</a></li><li><a href=#nasil-eğitilir>NASIL EĞİTİLİR</a></li></ul></li><li><a href=#references>REFERENCES</a></li></ul></nav></div></div><div class=content id=content><p>Makine öğrenmesinde modellerin veriyi görme şekli biz insanlardan farklıdır. Biz kolayca <em><strong>Kırmızı arabayı görüyorum.</strong></em> cümlesini anlayabilirken, model bu kelimeleri anlayacak vektörlere ihtiyaç duyar. Bu vektörlere <code>word embeddings</code> denir.</p><h2 id=word-vectorleri-nasil-çalişir---tablodan-bak>WORD VECTORLERİ NASIL ÇALIŞIR - Tablodan Bak</h2><p>Her kelimemiz için belirli bir boyutta vektörümüz olacak ve bu vektörleri kelimeyi isteyerek alabiliriz.</p><p>Buna key-value pair örneği verilebilir.</p><ul><li>key: kelime</li><li>value: vektör</li></ul><p>Bundan dolayı herhangi bir kelimenin vektörüne bakmak için dictionaryden kelimeyi istediğimiz zaman vektöre ulaşmış olacağız.</p><h2 id=word2vec-tahmin-bazlı-bir-metod>Word2Vec: Tahmin Bazlı bir Metod</h2><p>Ana amacımız kelimelerden, kelime vektörleri oluşturmak.</p><p>Word2Vec parametreli word vektörleri olan bir modeldir. Bu parametreler itaretive yöntemle, objective function(küçültmeye çalıştığımız fonksiyon) kullanarak optimize edilir.</p><p>Peki bunu nasıl yapacağız.</p><p>Unutmadan:</p><ul><li>amaç : her bir vektörü kelimenin içeriğini bilecek şekilde kodlamak</li><li>nasıl yapılacak: vektörleri kelimelerden olası içerik tahmin edecek şekilde eğitmek.</li></ul><p><code>Word2Vec</code> iterative bir metottur. Ana fikirleri kısaca şöyledir.</p><ul><li>büyük bir text corpusu alır</li><li>texti, belirli bir sliding window(kayan pencere) kullanarak, her seferinde bir kelime ilerleyecek şekilde ilerlemek. Her bir adımda, bir tane <code>central word (merkezi kelime)</code> ve <code>context words(içerik kelimeleri)</code> -> penceredeki diğer kelimeler.</li><li>merkezi kelime için, içerik kelimelerinin olasılıklarını hesapla.</li><li>vektörleri olasılıkları artıracak şekilde ayarla</li></ul><p><img class=lazyload src=/svg/loading.min.svg data-src=../../images/training_data.png data-srcset="../../images/training_data.png, ../../images/training_data.png 1.5x, ../../images/training_data.png 2x" data-sizes=auto alt=../../images/training_data.png title=word2vec-nedir></p><p>Resimde de görüleceği üzere her seferinde arkası mavi olan <code>merkezi kelime</code> ve diğerleri de <code>içerik kelimeleri</code>.</p><h3 id=objective-function-amaç-fonksiyonu>Objective Function (Amaç Fonksiyonu)</h3><p>Text corpusundaki her bir $ t = 1, &mldr; , T$ pozisyon için, Word2Vec merkezi kelimesi $w_{t}$ verilmiş m-boyutlu penceredeki içerik kelimelerini tahmin eder.</p><p>$$
Likelihood = L(\theta) = \prod_{t=1}^{T} \prod_{-m \leq j \leq m, j \neq 0} P(w_{t + j} \mid w_t, \theta)
$$</p><p>Bu fonksiyonda $\theta$ optimize edilecek bütün parametrelerdir. Amaç ve Kayıp Fonksiyonu $J(\theta) ise ortalama negatif log olabilirlik fonksiyonudur. (Negative log-likelihood)</p><p>$$
J(\theta) = -\frac{1}{T} \log L(\theta) = -\frac{1}{T} \sum_{t=1}^{T} \sum_{-m \leq j \leq m, j \neq 0 } \log P(w_{t + j} \mid w_t, \theta)
$$</p><p>Bu formüldeki parçalara ayıralım.</p><ul><li>$\sum_{t=1}^{T}$ Bu kısım bütün text üzerinde gezinir.</li><li>$\prod_{-m \leq j \leq m, y \neq 0}$ bu ise kayma penceresini(sliding window) temsil eder.</li><li>$\log P(w_{t + j} \mid w_t, \theta)$ : bu ise merkezi kelimesi verilen içeriğin olasılığını hesaplar.</li></ul><p>Peki asıl sorulması gereken soru bu olasılıklar nasıl hesaplanacak?</p><h3 id=olasılıkları-nasıl-hesaplayacağız>Olasılıkları Nasıl Hesaplayacağız?</h3><p>Hesaplamak istediğimiz olasılık
$$
P(w_{t + j} \mid w_t, \theta)
$$</p><p>Verilen her kelime $w$ için, iki adet vektörümüz var.</p><ul><li>$v_w$ -> kelimenin merkezi kelime (central word) olduğu zaman</li><li>$u_w$ -> kelimenin içerik kelime (context word) olduğu zaman</li></ul><p>Vektörler train edildikten sonra, genel olarak içerik vektörlerini $u_w$ atar ve sadece merkezi kelime vektörlerini $v_w$ kullanılır.</p><p>Bundan sonra verilen <strong>merkezi kelime</strong> $c$ ve <strong>içerik kelimesi</strong> $o$ kelimeleri için olasılık:</p><p>$$
P(o \mid c) = \frac{exp(u_{o}^{T})}{\sum_{v \in V} exp(u_{w}^{T} v_c)}
$$</p><p><strong>NOT:</strong> Bu bir <code>softmax fonksiyonudur.</code> Softmax ile alakalı yazıma <a href=https://ocakhasan.github.io/blog/Softmax-Aktivasyon-Fonksiyonu-Nedir-Numpy-Implementasyonu/ target=_blank rel="noopener noreffer">bu yazımdan</a> ulaşabilirsiniz.</p><p>Şimdi bu olasılıkları nasıl hesaplayacağımız gördüğümüze göre, vektörleri nasıl eğiteceğimizi görelim.</p><h3 id=nasil-eğitilir>NASIL EĞİTİLİR</h3><p>Kısaca bu sorunun cevabı <em>Gradient Descent</em> ile her seferinde bir kelime alarak gerçekleşir.</p><p>Parametrelerimiz $\theta$ bütün kelimelerin $v_w$ ve $u_w$ vektörleri olduğunu hatırlayalım. Bu vektörleri gradient descent kullanarak optimize edeceğiz.</p><p>$$
\theta^{new} = \theta^{old} - \alpha \nabla_{\theta} J(\theta)
$$</p><p>Bu parametre güncellemerini her seferinde bir kelime kullanarak yapıyoruz. Her bir güncelleme bir merkez kelime ve içerik kelimesi ikilileriyle yapılır. Tekrardan kayıp fonksiyonuna bakalım.</p><p>$$
J(\theta) = -\frac{1}{T} \log L(\theta) = -\frac{1}{T} \sum_{t=1}^{T} \sum_{-m \leq j \leq m, j \neq 0 } \log P(w_{t + j} \mid w_t, \theta)
$$</p><p>Merkezi kelime $w_t$ için, kayıp fonksiyonu ayrı bir terimi her bir içerik kelimesi (w_{t + j}) (sliding window içerisindeki) (J_{t,j}(\theta) = -\log P(w_{t + j} \mid w_t, \theta\</p><p>Bir örnek vererek bu durumu daha iyi anlayalım. Şu cümleyi ele alalım.</p><p>Bugün bahçede <span style=color:green>bir</span> top gördüm.</p><p>Yeşil renkli <em>bir</em> kelimesi burada bizim merkezi kelimemizdir. Her seferinde bir kelimeye bakacağımız için, bir tane içerik kelimesi seçeceğiz. Örnek olarak <em>top</em> kelimesini ele alalım. Bundan sonra bu iki kelime için kayıp fonksiyonu</p><data id=id-1 data-raw></data><p>Buradaki $V$ kümesi sliding windowu kapsayan kelimelerden oluşur. Loss (kayıp) fonksiyonumuzu aldığıma göre, şimdi vektörler üzerinde güncelleme yapalım.</p><p>Burada hangi parameterlerin olduğuna göz atalım.</p><ul><li>merkezi kelime vektörlerinden sadece $v_{bir}$</li><li>içerik kelime vektörlerinden ise sliding window içerisindeki bütün kelimeler $u_w \forall w \in V$</li></ul><p>Şuanki adımda sadece bu parametreler güncellenecek.</p><p>$$
v_{bir} := v_{bir} - \alpha \frac{\partial J_{t, j}(\theta)}{\partial v_{bir}}
$$</p><p>$$
u_w = u_w - \alpha \frac{\partial J_{t, j}(\theta)}{\partial u_{w}} \forall w \in V
$$</p><p>Kayıp fonksiyonunu azaltacak şekilde yaptığımız her bir güncelleme, parametreler arasındaki benzerliği $v_{bir} \hspace{1mm} ve \hspace{1mm} u_{top}$ dot product&rsquo;ını artırıyor ve aynı zamanda diğer her bir diğer $u_w$ ile $v_{bir}$ arasındaki benzerliği de azaltıyor.</p><p>Bu biraz garip gelebilir ancak neden <em>bir</em> kelimesinin <em>top</em> kelimesinden hariç diğer kelimelerle benzerliğini azaltmaya çalışıyoruz. Diğerleri de mantıklı, içerik verecek kelimeler olabilir. Ancak bu bir sorun değil! Biz bu güncellemeyi her kelime için tek tek yaptığımızdan dolayı, yani her kelime bir kez merkezi kelime olacak, vektörler üzerindeki bütün güncellemelerin ortalaması metin içeriğininin dağılımını öğrenecektir.</p><p>Bu yazıda partial derivative kısımlarına girilmemiştir. Ancak ben genel olarak <strong>Word2Vec</strong> modelinin nasıl çalıştığını anlatabildiğimi düşünüyorum. Eğer denemek isterseniz partial derivative kısımlarını kendiniz deneyebilirsiniz. Diğer yazılarda görüşmek üzere.</p><p>Eğer yazıyı beğendiyseniz paylaşmayı unutmayın ki diğer insanlar da yararlansın.</p><h2 id=references>REFERENCES</h2><ul><li><a href=https://lena-voita.github.io/nlp_course/word_embeddings.html target=_blank rel="noopener noreffer">https://lena-voita.github.io/nlp_course/word_embeddings.html</a></li></ul></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2022-12-11</span></div></div><div class=post-info-line><div class=post-info-md><span><a class=link-to-markdown href=/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/index.md target=_blank>Read Markdown</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://ocakhasan.github.io/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/ data-title="Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir" data-hashtags="makine ogrenmesi,nlp"><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://ocakhasan.github.io/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/ data-hashtag="makine ogrenmesi"><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://ocakhasan.github.io/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/ data-title="Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://ocakhasan.github.io/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/ data-title="Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir"><i data-svg-src=/lib/simple-icons/icons/line.min.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://ocakhasan.github.io/word2vec-nedir-ve-word2veckelimelerden-nasil-ogrenir/ data-title="Word2Vec Nedir ve Word2Vec Kelimelerden Nasıl Öğrenir"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/makine-ogrenmesi/>makine ogrenmesi</a>,&nbsp;<a href=/tags/nlp/>nlp</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/dinamik-programlama-ile-knapsack-problemi-nasil-cozulur/ class=prev rel=prev title="Dinamik Programlama ile Knapsack Problemi Nasıl Çözülür"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>Dinamik Programlama ile Knapsack Problemi Nasıl Çözülür</a>
<a href=/evrisimsel-sinir-aglari-nedir/ class=next rel=next title="Evrişimsel Sinir Ağları  (Convolutional Neural Network) Nedir">Evrişimsel Sinir Ağları (Convolutional Neural Network) Nedir<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.117.0">Hugo</a> | Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden=true></i> LoveIt</a></div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2019 - 2023</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>Hasan Ocak</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=/lib/katex/katex.min.css><script type=text/javascript src=/lib/autocomplete/autocomplete.min.js></script><script type=text/javascript src=/lib/lunr/lunr.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js></script><script type=text/javascript src=/lib/katex/contrib/auto-render.min.js></script><script type=text/javascript src=/lib/katex/contrib/copy-tex.min.js></script><script type=text/javascript src=/lib/katex/contrib/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:100},comment:{},data:{"id-1":"\n$$\nJ_{t,j}(\\theta) = -\\log P(top \\mid bir) = -log \\frac{exp(u^{T}_{top} v_{bir})}{\\sum_{w \\ in V} exp(u^{T}_{w} v_{bir})} = -u_{top}^T v_{bir} + log \\sum_{w \\in V} exp(u^{T}_{w} v_{bir})\n$$ \n"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.js></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-165674239-4",{anonymize_ip:!0})</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=UA-165674239-4" async></script></body></html>