<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>matematik - Tag - Hasan Ocak Tech Blog</title><link>https://ocakhasan.github.io/tags/matematik/</link><description>matematik - Tag - Hasan Ocak Tech Blog</description><generator>Hugo -- gohugo.io</generator><language>tr</language><managingEditor>hasanocak.tech@gmail.com (Hasan Ocak)</managingEditor><webMaster>hasanocak.tech@gmail.com (Hasan Ocak)</webMaster><lastBuildDate>Sat, 20 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://ocakhasan.github.io/tags/matematik/" rel="self" type="application/rss+xml"/><item><title>Pytorch AutoGrad Nedir ve Nasıl Çalışır</title><link>https://ocakhasan.github.io/pytorch-autograd-nedir-ve-nasil-calisir/</link><pubDate>Sat, 20 Feb 2021 00:00:00 +0000</pubDate><author>Hasan Ocak</author><guid>https://ocakhasan.github.io/pytorch-autograd-nedir-ve-nasil-calisir/</guid><description>Basit şekilde Pytorch Autograd ile otomatik olarak nasıl türev işlemleri halledilir.</description></item><item><title>Softmax Aktivasyon Fonksiyonu Nedir ve Numpy ile Nasıl Implement Edilir</title><link>https://ocakhasan.github.io/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/</link><pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate><author>Hasan Ocak</author><guid>https://ocakhasan.github.io/softmax-aktivasyon-fonksiyonu-nedir-numpy-implementasyonu/</guid><description>Derin Öğrenmede kullanılan softmax aktivasyon fonksiyonunu inceliyoruz.</description></item><item><title>Makine Ogrenmesinde Parametrik Metodlar</title><link>https://ocakhasan.github.io/makine-ogrenmesinde-parametrik-metodlar/</link><pubDate>Sun, 12 Jan 2020 00:00:00 +0000</pubDate><author>Hasan Ocak</author><guid>https://ocakhasan.github.io/makine-ogrenmesinde-parametrik-metodlar/</guid><description>İstatiksel biçimde parametrik metodları inceliyoruz.</description></item></channel></rss>